[
  {
    "objectID": "workbooks.html",
    "href": "workbooks.html",
    "title": "Workbooks",
    "section": "",
    "text": "Published Workbooks\n\nProject 0\n\nProject 1\n\nProject 2\n\nProject 3\nProject 4\nProject 5\n\nProject 6\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Course Workbooks"
    ]
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides",
    "section": "",
    "text": "About this site\n\n\n\n Back to top"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Course Setup",
    "section": "",
    "text": "How to get your computer setup?\nThe left navigation bar is sequenced for the setup process:\nIf you want to use a AWS Cloud Virtual Machine (VM) instead of your laptop and install Python and VS Code on that VM, start here:\n\nCreate an AWS EC2 VM (recomended for online and non-DataScience students)\n\nThis course uses Slack as our main tool for communication and collaboration. You will need to install Slack on your laptop and mobile device. You will also need to create a Slack account using your BYU-Idaho email. If you have an existing account, you can either change your email to the BYU-Idaho email or you can create a new account.\n\nInstall Slack on your laptop:\n\nWindows\n\nMac\n\n\nInstall Slack on your Cell:\n\nAndroid\n\niPhone\n\nCreate a Slack Account using your BYU-Idaho email:\n\nSlack\n\n\nIf you want to use Python and VS code on your own laptop, start here:\n\nInstall Python\nInstall Python Libraries\n\nInstall VS Code\n\nInstall Quarto\n\nYou will need to use SQL in Week 4:\n\nSQL setup and test\n\nYou will need to use GitHub from Week 6 on:\n\nInstall Git & GitHub\n\nUsing Copilot (AI)?\n\nCopilot is a micro-assistant that helps you write better code. It is a VS Code extension that uses AI built off Chat GPT-4. With your student GitHub account, you can use Copilot for free. It helps you write code faster and with fewer errors. It is not perfect, but it is a great tool to help you learn to code.\n\n\nThis course is designed with a Core and Stretch for each project. It is expected that you acomplish the Core without the use of Copilot. The Stretch is where you should use Copilot. Without using Copilot, the stretch questions will be more challenging. The goal is to help you learn to code and to use Copilot as a tool to help you learn, not to do the work for you.\n\n\nInstall GitHub Copilot (required for Stretch Questions)\n\nPrefer an Open Source AI tool try Llama?\n\nLlama is an AI-powered code editor that helps you write better code. It is a VS Code extension that uses AI built off Chat GPT-4. With your student GitHub account, you can use Llama for free. It helps you write code faster and with fewer errors. It is not perfect either, but it is a great tool to help you learn to code.\n\n\nInstall Llama (optional)\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Course Material",
    "section": "",
    "text": "We will be relying on a few resources for this course. You will find the pertinant readings attached to each of the projects. Those readings will be culled from:\n\nPython for Data Science: A port of R for Data Science using the Python packages pandas and Altair.\npandas User Guide\nLets Plot User Guide\nscikit-learn learn User Guide\nscikit-learn tutorials\nPython Data Science Handbook\nA Whirlwind Tour of Python\nSQL \n\nWes McKinney’s pandas code for his book Python for Data Analysis is a useful reference as well: https://github.com/wesm/pydata-book\n\n\n\n Back to top",
    "crumbs": [
      "Course Materials"
    ]
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "“What do you mean by data science programming?”\nMost likely, you have had 1-2 courses of programming before you have taken DS 250. Unlike traditional computer science courses, DS 250 uses Python in an interactive mode instead of building programs. The data provider usually has some big questions that need answering; However, there are hundreds of little issues and responses along the way. We use programming to facilitate this investigation.\nThere are similarities with User Experience Designers. In our case, we don’t get to ask users about their experience. We use programming to ask data about its background, and each data set has its own history. We want our analysis to mold to that experience. You can think of data science programming like a first date with your data. You can’t write one long program nieve of the issues and nuances each living data set provides.\n\n\n\n“How does DS 250 compare to DS 350?”\nThe two courses have similarities. You could think of DS 250 as an introduction to data wrangling and visualization. Both classes use real-world data and are built around data science projects. There are some critical differences between the two courses.\n\nIn this course, we use Python, and DS 350 uses R.\nWe are introducing the principles of data science programming in DS 250.\nThe course is only 2-credits.\nDS 250 is intended to introduce visualization, wrangling, and modeling.\n\n\n\n\nfaq “How does DS 250 prepare me for DS 350 and CSE 450?”\nYou will be comfortable with interactive programming and have an introduction to the principles of data formats for data science applications. You will be introduced to principles related to machine learning, data wrangling, and data visualization.\n\n\n\n“What programming languages do we use in this course?”\nThe course is done using Python. We focus on the pandas and the lets-plot plotting packages (this plotting package is modeled after ggplot2 in R).\n\n\n\n“What are the prerequisites for this course?”\nUsing the new courses at BYU-I, the prerequisite is CSE 110. However, if you have experience programming from other classes, you most likely are prepared for this course.\n\n\n\n“Why Python instead of R?”\nThe computer science and software engineering programs at BYU-I use Python as their foundational courses. The standard student will have some experience with Python before DS 250. Python is an essential programming language for data scientists, and we already have DS350, which is taught in R.\n\n\n\n“What is pandas?”\npandas is the foundational data science package in Python. If you are using tabular data you will be in pandas. Polars is growing in popularity, but there isn’t as much help for it yet.\n\n\n\n“Why are we using lets-plot instead of Seaborn or Matplotlib or Altair?”\nMatplotlib was the first visualization package to gain a following in Python. Seaborn is built on top of Matplotlib. Seaborn is easy to pick-up and understand, but much less flexible. Many data scientists use both in their work—neither leverage the grammar of graphics as developed by Leland Wilkinson. Altair is built on Vega-Lite, which uses the Vega visualization grammar. It is declarative and actively developed.\nLets-plot has the advantage of being similar to ggplot2 in R and also uses a grammar of graphics. Using this plotting package should help students transition between the two so they can more quickly move between R and Python. It is intuitive and relatively easy to use. There are other plotting packages as well, but none of them are an obvious choice or a dominant choice of the others.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Workbooks/wb6.html",
    "href": "Workbooks/wb6.html",
    "title": "Project 6 Workbook",
    "section": "",
    "text": "Project 6 WorkBook\nUnder Construction\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 6"
    ]
  },
  {
    "objectID": "Workbooks/wb4.html",
    "href": "Workbooks/wb4.html",
    "title": "Project 4 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 4"
    ]
  },
  {
    "objectID": "Workbooks/wb4.html#tutoring-lab-info",
    "href": "Workbooks/wb4.html#tutoring-lab-info",
    "title": "Project 4 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 4"
    ]
  },
  {
    "objectID": "Workbooks/wb2.html",
    "href": "Workbooks/wb2.html",
    "title": "Project 2 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 2"
    ]
  },
  {
    "objectID": "Workbooks/wb2.html#tutoring-lab-info",
    "href": "Workbooks/wb2.html#tutoring-lab-info",
    "title": "Project 2 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 2"
    ]
  },
  {
    "objectID": "Workbooks/wb2.html#plotly-chart-structure",
    "href": "Workbooks/wb2.html#plotly-chart-structure",
    "title": "Project 2 Workbook",
    "section": "Plotly Chart Structure",
    "text": "Plotly Chart Structure\n\n\nShow the code\nfig = px.scatter(data, x='displ', y='hwy')\nfig.show()",
    "crumbs": [
      "Project 2"
    ]
  },
  {
    "objectID": "Workbooks/wb2.html#size-of-chart",
    "href": "Workbooks/wb2.html#size-of-chart",
    "title": "Project 2 Workbook",
    "section": "Size of Chart",
    "text": "Size of Chart\nWidth and Height\n\n\nShow the code\nfig = px.scatter(data, x='displ', y='hwy')\nfig.update_layout(width=600, height=600)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipWidth and Height Explanation\n\n\n\n\n\nThe width and height parameters in the update_layout method are used to set the width and height of the plot in pixels, respectively. In this example, the width is set to 600 pixels, and the height is also set to 600 pixels. Adjust these values according to your desired dimensions for the scatter plot.",
    "crumbs": [
      "Project 2"
    ]
  },
  {
    "objectID": "Workbooks/wb2.html#title-and-subtitle",
    "href": "Workbooks/wb2.html#title-and-subtitle",
    "title": "Project 2 Workbook",
    "section": "Title and Subtitle",
    "text": "Title and Subtitle\nTitle\n\n\nShow the code\nfig = px.bar(data, x='cty', y='hwy')\nfig.update_layout(title_text=\"Bar Chart Example\")\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipTitle Explanation\n\n\n\n\n\nThe title_text parameter in the update_layout method is used to set the title of the plot. In this example, the title is set to “Bar Chart Example”. You can customize the title by changing the value assigned to title_text to better describe the content or purpose of your bar chart.\n\n\n\nTitle and subtitle - Title w/ Subtitle 1\n\n\nShow the code\nfig = px.bar(data, x='cty', y='hwy')\n\nfig.update_layout(\n    title_text=\"City vs Highway MPG Bar Chart\",\n    title_font=dict(color=\"red\"),\n    title_font_size=18,\n    title_y=0.95,\n    title_x=0.5\n)\n\nfig.add_annotation(\n    text=\"Your Annotation Text\",\n    font=dict(color=\"blue\"),  # Choose your desired font color\n    x=0.5,\n    y=0.9,\n    showarrow=False\n)\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipTitle and subtitle - Title w/ Subtitle 1 Explanation\n\n\n\n\n\nThe title_text parameter in the update_layout method is used to set the main title of the plot, and additional parameters like title_font, title_font_size, title_y, and title_x are used to customize the appearance and position of the title.\nThe add_annotation method is used to add an annotation or subtitle to the plot. In this example, it adds a blue text annotation with the content “Your Annotation Text” at a specified position (x=0.5, y=0.9) relative to the plot.\nAdjust the values of these parameters to customize the appearance and position of the title and annotation according to your preferences.\n\n\n\nTitle and subtitle - Title w/ Subtitle 2\n\n\nShow the code\nfig = px.bar(data, x='cty', y='hwy')\n\nfig.update_layout(\n    title_text=\"City vs Highway MPG Bar Chart\",\n    title_font_size=18,\n    title_y=0.95,\n    title_x=0.5\n)\n\nfig.add_annotation(\n    text=\"Your Annotation Text\",\n    x=0.5,\n    y=0.9,\n    showarrow=False\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipTitle and subtitle - Title w/ Subtitle 2 Explanation\n\n\n\n\n\nThe title_text parameter in the update_layout method is used to set the main title of the plot, and additional parameters like title_font_size, title_y, and title_x are used to customize the appearance and position of the title.\nThe add_annotation method is used to add an annotation or subtitle to the plot. In this example, it adds a text annotation with the content “Your Annotation Text” at a specified position (x=0.5, y=0.9) relative to the plot.\nAdjust the values of these parameters to customize the appearance and position of the title and annotation according to your preferences.\n\n\n\nGroup Variable\n\n\nShow the code\nfig = px.bar(data, x='manufacturer', y=['cty', 'hwy'], barmode='group')\n\nfig.update_layout(\n    xaxis_title=\"Manufacturer\",\n    yaxis_title=\"Mileage\",\n    title_text=\"Average City and Highway Mileage by Manufacturer\"\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipGroup Variable Explanation\n\n\n\n\n\nThe x parameter in the px.bar function is set to ‘manufacturer’, which means the bars will be grouped by the ‘manufacturer’ variable on the x-axis. The y parameter is set to a list [‘cty’, ‘hwy’], indicating that two sets of bars will be plotted for each manufacturer, one for ‘cty’ and another for ‘hwy’.\nThe barmode='group' parameter ensures that the bars are grouped for each ‘manufacturer’.\nThe update_layout method is used to set the titles for the x-axis (xaxis_title), y-axis (yaxis_title), and the overall plot (title_text). In this example, the plot represents the average city and highway mileage by manufacturer.\n\n\n\nAxis formatting - Axis Scale removing Zero\n\n\nShow the code\nfig = px.bar(data, x='manufacturer', y=['cty', 'hwy'], barmode='group')\n\nfig.update_layout(\n    xaxis_title=\"Manufacturer\",\n    yaxis_title=\"Mileage\",\n    title_text=\"Average City and Highway Mileage by Manufacturer\",\n    xaxis=dict(showline=True, showgrid=False),\n    yaxis=dict(zeroline=False, showline=True, showgrid=False),\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipAxis formatting - Axis Scale removing Zero Explanation\n\n\n\n\n\nThe xaxis_title and yaxis_title parameters in the update_layout method are used to set the titles for the x-axis and y-axis, respectively.\nThe xaxis and yaxis dictionaries in the update_layout method provide additional formatting options for the x-axis and y-axis. In this example:\nxaxis=dict(showline=True, showgrid=False) ensures that the x-axis has a visible line but no grid lines. yaxis=dict(zeroline=False, showline=True, showgrid=False) ensures that the y-axis has no zero line (zeroline=False), a visible line, and no grid lines. These settings help customize the appearance of the plot by controlling the visibility of axis lines and grid lines.\n\n\n\nAxis formatting - Axis Domain Sizing\n\n\nShow the code\nfig = px.bar(data, x='manufacturer', y=['cty', 'hwy'], barmode='group')\n\nfig.update_layout(\n    xaxis_title=\"Manufacturer\",\n    yaxis_title=\"Mileage\",\n    title_text=\"Average City and Highway Mileage by Manufacturer\",\n    xaxis=dict(domain=[0.1, 0.9]),  # Adjust the domain as needed\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipAxis formatting - Axis Domain Sizing Explanation\n\n\n\n\n\nThe xaxis_title and yaxis_title parameters in the update_layout method are used to set the titles for the x-axis and y-axis, respectively.\nThe xaxis dictionary in the update_layout method includes the domain parameter, which is set to [0.1, 0.9]. This parameter controls the size of the x-axis domain, determining the portion of the total width of the plot that the x-axis occupies. In this example, the x-axis is set to span from 10% to 90% of the total width.\nAdjust the values of the domain parameter as needed to control the sizing of the x-axis in your plot.\n\n\n\nReference marks - Verticle Reference Line with Color\n\n\nShow the code\nfig = px.bar(data, x='manufacturer', y=['cty', 'hwy'], barmode='group')\n\nfig.update_layout(\n    xaxis_title=\"Manufacturer\",\n    yaxis_title=\"Mileage\",\n    title_text=\"Average City and Highway Mileage by Manufacturer\"\n)\n\nfig.add_shape(\n    dict(\n        type=\"line\",\n        x0=\"Your_X_Value\",  # Specify the x-coordinate of the line\n        x1=\"Your_X_Value\",  # Specify the x-coordinate of the line\n        y0=0,\n        y1=1,\n        line=dict(color=\"red\"),  # Specify the color of the line\n    )\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipReference marks - Verticle Reference Line with Color Explanation\n\n\n\n\n\nThe add_shape method is used to add a reference line to the plot. In this example, a vertical reference line is added to the x-axis at the specified x-coordinate value.\nThe type=\"line\" parameter specifies that the added shape is a line. The x0 and x1 parameters are set to “Your_X_Value” to specify the x-coordinates where the line starts and ends. Replace “Your_X_Value” with the actual x-coordinate value where you want the reference line.\nThe y0 and y1 parameters set the starting and ending points on the y-axis. In this example, they are set to 0 and 1, respectively.\nThe line dictionary inside the shape specifies the attributes of the line, such as the color. In this case, the line color is set to red. Adjust the values as needed to customize the appearance of the reference line.\n\n\n\nReference marks - Verticle Reference Line with Text\n\n\nShow the code\nfig = px.bar(data, x='manufacturer', y=['cty', 'hwy'], barmode='group')\n\nfig.update_layout(\n    xaxis_title=\"Manufacturer\",\n    yaxis_title=\"Mileage\",\n    title_text=\"Average City and Highway Mileage by Manufacturer\"\n)\n\nfig.add_shape(\n    dict(\n        type=\"line\",\n        x0=\"Your_X_Value\",  # Specify the x-coordinate of the line\n        x1=\"Your_X_Value\",  # Specify the x-coordinate of the line\n        y0=0,\n        y1=1,\n        line=dict(color=\"red\"),  # Specify the color of the line\n    )\n)\n\nfig.add_annotation(\n    text=\"Your Text\",\n    x=\"Your_X_Value\",  # Specify the x-coordinate of the text\n    y=500,  # Adjust the y-coordinate of the text as needed\n    showarrow=False\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTipReference marks - Verticle Reference Line with Text Explanation\n\n\n\n\n\nThe add_shape method is used to add a reference line to the plot. In this example, a vertical reference line is added to the x-axis at the specified x-coordinate value.\nThe type=\"line\" parameter specifies that the added shape is a line. The x0 and x1 parameters are set to “Your_X_Value” to specify the x-coordinates where the line starts and ends. Replace “Your_X_Value” with the actual x-coordinate value where you want the reference line.\nThe y0 and y1 parameters set the starting and ending points on the y-axis. In this example, they are set to 0 and 1, respectively.\nThe line dictionary inside the shape specifies the attributes of the line, such as the color. In this case, the line color is set to red.\nThe add_annotation method is used to add text annotation to the plot. The text parameter is set to “Your Text”, and the x and y parameters specify the coordinates where the text will be placed. Adjust the values of these parameters as needed to customize the appearance of the reference line and text.",
    "crumbs": [
      "Project 2"
    ]
  },
  {
    "objectID": "Workbooks/wb0.html",
    "href": "Workbooks/wb0.html",
    "title": "Project 0 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.\n\n\n\n\n\nCourse Setup ::: {.callout-note collapse=“true”} ## Note on the Intro Chapter in Python for DataScience\nDon’t follow the setup for pyton in the book use the Course Setup instead\nTesting running the instructional template to make sure your setup is correct ::: —\n\n\n\n\n\nLearn about Lets-Plot",
    "crumbs": [
      "Project 0"
    ]
  },
  {
    "objectID": "Workbooks/wb0.html#tutoring-lab-info",
    "href": "Workbooks/wb0.html#tutoring-lab-info",
    "title": "Project 0 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 0"
    ]
  },
  {
    "objectID": "Workbooks/wb0.html#setup-python-vs-code-and-quarto",
    "href": "Workbooks/wb0.html#setup-python-vs-code-and-quarto",
    "title": "Project 0 Workbook",
    "section": "",
    "text": "Course Setup ::: {.callout-note collapse=“true”} ## Note on the Intro Chapter in Python for DataScience\nDon’t follow the setup for pyton in the book use the Course Setup instead\nTesting running the instructional template to make sure your setup is correct ::: —",
    "crumbs": [
      "Project 0"
    ]
  },
  {
    "objectID": "Workbooks/wb0.html#learn-about-lets-plot",
    "href": "Workbooks/wb0.html#learn-about-lets-plot",
    "title": "Project 0 Workbook",
    "section": "",
    "text": "Learn about Lets-Plot",
    "crumbs": [
      "Project 0"
    ]
  },
  {
    "objectID": "Syllabus/competency.html",
    "href": "Syllabus/competency.html",
    "title": "DS 250 Competency",
    "section": "",
    "text": "We need skills not grades! Shifting Attention\n\n\nCompetency scale\nYou must complete all competency items at the level detailed to achieve the listed grade. You can request half-step adjustments if you fall slightly short on some elements and over on others. If you are fall short slightly on some elements but dont achive over on others you have not met the requirements for the half-step adjustment.\nExample of a half-step adjustment:\n\nProjects 33 points (B+)\nProject Stretchs 4 (A+)\nMid-project checkpoints (online only) 5 (A)\nMethods & Calculations checkpoints 5 (B)\nDS Community 5 (A+)\nCoding challenge 3 (A/B)\nThe over-under of my work is a B+/A-. My extra work on Project Stretches helps ofset me not meeting the A level project points. Also my extra DS Community efforts to ofset my M&C checkpoints. I am requesting a A for the course.\n\nYou will need to provide a detailed description in your Course Goals Letter of the items you completed to support your grade request. The course goals letter is a reflection on your efforts and the competencies they align with as well as your reflection on achieving your goals for this course.\n\nExample Course Goals Letter (End):\nHere is my assessment of my efforts and the competency that they align with, as well as my reflection on achieving my goals for this course:\n\nProjects 29 points (B-)\nProject Stretchs 1 (C)\nMid-project checkpoints (online only) 4 (B+)\nMethods & Calculations checkpoints 4 (C+)\nDS Community 3 (A)\nCoding challenge 3 (A/B)\nThe over-under of my work is a B/B+. I am requesting a B+ for the course.\n\n\nLeader (A)Supporter (B)Listener (C)Asleep (D)\n\n\n\nLeader (A)\n\n\n\n\n\n\n\n\nElement\nRequirement\nDescription\n\n\n\n\nProjects\n34+ Points\n5 points per project\n\n\nProject Stretchs\nAt least 3\n3 projects all stretches\n\n\nMid-project checkpoints\n5 completed\nFull credit (online only)\n\n\nMethods & Calculations checkpoints\n6 completed\nAll 6 @ 100% Full Points\n\n\nDS Community\nAt least 3\n–\n\n\nCourse Goal Letter (End)\nsubmission\n–\n\n\nCoding challenge\nAt least 3\nScore is out of 4\n\n\n\n\n\n\n\nSupporter (B)\n\n\n\n\n\n\n\n\nElement\nRequirement\nDescription\n\n\n\n\nProjects\n29-33 Points\n5 points per project\n\n\nProject Stretchs\nAt least 2\n2 projects all stretches\n\n\nMid-project checkpoints\n3 completed\nFull credit (online only)\n\n\nMethods & Calculations checkpoints\n5 completed\n5 @ 100% Full Points\n\n\nDS Community\nAt least 2\n–\n\n\nCourse Goal Letter (End)\nsubmission\n–\n\n\nCoding challenge\nAt least 3\nScore is out of 4\n\n\n\n\n\n\n\nListener (C)\n\n\n\n\n\n\n\n\nElement\nRequirement\nDescription\n\n\n\n\nProjects\n24-28 Points\n5 points per project\n\n\nProject Stretchs\nAt least 1\n1 projects all stretches\n\n\nMid-project checkpoints\n3 completed\nFull credit (online only)\n\n\nMethods & Calculations checkpoints\n3 completed\n3 @ 100% Full Points\n\n\nDS Community\nAt least 1\n–\n\n\nCourse Goal Letter (End)\nsubmission\n–\n\n\nCoding challenge\nAt least 2\nScore is out of 4\n\n\n\n\n\n\n\nAsleep (D)\n\n\n\n\n\n\n\n\nElement\nRequirement\nDescription\n\n\n\n\nProjects\n14-23 Points\n5 points per project\n\n\nProject Stretchs\nNone\n0 projects all stretches\n\n\nMid-project checkpoints\n1 completed\nFull credit (online only)\n\n\nMethods & Calculations checkpoints\n2 completed\n2 @ 100% Full Points\n\n\nDS Community\nNone\n–\n\n\nCourse Goal Letter (End)\nNone\n–\n\n\nCoding challenge\nNone\nScore is out of 4\n\n\n\n\n\n\n\n\n\n\nCompetency elements\n\nProjectsQuiz CheckpointsCheckpoints Mid-Project (online only)DS CommunityCourse Goals LetterChallenge\n\n\n\nProjects (Questions|Tasks)\nEach of the 7 projects is worth 5 points. There is no late work accepted for any project. Any submissions after the due date will receive a zero (0).\nThere is a optional early submission up through Friday (F) of the 2nd week of the project. This allows for coaching feedback and gives you that opportunity to fix any errors and resubmit. The resubmission is due by the following Wednesday. No resubmissions are allowed after that date. This structure is designed to give all students 2 attempts to get full project points.\nAll that wait to submit on the due date (Saturday), become ineligible for a rework submission. All submissions after Saturday will receive a zero (0).\nThere are 6 two-week projects (P0-P5) and 1 one-week project (P6).\nProjects 1-5 will have stretch questions. You must complete all the core questions first before attempting the stretch questions. You must complete all the stretch questions accurately for the project to count as a stretch project for the competency requirements. The number in the competencies relating to Project Stretches is the number of projects with all the stretch questions completed.\n\nGrading Details\n\n1 point: Submission\n3 points: Submission of a good faith attempt with a statement of work quality\n4 points: High-quality work that addresses each of the Questions and Tasks and a comment in Canvas of your statement of work quality\n5 points: Perfect-quality work or Rework that addressed all issues from the early submission\n\n\n\n\n\n\nCheckpoints (methods and calculations)\nThese Methods and Calculation Quizzes are in Canvas and they open when the project starts. They have unlimited attempts and remain open until the end of the semester. You must get a 100% on these quizzes for them to count toward the competencies.\n\nExamples\n\nFact-Finding Questions (Calculate descriptive summaries): Fact-finding questions help you with calculations that build into the Questions and Tasks of the project. These questions have clearly defined answers using Python calculations. You should expect 2-3 problems.\n\n\nExample: Using the top 10 airports in size, what is the average size?\nExample: What proportion of flights are delayed at the largest airport?\n\n\nHow the code works questions (Explaining the tools): This part could have direct answer questions or open-ended questions.\n\n\nExample (direct): What is the recommended function for arranging your data by a variable? What are the outputs after using &lt;FUNCTION&gt;?\nExample (open): Your client has shown some confusion about NumPy’s ‘nan’ handling in Python. Help them understand by answering the question, ‘How is missing data handled in Pandas?’\n\n\n\n\n\n\nCheckpoints (Mid-project status)\nThe mid-project checkpoint has a few questions. It opens the first day of the project and closes on the first Saturday of a 2 week project. It has the following questions.\n\nExamples\n\nThroughout this project, you have worked on a code. Record a video showing your code that is no more than 1 minute. This video must include: &gt; How long have you worked on this code? &gt; What is your code designed to do? &gt; What are, if any, the issues you’re facing? &gt; What questions or tasks have you checked off?\nSubmit your 1 minute video. &gt; You may share any additional notes with your teacher using the Canvas comment feature.\n\n\n\n\n\n\nData Science Community\nTo earn credit for the DS Community element you must complete tasks from the list below. At the end of the semester, you will be asked to report on how many tasks you completed and what you learned from them. See the Competency Scale above to determine how many you need to complete based on the grade you want.\n\nAttend Data Science Society at least once.\nSign up for an email newsletter that will teach you more about data science. Data Science Weekly or Data Elixir are good options.\nListen to a podcast episode about data science. Build a Career in Data Science has some excellent episodes.\nWatch a professional presentation on YouTube about data science. Be prepared to share the link and a summary of the video.\nReach out to someone who works in a data-related field and ask them for 15 minutes of their time. Use this time to conduct an “informational interview” and learn more about their responsibilities and career path.\nResearch and apply to at least 5 data-related jobs or internships.\n\n\n\n\n\nFinishing the semester\nSubmit a Course Goals Letter (End) that includes what you have learned from this class, the next data science course you plan on taking, and the final grade that you are requesting based on the work you have submitted compared to the competencies above.\n\n\n\n\nCoding challenge\nWe will have a timed (60 min) coding challenge on the ultimate or penultimate day of class. This is not a traditional exam and is similar to the projects all semester in size and scope but is accumulative. It will cover the general techniques that we have been practicing throughout the course. You will rely on your code from the projects and the methods and calculations checkpoints to complete the challenge.\nWe expect to have a few practice challenges throughout the semester. We will score the coding challenge on a four-point scale.\n\n1 point: At least you tried.\n2 points: You have learned some items from the course, but your work in the coding challenge is deficient.\n3 points: Your submission uses proper coding techniques and addresses the objective.\n4 points: Exceptional work. Your code can be used as a solution to share with others.\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Competency"
    ]
  },
  {
    "objectID": "Skill Builders/pandas_letsplot.html",
    "href": "Skill Builders/pandas_letsplot.html",
    "title": "Pandas and LetsPlot",
    "section": "",
    "text": "For this skill builder, we are exploring some important functions in the package of pandas and LetsPlot. DS programming requires a lot of data wrangling. Using the proper functions, we can create concise and comprehensive codes. You should be exposed to a few functions through the readings this week.\nYou may want to at least scan the readings before beginning this task since this serves as an assessment of your understanding of the assigned readings. This should be able to be finished within 60 minutes. You should work through it on your own or in a group based in your professors instruction.",
    "crumbs": [
      "Project 1: Pandas and LetsPlot"
    ]
  },
  {
    "objectID": "Skill Builders/pandas_letsplot.html#skill-builder",
    "href": "Skill Builders/pandas_letsplot.html#skill-builder",
    "title": "Pandas and LetsPlot",
    "section": "",
    "text": "For this skill builder, we are exploring some important functions in the package of pandas and LetsPlot. DS programming requires a lot of data wrangling. Using the proper functions, we can create concise and comprehensive codes. You should be exposed to a few functions through the readings this week.\nYou may want to at least scan the readings before beginning this task since this serves as an assessment of your understanding of the assigned readings. This should be able to be finished within 60 minutes. You should work through it on your own or in a group based in your professors instruction.",
    "crumbs": [
      "Project 1: Pandas and LetsPlot"
    ]
  },
  {
    "objectID": "Skill Builders/pandas_letsplot.html#data-import",
    "href": "Skill Builders/pandas_letsplot.html#data-import",
    "title": "Pandas and LetsPlot",
    "section": "Data Import",
    "text": "Data Import\nRun the following code to import the data we need for this skill builder:\n\n# package import\nimport numpy as np\nimport pandas as pd\nfrom lets_plot import *\nLetsPlot.setup_html(isolated_frame=True)\n\n# data import\nurl = 'https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/AER/Guns.csv'\ndf = pd.read_csv(url)\nMake sure the variable df is correctly assigned in your environment and finish the following exercises. You can read the documentation of the data on this page - https://vincentarelbundock.github.io/Rdatasets/doc/AER/Guns.html\n\n\nExercise 1\nOne of the first things we can do to a freshly imported data is to check its columns. This will help us understand the basic structure of the dataframe(table).\n\nUsing one line of code, select all the columns in dat, assign it to a variable called col_list.\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nEvery dataframe has an attribute “columns”.\nAccessing this attribute will give you a list of all column names\n\n\n\nWe often want to know the dimension of a dataframe. How many columns are in the dataset? How many rows are in the dataset?\n\nUsing one line of code, show the number of columns and rows in df.\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nEvery dataframe has an attribute “shape”.\nAccessing this attribute will give you the dimension of a datafarme\n\n\n\nNow run df.head(). It will print out the first 5 rows of data in df.\n\nJust from looking at the output, what column(s) seems to be redundant with the row number?\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nThere is one column that serves as nothing but a row counter, that columns is redundant.\n\n\n\n\n\n\nExercise 2\nAfter a brief investigation of the data, we will clean up the data. By cleaning up, we are trying to filter down df so this only holds data we need. We will first get rid of the extra column we found in the previous excercise.\n\nUsing one line of code, drop the redundant column using the variable col_list (created in excercise 1)\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nUse drop().\nUnderstand what “axis” is as a parameter of drop().\nYour function should looks like this:\ndf.drop([col_list[_]], axis = _)\nfill the “_“’s with the correct values and assign the output to df.\n\n\n\nDon’t forget to save the changes in df. Run df.head() to make sure the column is dropped in df.\n\n\n\nExercise 3\nWe have filtered df vertically by dropping a column. Now we will try to filter df horizontally, meaning we will get rid of some the rows.\nWe can do that by applying a condition to df. A condition is an expression that can be evaluated as True/False. For example, 8 &gt; 5 is an expression that evaluates to be True. This is trivial because 8 will always be greater than 5.\nRun the code below:\n\nwhat is the difference between exp1 and exp2?\n\nexp1 = 8 &gt; 5\nexp2 = df.violent &lt; 300\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nTry type() on else variable OR calling else variable.\n\n\n\nRun ths code below:\n\nBy putting df.violent &lt; 300, and the violent column from df into a dataframe, what is the relationship between the two columns?\n\nexp = pd.DataFrame({\"df.violent &lt; 300\" : exp2,\n                    \"violent value from dat\" : df.violent})\n\nexp\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nTry computing df.violent[n] &lt; 300 and (df.violent &lt; 300)[n] where n is less than the number of row. The two expressions will always be the same as long as n is less than the number of rows.\n\n\n\n\nUsing query()to filter down the df so that it only contains the data for idaho\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nquery() takes in expressions and filters down data.\n\n\n\nDon’t forget to save the changes in df. Run df.shape() to make sure the there are 23 rows and 13 columns.\n\n\n\nExercise 4\nBesides filtering, we can manipulate the data by adding new data to it. By adding a new column to the data, we assign a new value to each row.\n\nUsing assign(), create a new column that show the ratio between murder rate and violent rate.\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nUse assign()\nYou see get the ratio by computing this code:\ndf.murder/df.violent\n\n\n\n\n\n\nExercise 5\n\nCreate a scatter plot that shows the relationship between murder rate and violent rate for the state of Idaho. Your chart should show murder rate as the x-axis, violent as the y-axis.\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nCan you mimic this plot while using LetsPlot? https://lets-plot.org/",
    "crumbs": [
      "Project 1: Pandas and LetsPlot"
    ]
  },
  {
    "objectID": "Skill Builders/pandas_letsplot.html#because-youre-extra",
    "href": "Skill Builders/pandas_letsplot.html#because-youre-extra",
    "title": "Pandas and LetsPlot",
    "section": "Because You’re Extra",
    "text": "Because You’re Extra\n\nExercise 6\n\nUsing a line of code, filter down the data set so that it only shows the data in years between 1993 and 1997.\n\n\n\n\nExercise 7\n\nCreate a line chart that show prisoners numbers for the state of Idaho, Utah, and Oregon.\n\nYour chart should show year as the x-axis, prisoner as the y-axis, states as different colours, along with an appropriate title.\n\n\n\nExercise 8\n\nWithout using query(), finshed the data wrangling in question 2,5 and 6.\n\n\n\n\n\n\n\n\nNoteAfter you have completed this skill builder with your team (or on your own) then compare your work to our script\n\n\n\n\n\nSee the script.",
    "crumbs": [
      "Project 1: Pandas and LetsPlot"
    ]
  },
  {
    "objectID": "Skill Builders/ml_sklearn.html#data",
    "href": "Skill Builders/ml_sklearn.html#data",
    "title": "Machine Learning",
    "section": "Data",
    "text": "Data\nLink to data",
    "crumbs": [
      "Project 4: Machine Learning"
    ]
  },
  {
    "objectID": "Skill Builders/ml_sklearn.html#intro-to-titanic-machine-learning-skill-builder",
    "href": "Skill Builders/ml_sklearn.html#intro-to-titanic-machine-learning-skill-builder",
    "title": "Machine Learning",
    "section": "Intro to Titanic Machine Learning Skill Builder",
    "text": "Intro to Titanic Machine Learning Skill Builder\nFor this skill builder, we’ll be putting our machine learning hats on. We’ll be creating a model that predicts whether a passenger survived. With machine learning, there is a lot of jargon! It can be quite overwhelming at times. This skill builder attempts to keep things basic and simple. With that being said, there are some terms that are important to understand. Let’s look at the first few rows of our dataset before proceeding with the definitions.\nThe titanic dataset will be used for examples of each definition.\n\n\n\n\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsiblings_spouses_aboard\nparents_children_aboard\nfare\n\n\n\n\n0\n3\n1\n22\n1\n0\n7.25\n\n\n1\n1\n0\n38\n1\n0\n71.2833\n\n\n1\n3\n0\n26\n0\n0\n7.925\n\n\n1\n1\n0\n35\n1\n0\n53.1\n\n\n0\n3\n1\n35\n0\n0\n8.05\n\n\n\n\nImportant Terms:\n\nfeatures: measurable property of the object you’re trying to predict. We use this information to predict our target of interest.\n\nExample: pclass, sex, age, siblings_spouses_aboard , parents_children_aboard, fare columns are all examples of different features.\nSynonyms: attributes, explanatory variables, independent variables, variables, X’s, covariates\n\ntarget: the feature that you are wanting to gain more insight into. The thing you are trying to predict.\n\nExample: in the titanic dataset our target is survived\nSynonyms: label, dependent variable, y\n\ntrain set: Usually 70% of the rows from the original dataset are randomly sampled to create this training data. It’s used by the algorithm, to determine, or learn, the optimal combinations of variables that will generate a good predictive model\n\nExample: Random sample of 70% of the original titanic dataset rows\nSynonyms: training data, train data, X_train, y_train\n\ntest set: Usually the remaining 30% of the rows in the original dataset are used to create this dataset. The testing data is a set of rows used only to assess the performance (i.e. generalization) of a model. To do this, the final model is used to predict classifications of examples in the test set. Those predictions are compared to the examples’ true classifications to assess the model’s accuracy.\n\nExample: Random sample of 30% of the original titanic dataset rows\nSynonyms: testing data, test data, X_test, y_test\n\nevaluation metrics: A statistic that tells you how well your predictions align with the actual values. Other words, tells you how good your model is.\n\nExample: Accuracy, Precision, Recall, MSE, MAE, Rsquared\nSynonyms: performance metric\n\n\nAgain, this is a very light and oversimplified treatment of machine learning. The purpose of this project is to help you understand the main concepts of ml and walk you through the process of building a machine learning model. A simplified work flow of a machine learning project is shown below. Spend some time getting familiar with this flow &mdash as you are about to code it… Exciting!\nNote in order to do this skill builder you will need to have scikit-learn installed on your machine. Run the following command in your terminal if you haven’t already.\npip install scikit-learn\n\n\n\nExercise 1\n\nImports and Loading in Data\n# Loading in packages\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Loading in data\ndata = pd.read_csv(___)\n\n\n\n\nExercise 2\nCreate a chart exploring the relationship between age and survived in the titanic dataset. A strip plot, density plot, or boxplot might be useful here. Below is an example of a density plot. Feel free to replicate this chart or create your own.\nThe purpose of making this chart is to explore the relationships between a feature and the target. We want to see if the feature contains predictive information about the target. This is a large part of machine learning called Exploratory Data Analysis that should never be skipped! Spend time getting to know your features and how they interact with other features and the target.\n\n\n\n\nExercise 3\nBuild a random forest model that is able to predict whether a passenger survived. This exercise is the bulk of the skill builder and contains several steps.\n\nStep 0: Split the data into X and y variables\nThe X variable will contain all your features\n# Removes the target and keeps all features\nX = data.drop(___, axis=1)  \nThe y variable will hold the target\n# Selects the target column\ny = data['___']  \n\n\nStep 1: Split data into train and test sets\nThe train_test_split function is useful for this task. Review the train_test_split function documentation\n# Splitting X and y variables into train and test sets using stratified sampling\nX_train, X_test, y_train, y_test = train_test_split(___, ___, test_size=0.3,\n                                                    random_state=24, stratify=y)\n\n\nStep 2: Train the model\nExplore the RandomForestClassifier documentation for the RandomForestClassifier. It’s not necessary to understand the inner workings of the Random Forest algorithm for this class - just learn the syntax of fitting the model.\n# Creating random forest object\nrf = RandomForestClassifier(random_state=24)  \n\n# Fit with the training data\nrf.fit(___, ___)  \n\n\nStep 3: Use test set to make predictions\n# Using the features in the test set to make predictions\ny_pred = rf.predict(___)  \n\n\nStep 4: Compare test set predictions to actual values. Calculate the accuracy.\n# Comparing predictions to actual values\naccuracy_score(___, ___)  \n\n\n\n\nExercise 4\nWhat is the most important feature in making predictions? Why do you think this is?\nCreate a table that shows the feature importances in descending order. The random forest classifier has a feature importances attribute. It can be accessed by rf.feature_importances_. The table should look something like this.\n\n\n\nfeature names\nimportances\n\n\n\n\nfare\n0.288051\n\n\nsex\n0.281853\n\n\nage\n0.266491\n\n\npclass\n0.0814224\n\n\nsiblings_spouses_aboard\n0.0475633\n\n\nparents_children_aboard\n0.034619\n\n\n\n\n\n\n\n\n\n\nNoteAfter you have completed this skill builder with your team (or on your own) then compare your work to our script\n\n\n\n\n\nSee the script.",
    "crumbs": [
      "Project 4: Machine Learning"
    ]
  },
  {
    "objectID": "Skill Builders/introduction.html",
    "href": "Skill Builders/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "This should be able to be finished within 60 minutes. You should work through it on your own or in a group based in your professors instruction. This serves as an assessment of your understanding of the assigned readings.",
    "crumbs": [
      "Project 0: Introduction"
    ]
  },
  {
    "objectID": "Skill Builders/introduction.html#skill-builder",
    "href": "Skill Builders/introduction.html#skill-builder",
    "title": "Introduction",
    "section": "",
    "text": "This should be able to be finished within 60 minutes. You should work through it on your own or in a group based in your professors instruction. This serves as an assessment of your understanding of the assigned readings.",
    "crumbs": [
      "Project 0: Introduction"
    ]
  },
  {
    "objectID": "Skill Builders/introduction.html#before-you-start",
    "href": "Skill Builders/introduction.html#before-you-start",
    "title": "Introduction",
    "section": "Before You Start",
    "text": "Before You Start\nMake sure you have installed VS-code, pandas, and plotly express on your computer. You can install these package by typing this line in the terminal.\npip install pandas plotly.express\nOR if you have more than one version of python\npip3.10 install pandas plotly.express\npip3.10 indicates the version of python you are installing the packages to.\n\n\nGet Familiar With Your Tools\nProgramming involves a lot of research. Unlike subjects like Mathematics or History, we are not required to remember every single function and its usage. It is natural for experienced programmers to look for answers on the internet, books, even from other people’s code. Programming will be extremely frustrating if we are not allowed to do web searches, so please get familiar with the tools you have and use them often.\n\n\n\nOffical Documentation\nThis should be your first resort for understanding any code/function. Scanning the documentation of a function will allow you to get an overview of its usage.\nHere is a link to the documentation of the assign() function:\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html\nExample of assign() (as shown in the documentation)\n    import pandas as pd\n\n    df1 = pd.DataFrame({'temp_c': [17.0, 25.0]},\n                  index=['Portland', 'Berkeley'])\n    \n    df2 = df1.assign(temp_f=df1.temp_c * 9 / 5 + 32)\n\n\n\nExercise 1\nAfter reading the documentation for assign(), write a short paragraph to explain assign() as if you were talking to someone with zero programming experience (use the example above to help you explain assign()).\n\nWhat is the difference between df1 and df2?\nHow was df2 derived from df1?\n\n\nOnline Textbook\nIt pains us to see students would rather be stuck at problems for hours yet they refuse to use the textbook. This is another very useful resource since this is designed for this class. link to the textbook: https://byuidatascience.github.io/python4ds/\n\n\n\n\nExercise 2\nLocate the section where the textbook talks about query() and answer these questions.\n\nWhat function in R’s dplyr is equivalent or comparable to query() in pandas (You should include the section number in your answer)?\nWhat is the easiest mistake for python beginner to make that was shown in the text about query() (You should include the section number in your answer)?\n\n\nThe Internet\nGoogle is a programmer’s friend. Get used to googling thing, in fact, you want to be an expert in googling\n\nQuestion that cannot be answered by the textbook and documentation? Google it.\n\nA function you have never seen before? Google it.\nAn error in your code? Google it.\n\n\n\n\n\nExercise 3\nProvide at least 2 extra resources you could find about the pandas function drop() on the internet.\n\nTutor, TA (Through Slack, Zoom, or In-Person)\nWe want to help you with your work; we want to answer your questions; but most importantly, we want to help you succeed in this class. That will require you to put in the necessary time in understanding the readings, coding and debugging. When you ask us a question, we expect that you have read the documentation, searched the textbook, and done your own research. Then we can be most helpful and can provide insights on top of your understanding.\n\n\nExamples of Bad Questions\n\nHow does drop() work? We will ask you to read the documentation for drop().\nHow do you make a table in a markdown file? We will refer you to the textbook.\nI don’t want these columns in my data, how can I drop them? We will ask you if you have found any things on the internet.\n\n\n\nExamples of good questions\n\nI am still confused about the syntax of drop(). After reading the documentation, this is my understanding of the function… . What am I missing?\nI tried making a table in markdown (show code), it is still not giving me what I want, how can I fix this?\nI am trying to drop these columns in my dataframe, I think drop() is what I am looking for. Am I in the right direction? If not, what keywords should I be googling?\n\n\n\n\n\nExercise 4\nUsing the code and tools mentioned above, finish question 4 and 5 under 3.2.4 in the textbook.(use the data in mpg for your plot):\n# library import\nimport pandas as pd \nimport plotly.express as px\n\n# data import\nurl = \"https://github.com/byuidatascience/data4python4ds/raw/master/data-raw/mpg/mpg.csv\"\n\nmpg = pd.read_csv(url)\n\nQuestion 4: Make a scatterplot of hwy vs cyl.\nQuestion 5: What happens if you make a scatterplot of class vs drv? Why is the plot not useful?\n\n\n\n\n\n\n\n\nNoteAfter you have completed this skill builder with your team (or on your own) then compare your work to our script\n\n\n\n\n\nSee the script.",
    "crumbs": [
      "Project 0: Introduction"
    ]
  },
  {
    "objectID": "Setup/vs_code_setup.html",
    "href": "Setup/vs_code_setup.html",
    "title": "VS Code for Data Science",
    "section": "",
    "text": "Download and Install Visual Studio Code\n\nUse the link below to download and install the latest version of VS Code:\n\nVS Code\n\n\n\nInstall VS Code Extensions\nUse these links to install the VS Code Extensions. Note: DO NOT install python when you install the python extension. You will install python from a different source in the next step.\n\nJupyter\nLive Share\nPython\nPylance\nQuarto\n\n\n\nLearn More About VS Code\nVS Code\n\n\nContinue to Install Quarto\nQuarto\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup",
      "VS Code"
    ]
  },
  {
    "objectID": "Setup/slack_setup.html",
    "href": "Setup/slack_setup.html",
    "title": "VS Code for Data Science",
    "section": "",
    "text": "Intro to Slack\n\n\n\nDownload and Install Slack\nUse the link below to download and install the latest version of Slack (both desktop and mobile):\n\nSlack for Windows\nSlack for Mac\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup",
      "Slack"
    ]
  },
  {
    "objectID": "Setup/python_setup.html",
    "href": "Setup/python_setup.html",
    "title": "Python for Data Science",
    "section": "",
    "text": "Download and Install Python\n\nFirst we need to confirm you dont already have python installed. Open a command prompt (win) or terminal (mac) and type python --version or python3 --version. If you see a version number, you already have python installed. If you see an error message, you need to install python. If the version you have is not the same as the one listed below you will still want to uninstall and install the correct version.\nHow to uninstall python on windows: - Open the Control Panel - Click on Programs - Click on Programs and Features - Find Python in the list of programs - Right click on Python or click on the … and select Uninstall\nHow to uninstall python on mac: - If it is python 3.10 or higher you should be fine to uninstall it. - Make sure it has a folder in your applications folder before uninstalling. - To uninstall simply drag the python folder to the trash. - If it does not have a folder in the applciations folder it will be much more difficult to uninstall. - Do not uninstall python 2.7 if you have it. We will not be using it but it is required for some system functions.\nWe need to download and install the latest version of python approved for this course. (Python 3.12)\nNote: [do not] install python from VS Code or the Microsoft Store or Anaconda Python.org is the only place you should install VS Code from (link below)\n\nPython\n\n\nInstall Python on Windows\nMake sure to check the box that says Add Python to PATH before clicking Install Now. Sometimes it is phrased as Add Python to environment variables. Failture to do so will cause issues with the quarto install process. \n\n\nContinue to Install Python Libraries\nInstall Python Libraries\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup",
      "Python"
    ]
  },
  {
    "objectID": "Setup/git_github_setup.html",
    "href": "Setup/git_github_setup.html",
    "title": "Git and GitHub for DS",
    "section": "",
    "text": "Note: Changes have been made to this course since the video was recorded. The video is still relevant and will be updated in the future to reflect the changes. For conflicts of the video and the text, the text is the most current.\n\n\n\nSetup Git and GitHub\n\nGitHub will be used for publishing all projects\n\nInstall git on your computer\n\nWindows Installation Note: Keep all settings as default during installation\nMac Installation\nNote: Mac users can install git using homebrew by running brew install git in the terminal. You will need to install homebrew first if you don’t have it\n\nCreate a GitHub Account with your BYUI-I email.\n\nUse an appropriate username. It will be the name of your public profile and website in Project 6.\nIf you already have a GitHub account, you can add your BYUI-I email to your existing account. Go to Settings -&gt; Emails -&gt; Add email address and make it your primary email.\n\nInstall GitHub Desktop\nGit a Course Work Portfolio in GitHub\n\nUse the Portfolio Template in Data Science GitHub repo\n\nNavigate to the Course Work Portfolio in GitHub\n\nClick the Green Button Use this template and select Create a new repository\n\nCheck the box to Include all branches\n\n\nSelect byui-math-dept as the Owner You should have been added to byui-math-dept by your teacher if you dont see it ask them to add you. This Org uses SSO with BYUI, if you dont have your BYUI email in your GitHub account you need to add it (account -&gt; settings -&gt; emails -&gt; add email address) If you have performed all these steps and still dont see it look for a badge above Repository template that states Single sign-on to see results in the byui-math-dept organization. Follow that link to sign in with SSO then you will be able to choose byui-math-dept as the Owner\n\n\nName the repository as your GitHub username + _ + the current semester and yearall lowercase (see example in image above)\n\nSelect Private as the type of Repo, then click Create Repository\n\n\nClone the repository to your computer\n\nClick the &lt;&gt; Code menu\nClick the Green Button &lt;&gt; Code and select Open with GitHub Desktop\n\n\nClick the Button Open in Visual Studio Code \n\nIf it asks for a username and password, this is because your GitHub Desktop is not logged in to your GitHub account via SSO. Log out of your account in GitHub Desktop, be logged in in your browser to GitHub and make sure you can access the byui-math-dept org where you cloned your new portfolio. Then repete these instructions. It will log you back in to GitHub Desktop but this with with the SSO credentials\n\n\nIf you forgot to Check the box to Include all branches in the previous step (otherwise skip to the next step): Create a new branch gh-pages\n\nCreate a new branch gh-pages\n\nClick the Branch: main button then view all branches\n\nClick the New Branch button\n\nName the branch gh-pages and click the Green Button Create new branch\n\n\nModify Pages Settings for Build and deployment from main to gh-pages:\n\nClick the Settings tab\n\nScroll down to the Pages section in the left hand menu\n\nLocate the Build and deployment section and change Branch from main to gh-pages and leave the right side as /root\n\n\n\nUpdate the _quarto.yml file in course work portfolio:\n\nupdate the title to includ your name\nupdate the site url to your published site url (this will be in the deployment section in GitHub)\nupdate the repo-url to your GitHub repository url\nupdate the issue-url to your GitHub issue url (its the same as the repo url but with /issues/new at the end)\nupdate the page-footer left to include your name (line 15)\nupdate the page-footer right href to include your LinkedIn url (line 18 - optional)\nScroll to the bottom and change the theme light: and/or dark: to another theme (optional)\n\nCommit and Push the changes made to GitHub\n\nPush the changes to GitHub via GitHub Desktop\n\nMake sure you have the correct repo selected in the top left\n\n\nType a commit message and click the Blue Button Commit to main\n\n\nClick the Blue Button Push origin\n\n\nIf it gives you a big long error when you push, this is because your GitHub Desktop is not logged in to your GitHub account via SSO. Log out of your account in GitHub Desktop, and log right back in\n\nConfirm the GitHub Actions are working\n\nNavigate to the repo in GitHub and click on the Actions tab\n\nConfirm the Update _quarto.yml is working by the yellow circle turning to a green check circle (Note: this can take 3-5min)\n\n\n\nFix for a common bug\n\nFix for the main page loading the ReadMe.md file instead of the portfolio website\n\nRun quarto publish gh-pages in the terminal of VS Code\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup",
      "Git and Github"
    ]
  },
  {
    "objectID": "Setup/aws_setup.html",
    "href": "Setup/aws_setup.html",
    "title": "AWS Virtual Machine Setup",
    "section": "",
    "text": "Prerequisites\nIf you want to use a AWS Academy VM for this course, you will need to have an AWS Educate account. Please email the admin for with the subject line “AWS Educate Account Request” and include your full name and course code. You will receive an email from AWS Educate with instructions on how to create an account.\n\n\nAWS Virtual Machine Setup\nWatch and follow the two videos, and or follow along with the AWS Virtual Machine Creation Document. Copy paste code from the cell below.\n\n\n\n\nSetup AWS Documentation\n\nAWS Virtual Machine Creation\n\n\n\nCopy Paste Code Block\ngit clone https://github.com/byui-bwh/db-workstation-automation.git \n\ncd db-workstation-automation/\n\n. ./provision_vm.sh\n\n\nClone this GitHub Repository\ncd Desktop\ngit clone https://github.com/NicholasBoss/clarkstudents24.git\n\n\nInstalling GitHub Desktop\n\nOpen the Repo just cloned in Visual Studio Code\nNavigate through code to week 2 and open the root.py file\nRun the code in the root.py file by pressing the play button in the top right corner of the file\n\nWhen asked to run the GitHub desktop script answer y\nWhen asked to run the file setup script answer n\nClose the file\n\n\n\n\nInstalling Quarto CLI\n\nNavigete to the Quarto CLI website for Linux\n\nRun all the termainal commands on the site in the terminal in the AWS instance\n\n\n\n\nInstalling the Quarto VS Code Extension\n\nOpen Visual Studio Code\nClick on the Extensions icon in the left side bar\nSearch for Quarto in the search bar\nClick the Install button on the Quarto extension\nClose the Extensions tab\n\n\n\nInstall Python Libraries\n\nOpen the terminal in Visual Studio Code\nRun the following command to install the required Python libraries\n\npip install numpy pandas scikit-learn plotly.express nbformat nbclient pyyaml jupyter\n\n\nInstall Other VS Code Extensions\n\nJupyter\nLive Share\nPython\nPylance\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup",
      "AWS VM (Optional)"
    ]
  },
  {
    "objectID": "Projects/unit5_task4.html",
    "href": "Projects/unit5_task4.html",
    "title": "Project 5: To Infinity and Beyond…wait wrong movie",
    "section": "",
    "text": "Background\nSurvey data is notoriously difficult to munge. Even when the data is recorded cleanly the options for ‘write in questions’, ‘choose from multiple answers’, ‘pick all that are right’, and ‘multiple choice questions’ makes storing the data in a tidy format difficult.\nIn 2014, FiveThirtyEight surveyed over 1000 people to write the article titled, America’s Favorite ‘Star Wars’ Movies (And Least Favorite Characters). They have provided the data on GitHub.\nFor this project, your client would like to use the Star Wars survey data to figure out if they can predict an interviewing job candidate’s current income based on a few responses about Star Wars movies.\n\n\nClient Request\nThe Client is who performed the survey but outsourced the analitics to a 3rd party. They want you to clean up the data so you can: a. Validate the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article a. Predict if a person from the survey makes at least $50k\n\n\nData\nURL: StarWars.csv\nInformation: Article\n\n\nReadings\nNo new readings\n\n\nQuestions\n\nBuild a machine learning model that predicts whether a person makes at least $50k with accuracy of at least 65%. Describe your model and report the accuracy.\nValidate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.\nCreate a new column that converts the location groupings to a single number (a.k.a. label encoding). Drop the location categorical column.\n\n\n\nSubmission / Deliverables:\nRather than submitting something for each task of this unit, you will submit one client report at the end of the unit that is the culmination of all the tasks. Use this template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables. Be sure to state in your executive summary whether you completed the stretch or not.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit5_task2.html",
    "href": "Projects/unit5_task2.html",
    "title": "Project 5: Recoding Range Variables",
    "section": "",
    "text": "Background\nSurvey data is notoriously difficult to munge. Even when the data is recorded cleanly the options for ‘write in questions’, ‘choose from multiple answers’, ‘pick all that are right’, and ‘multiple choice questions’ makes storing the data in a tidy format difficult.\nIn 2014, FiveThirtyEight surveyed over 1000 people to write the article titled, America’s Favorite ‘Star Wars’ Movies (And Least Favorite Characters). They have provided the data on GitHub.\nFor this project, your client would like to use the Star Wars survey data.\n\n\nClient Request\nThe Client is who performed the survey but outsourced the analitics to a 3rd party. They want you to clean up the data so you can ultimately run a machine learning model.For this task, complete the items in the Questions section below.\n\n\nData\nURL: StarWars.csv\nInformation: Article\n\n\nReadings\nNo new readings. Review previous readings as needed:\n\nBYUI DS Programming: CH12 Tidy Data\nP4DS: CH16 Numbers\nVideo on regular expression\nP4DS: CH17 Strings and Text\nP4DS: Ch18 Regular Expressions\n\n\n\nQuestions\n\nClean and format the data so that it can be used in a machine learning model. As you format the data, you should complete each item listed below. In your final report provide an excerpt of the reformatted data with a short description of the changes made.\n\nCreate a new column that converts the age ranges to a single number. Drop the age range categorical column\n\nCreate a new column that converts the education groupings to a single number. Drop the school categorical column\n\nCreate a new column that converts the income ranges to a single number. Drop the income range categorical column\n\nCreate your target (also known as “y” or “label”) column to indicate whether a person had a Household Income $50,000 or greater\n\nEncode favorability ratings as a number. Remove the favorability categorical columns.\nOne-hot encode all remaining categorical columns\n\n\n\n\nSubmission / Deliverables:\nRather than submitting something for each task of this unit, you will submit one client report at the end of the unit that is the culmination of all the tasks. Use this template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit5_task1.html",
    "href": "Projects/unit5_task1.html",
    "title": "Project 5: The war with Star Wars",
    "section": "",
    "text": "Background\nSurvey data is notoriously difficult to munge. Even when the data is recorded cleanly the options for ‘write in questions’, ‘choose from multiple answers’, ‘pick all that are right’, and ‘multiple choice questions’ makes storing the data in a tidy format difficult.\nIn 2014, FiveThirtyEight surveyed over 1000 people to write the article titled, America’s Favorite ‘Star Wars’ Movies (And Least Favorite Characters). They have provided the data on GitHub.\nFor this project, your client would like to use the Star Wars survey data to figure out if they can predict an interviewing job candidate’s current income based on a few responses about Star Wars movies.\n\n\nClient Request\nThe Client is who performed the survey but outsourced the analitics to a 3rd party. They want you to clean up the data so you can: a. Validate the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article a. Predict if a person from the survey makes at least $50k\n\n\nData\nURL: StarWars.csv\nInformation: Article\n\n\nReadings\n\nBYUI DS Programming: CH12 Tidy Data\nP4DS: CH16 Numbers\nVideo on regular expression\nP4DS: CH17 Strings and Text\nP4DS: Ch18 Regular Expressions\n\n\n\nQuestions\n\nShorten the column names and clean them up for easier use with pandas. Provide a table or list that exemplifies how you fixed the names.\nFilter the dataset to 835 respondents that have seen at least one film (Hint: Don’t use the column Have you seen any of the 6 films in the Star Wars franchise?)\nValidate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article. These visuals should be similar, including titles, subtitles, gridlines, order of categories, colors, etc. But, they don’t have to be exact. They need to be close enough that we can validate that the values in the dataset match the graphs in the chart. Though their charts were built using a different plotting software, the more you push yourself for an exact replica, the more you will learn. Spend at least a couple of hours on this.\n\n\n\nSubmission / Deliverables:\nRather than submitting something for each task of this unit, you will submit one client report at the end of the unit that is the culmination of all the tasks. Use this template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit4_task3.html",
    "href": "Projects/unit4_task3.html",
    "title": "Unit 4, Task 3: Show me",
    "section": "",
    "text": "Background\nThe clean air act of 1970 was the beginning of the end for the use of asbestos in home building. By 1976, the U.S. Environmental Protection Agency (EPA) was given authority to restrict the use of asbestos in paint. Homes built during and before this period are known to have materials with asbestos You can read more about this ban.\nThe state of Colorado has a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\nColorado gave you home sales data for the city of Denver from 2013 on which to train your model. They said all the column names should be descriptive enough for your modeling and that they would like you to use the latest machine learning methods.\n\n\nClient Request\nThe Client is a state agency in Colorado that is responsible for the health and safety of its residents. They have a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\n\n\nData\nURL: dwellings_ml.csv (ml ready)\nOptional URL: dwellings_neighborhoods_ml.csv (ml ready)\nInformational URL: dwellings_denver.csv (not cleansed)\nInformation: Data description\n\n\nReadings\nNo new readings. Consider reviewing the past readings as needed:\n\nMachine Learning Introduction\nA visual introduction to machine learning\nCalculate model accuracy in scikit-Learn\nA few popular models to choose from, and a review of Machine Learning workflow\nHow to choose a good evaluation metric for your Machine learning model\nIdentify and graph feature importance (especially method 1)\nExhaustive list of classifiers in scikit-Learn (skim)\n\n\nOptional References\n\nPros and cons of popular classifiers\nAnother overview and description of pros and cons for popular classifiers and regression models\nDecision Tree Classification in Python\n\nBoosted algorithms in scikit-learn\nscikit-plot package\n\n\n\n\nQuestions\n\nCreate 2-3 charts that evaluate the relationships between each of the top 2 or 3 most important variables (as found in Unit 4 Task 2) and the year the home was built. Describe what you learn from the charts about how that variable is related to year built.\nCreate at least one other chart to examine a variable(s) you thought might be important but apparently was not. The chart should show its relationship to the year built. Describe what you learn from the chart about how that variable is related to year built. Explain why you think it was not (very) important in the model.\n\n\n\nSubmission / Deliverables:\nUse this unit4_task3_template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit4_task1.html",
    "href": "Projects/unit4_task1.html",
    "title": "Unit 4, Task 1: Can You Predict That?",
    "section": "",
    "text": "Background\nThe clean air act of 1970 was the beginning of the end for the use of asbestos in home building. By 1976, the U.S. Environmental Protection Agency (EPA) was given authority to restrict the use of asbestos in paint. Homes built during and before this period are known to have materials with asbestos You can read more about this ban.\nThe state of Colorado has a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\nColorado gave you home sales data for the city of Denver from 2013 on which to train your model. They said all the column names should be descriptive enough for your modeling and that they would like you to use the latest machine learning methods.\n\n\nClient Request\nThe Client is a state agency in Colorado that is responsible for the health and safety of its residents. They have a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\n\n\nData\nURL: dwellings_ml.csv (ml ready)\nOptional URL: dwellings_neighborhoods_ml.csv (ml ready)\nInformational URL: dwellings_denver.csv (not cleansed)\nInformation: Data description\n\n\nReadings\n\nMachine Learning Introduction\nA visual introduction to machine learning\nCalculate model accuracy in scikit-Learn\nA few popular models to choose from, and a review of Machine Learning workflow\n\n\nOptional References\n\nDecision Tree Classification in Python\n\nBoosted algorithms in scikit-learn\nscikit-plot package\n\n\n\n\nQuestions\nBuild a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Report your final model choice and any other model parameters you may have tweaked (train-test split ratio, tuning parameters, etc).\n\n\nSubmission / Deliverables:\nUse this unit4_task1_template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit3_task3.html",
    "href": "Projects/unit3_task3.html",
    "title": "Project 3: If not now, when?",
    "section": "",
    "text": "Background\nDelayed flights are not something most people look forward to. In the best case scenario you may only wait a few extra minutes for the plane to be cleaned. However, those few minutes can stretch into hours if a mechanical issue is discovered or a storm develops. Arriving hours late may result in you missing a connecting flight, job interview, or your best friend’s wedding.\nIn 2003 the Bureau of Transportation Statistics (BTS) began collecting data on the causes of delayed flights. The categories they use are Air Carrier, National Aviation System, Weather, Late-Arriving Aircraft, and Security. You can visit the BTS website to read definitions of these categories.\n\n\nClient Request\nThe JSON file for this project contains information on delays at 7 airports over 10 years. Your task is to clean the data, search for insights about flight delays, and communicate your results to the Client. The Client is a CEO of a flight booking app who is interested in the causes of flight delays and wants to know which airports have the worst delays. They also want to know the best month to fly if you want to avoid delays of any length.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link” to use it to import the data into your project. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your .qmd file for it to work correclty in GitHub.\n\n\n\nURL: JSON File\nInformation: Data Description\nSubject Matter: Types of Delay\n\n\nReadings\n\nBYUI DS Programming CH15. - 15.2 Categorical data\n\n\nOptional References\n\nP4DS: CH19 Categories\n\n\n\n\nQuestions\nWhat is the best month to fly if you want to avoid delays of any length? Describe the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month.\n\n\nSubmission / Deliverables:\nUse this unit3_task3_template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit3_task1.html",
    "href": "Projects/unit3_task1.html",
    "title": "Project 3: Missing Data & JSON",
    "section": "",
    "text": "Background\nDelayed flights are not something most people look forward to. In the best case scenario you may only wait a few extra minutes for the plane to be cleaned. However, those few minutes can stretch into hours if a mechanical issue is discovered or a storm develops. Arriving hours late may result in you missing a connecting flight, job interview, or your best friend’s wedding.\nIn 2003 the Bureau of Transportation Statistics (BTS) began collecting data on the causes of delayed flights. The categories they use are Air Carrier, National Aviation System, Weather, Late-Arriving Aircraft, and Security. You can visit the BTS website to read definitions of these categories.\n\n\nClient Request\nThe JSON file for this project contains information on delays at 7 airports over 10 years. Your task is to clean the data, search for insights about flight delays, and communicate your results to the Client. The Client is a CEO of a flight booking app who is interested in the causes of flight delays and wants to know which airports have the worst delays. They also want to know the best month to fly if you want to avoid delays of any length.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link” to use it to import the data into your project. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your .qmd file for it to work correclty in GitHub.\n\n\n\nURL: JSON File\nInformation: Data Description\nSubject Matter: Types of Delay\n\n\nReadings\n\nP4DS: CH21 Missing Values\nP4DS: Ch25.3 JSON\nConvert a pandas dataframe to JSON\n\n\nOptional References\n\nPython Data Science Handbook: Missing Data\nHandling Missing Data\nWikipedia Missing Data\nisin method\nwhere method\nnp.where method\nreplace method\nThe key word in ‘Data Science’ is not Data…\nLambda Function\n\n\n\n\nQuestions\nFix all of the varied missing data types in the data to be consistent: use np.nan to represent missing value. In your report include one record example (one row) from your clean data, in the raw JSON format. Your example should display at least one missing value so that we can verify it was done correctly. (Note: JSON will convert NaN’s to null). Describe your process for finding values that needed to be changed, and how you changed them.__\n\n\nSubmission / Deliverables:\nUse this unit3_task1_template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit2_task3_validation_in_py.html",
    "href": "Projects/unit2_task3_validation_in_py.html",
    "title": "Unit 2 Task 3: Joins",
    "section": "",
    "text": "Background\nWhen you hear the word “relationship” what is the first thing that comes to mind? Probably not baseball. But a relationship is simply a way to describe how two or more objects are connected. There are many relationships in baseball such as those between teams and managers, players and salaries, even stadiums and concession prices.\nThe graphs on Data Visualizations from Best Tickets show many other relationships that exist in baseball.\nIt is rare for an analysis to rely solely on one table. In fact, that is the whole point of a relational database: to quickly and easily tie tables together. Many students have already learned how to join tables using SQL. This assignment gives you practice joining tables using Python Pandas code. Students inevitably ask, “if I can do the same thing in both languages, why/when would I chose one over the other?”. This thread has some good thoughts on the topic.\n\n\nClient Request\nFor this project you will use Python pandas code to join (a.k.a. merge) tables and perform additional manipulations. You will still need to connect to the database to pull the data in, but all the filtering, calculating, joining, etc. should be done with Python pandas (or polars).\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis project will use the Lahman Baseball Database. In order to complete this project, you will need to download the database and save it inside the DS250 folder (hopefully you have a folder dedicated to this class) next to the .qmd file you will be using for this assignment. Note: Right click the ‘Download’ link and select “Save Link As” to download the data to your computer.\n\n\n\nDownload: lahmansbaseballdb\nInformation: Lahman Data Dictionary\nSetup Instructions: See SQL Setup\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nComplete these readings before we cover the material in class. This will help you retain the material and make the class period more engaging - not less.\nIn other words, if an assignment is due on Wednesday, we will cover the material needed to complete the assignment on Tuesday. Therefore, you should complete the readings on Monday (or anytime before class on Tuesday).\n\n\n\n\nP4DS: CH22 Joins\n\nOptional\n\nP4DS: CH13 Exploratory Data Analysis Skim to see many different possible geoms to use depending on the data types and to see some of the commands from CH4 again.\n[P4DS: CH4 Data Transformation](https://aeturrell.github.io/python4DS/data-transform.html#) as review\n\n\n\nQuestions and Tasks\nDownload the template for this task.\n\nWrite an SQL query that pulls in the the salaries table and the collegeplaying table (and any other tables you might need) and store them in pandas dataframes. Combine the dataframes to create a list of baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID and teamID associated with each salary.\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Be creative! Write an SQL query to read in the table(s) you need, then use pandas to manipulate the data. Finally, make a graph using Lets-Plot to visualize the comparison. What do you learn?\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop this assignment into the terminal. This will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\nUse this task’s template to submit your Client Report.\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit2_task2.html",
    "href": "Projects/unit2_task2.html",
    "title": "Unit 2 Task 2: Basic aggregation and wrangling",
    "section": "",
    "text": "Background\nHow do you know if you have correctly programmed a query or an analysis? The process of confirming that your analysis or dataset is “correct” is called validation.\nImagine you are new on the job and received the assignment to run queries on a baseball dataset. Confirming you did things correctly is a good idea before presenting your data to others and letting them discover your mistake. Or maybe, it isn’t a matter of you doing something wrong as just a realization that the data source is flawed. Making that discovery is very important and makes you look really good; as opposed to someone else discovering it later - which can be a big hit to your credibility.\nConsider all the various ways you might want to validate the query results. One way to validate, though certainly not the only way and not necessarily the best way, is to try to accomplish the same task in a different system or language. That’s the purpose of this assignment.\nThis assignment may also help you connect how data wrangling is done in Python with a language you are already familiar with (SQL).\n\n\nClient Request\nFor this project, you will validate the assignments you have done previously, but this time using Python pandas code instead of complicated SQL queries. You will still need to connect to the database to pull the data in, but all the filtering, calculating, joining, etc. should be done with Python pandas (or polars).\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis project will use the Lahman Baseball Database. In order to complete this project, you will need to download the database and save it inside the DS250 folder (hopefully you have a folder dedicated to this class) next to the .qmd file you will be using for this assignment. Note: Right click the ‘Download’ link and select “Save Link As” to download the data to your computer.\n\n\n\nDownload: lahmansbaseballdb\nInformation: Lahman Data Dictionary\nSetup Instructions: See SQL Setup\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nComplete these readings before we cover the material in class. This will help you retain the material and make the class period more engaging - not less.\nIn other words, if an assignment is due on Wednesday, we will cover the material needed to complete the assignment on Tuesday. Therefore, you should complete the readings on Monday (or anytime before class on Tuesday).\n\n\n\n\nP4DS: CH4 Data Transformation\n\n\n\nQuestions and Tasks\nDownload the template for this task.\n\nWrite an SQL query that pulls in the batting table. Then, with Python Pandas code create a dataframe that contains playerID, yearID, and batting average for players with at least 10 at bat that year. Sort the dataframe from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\nWrite an SQL query that pulls in the batting table. Then, with Python Pandas calculate the batting average for each player over their entire career (all years combined). Only include players with at least 100 at bats over their entire career. Sort the dataframe from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop this assignment into the terminal. This will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\nUse this task’s template to submit your Client Report.\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit1_task4.html",
    "href": "Projects/unit1_task4.html",
    "title": "Unit 1 Task 4: Elliot",
    "section": "",
    "text": "Background\nEarly in prehistory, some descriptive names began to be used again and again until they formed a name pool for a particular culture. Parents would choose names from the pool of existing names rather than invent new ones for their children.\nWith the rise of Christianity, certain trends in naming practices manifested. Christians were encouraged to name their children after saints and martyrs of the church. These early Christian names can be found in many cultures today, in various forms. These were spread by early missionaries throughout the Mediterranean basin and Europe.\nBy the Middle Ages, the Christian influence on naming practices was pervasive. Each culture had its pool of names, which were a combination of native names and early Christian names that had been in the language long enough to be considered native. [ref]\n\n\nClient Request\nThis csv file contains the number of times a name was given to a child in a specific year. The Client has a passion for names throughout history. They would like to know how the usage of names has changed over time. They are particularly interested in the names Mary, Martha, Peter, and Paul. They would also like to know how the usage of a name from a famous movie has changed over time.\n\n\nData\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link”. You can use that copied URL in your code to read in the data. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your quarto file for the assignment in order for it to work correclty in GitHub.\nURL: names_year.csv\nInformation: data.md\n\n\nReadings\nNo new readings. Review the previous readings as needed\n\nPandas Tutorial 1: What kind of data does pandas handle?\nPandas Tutorial 2: How do I read and write tabular data?\nPandas Tutorial 3: How do I select a subset of a DataFrame?\nP4DS: Chapter 4.3 Manipulating rows in data frames\nP4DS: Chapter 11 Visualisation\nP4DS: Chapter 12.1 - 12.3 Layers: Aesthetic mappings and geometries\nP4DS: Chapter 14.2 - 14.3 Labels, titles, contextual info, annotations\n\nOptional Readings:\n\nP4DS: Rest of Chapter 12\nP4DS: Rest of Chapter 14\n\n\n\nQuestions and Tasks\nHere is an example Stretch question(s) for this project. You can may propose your own idea for a stretch task that you are interested in that would take a similar level of effort and practice a similar set of skills. If you propose a different task, be sure to get it approved by your instructor first.\n\nReproduce the chart Elliot using the data from the names_year.csv file. If, after a couple of hours, you can get the chart close, but not exactly the same, that is okay. You will learn more to the degree you push yourself.\n\n\nNote: There is no template for this task. You will have to create a new file from scratch as part of this stretch.\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the assignment open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the file but also the entire course work portfolio into HTML files for review\nConfirm everything displays as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop the assignment into the terminal, this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\n\n\n\n\n\n\nNote\n\n\n\n\n\nDeliverables are “the quantifiable goods or services that must be provided upon the completion of a project”. In this class the deliverable for each project is a .html file report created using Quarto files. This final section will be the same for each project.\n\n\n\nNo template is provided. Create a new quarto file for this assignment. It is part of stretching yourself.\n\nAnswers to the questions | tasks.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit1_task2.html",
    "href": "Projects/unit1_task2.html",
    "title": "Unit 1 Task 2: You and Brittany",
    "section": "",
    "text": "Background\nEarly in prehistory, some descriptive names began to be used again and again until they formed a name pool for a particular culture. Parents would choose names from the pool of existing names rather than invent new ones for their children.\nWith the rise of Christianity, certain trends in naming practices manifested. Christians were encouraged to name their children after saints and martyrs of the church. These early Christian names can be found in many cultures today, in various forms. These were spread by early missionaries throughout the Mediterranean basin and Europe.\nBy the Middle Ages, the Christian influence on naming practices was pervasive. Each culture had its pool of names, which were a combination of native names and early Christian names that had been in the language long enough to be considered native. [ref]\n\n\nClient Request\nThis csv file contains the number of times a name was given to a child in a specific year. The Client has a passion for names throughout history. They would like to know how the usage of names has changed over time. They are particularly interested in the names Mary, Martha, Peter, and Paul. They would also like to know how the usage of a name from a famous movie has changed over time.\n\n\nData\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link”. You can use that copied URL in your code to read in the data. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your quarto file for the assignment in order for it to work correclty in GitHub.\nURL: names_year.csv\nInformation: data.md\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nComplete these readings before we cover the material in class. This will help you retain the material and make the class period more engaging - not less.\nIn other words, if an assignment is due on Wednesday, we will cover the material needed to complete the assignment on Tuesday. Therefore, you should complete the readings on Monday (or anytime before class on Tuesday).\n\n\n\n\nP4DS: Chapter 11 Visualisation\nP4DS: Chapter 12.1 - 12.3 Layers: Aesthetic mappings and geometries\nP4DS: Chapter 14.2 - 14.3 Labels, titles, contextual info, annotations\n\nOptional Readings:\n\nP4DS: Rest of Chapter 12\nP4DS: Rest of Chapter 14\n\n\n\nQuestions and Tasks (Core)\nDownload this Unit 1 Task 2 Template template. The answer to each question should include a chart and a written response. The years labels on your charts should not include a comma. At least one of your charts must include reference marks.\n\nHow does your name at your birth year compare to its use historically?\n\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the Unit1_Task2 template open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the file but also the entire course work portfolio into HTML files for review\nConfirm everything displays as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop unit1_task2.qmd into the terminal, this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\n\n\n\n\n\n\nNote\n\n\n\n\n\nDeliverables are “the quantifiable goods or services that must be provided upon the completion of a project”. In this class the deliverable for each project is a .html file report created using Quarto files. This final section will be the same for each project.\n\n\n\nUse this Unit1_Task2 template to submit your Client Report.\n\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, and any charts and/or tables.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/project_6.html",
    "href": "Projects/project_6.html",
    "title": "Project 6: Git Your DS Portfolio Online",
    "section": "",
    "text": "Walkthrough\n\n\n\nBackground\nGitHub is an online platform where data scientists and developers can communicate and share work. It has also morphed into a tool to house all your work in a portfolio. Think about an Art student and how they have to develop their portfolio of various skills they have across the art classes. Similarly you will want to showcase you skillset across the Data Science skillsets.\nAs students, you will want to curate your creative work on GitHub using a program called Git. GitHub is the place to share your original work, not your homework assignments. The reading assignments will dive deaper into what to include in your portfolio and what not to include.\nMany people store their personal websites, blogs, and project websites on GitHub. Our textbook and course are hosted on GitHub, and you can see J. Hathaway’s or Ryan Hafen’s personal Data Science websites that are hosted on GitHub as well.\nFor this project, you will be making a public website that is a data science portfolio that will be hosted on GitHub. Your Resume will be one section of your portfolio/website. You should also post Data Science Society projects, personal projects, and any other data science related work you have done outside of class. Do not post any of the DS250 course work in this portfolio.\n\n\nReadings\n\nGit and GitHub for DS\nPull and Merge Forks on GitHub\nNew to Git and GitHub? This Essential Beginners Guide is for you\nGit vs. GitHub: What is the difference between them?\nUsing Version Control in VS Code\nGit in Visual Studio Code video\n\n\n\nPortfolio Resources\n\nHow to Modify a Quarto Website\nHow to Create a Compelling GitHub Portfolio\nHow to Create a Professional Portfolio on GitHub\nData Science Portfolios That Will Get You the Job\n4 Data Science Portfolio Projects You Need to Create\nExample 1 - Data Science Portfolio\nExample 2 - Data Science Portfolio\n\n\n\nQuestions and Tasks\n\nGit a Data Science Portfolio in GitHub (main page)\n\nUse the Portfolio Template on your Githhub root directory\n\nNavigate to the Data Science Portfolio repo in GitHub.\nClick the Green Button Use this template and select Create a new repository\n\nClick include all branches checkbox, this will include the gh-pages branch\n\nSelect yourself as the Owner\n\nName the repository as username.github.io where the username is your username on GitHub (Note: If the username part of the repository doesn’t exactly match your username, it won’t work, so make sure to get it right.)\nClick the Green Button Create repository\n\n\nCreate a new branch gh-pages if you forgot to check the include all branches box (skip otherwise)\n\nClick the Branch: main button then view all branches\n\nClick the New Branch button\n\nName the branch gh-pages and click the Green Button Create new branch\n\n\nModify Pages Settings for Build and deployment from main to gh-pages:\n\nClick the Settings tab\n\nScroll down to the Pages section in the left hand menu\n\nLocate the Build and deployment section and change Branch from main to gh-pages and leave the right side as /root\n\n\nClone the repository to your computer\n\nClick the &lt;&gt; Code menu\nClick the Green Button &lt;&gt; Code and select Open with GitHub Desktop\n\nClick the Button Open in Visual Studio Code \n\nUpdate the _quarto.yml file\n\nChange the title to your name\nChange the repo-url to your code repository url\nChange the page-footer left: to your name\nChange the page footer href: to your LinkedIn profile link\nScroll to the bottom and change the theme light: and/or dark: to another theme (optional)\n\nPush the changes to GitHub via GitHub Desktop\n\nMake sure your current repo in the top left is username.github.io\n\nType a commit message and click the Blue Button Commit to main\n\nClick the Blue Button Push origin\n\n\nConfirm the GitHub Actions are working\n\nNavigate to the repo in GitHub and click on the Actions tab\n\nConfirm the Update _quarto.yml is working by the yellow circle turning to a green check circle (Note: this can take 3-5min)\n\n\nFix the main page loading the ReadMe.md file\n\nRun quarto publish gh-pages in the terminal of VS Code\n\n\nGit your Resume in your Portfolio\n\n\nUpdate the resume.qmd file in course work portfolio to include your updated resume using markdown. See P4DS: CH30 Markdown\n\n\nPush your results to GitHub with GitHub Desktop.\n\n\n\n\nDeliverables:\n\nComplete the questions\n\nSubmit a URL link to your portfolio.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 6: Git Your Portfolio Online"
    ]
  },
  {
    "objectID": "Projects/project_4.html",
    "href": "Projects/project_4.html",
    "title": "Project 4: Can You Predict That?",
    "section": "",
    "text": "Walkthrough\n\n\n\nBackground\nThe clean air act of 1970 was the beginning of the end for the use of asbestos in home building. By 1976, the U.S. Environmental Protection Agency (EPA) was given authority to restrict the use of asbestos in paint. Homes built during and before this period are known to have materials with asbestos You can read more about this ban.\nThe state of Colorado has a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\nColorado gave you home sales data for the city of Denver from 2013 on which to train your model. They said all the column names should be descriptive enough for your modeling and that they would like you to use the latest machine learning methods.\n\n\nClient Request\nThe Client is a state agency in Colorado that is responsible for the health and safety of its residents. They have a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\n\n\nData\nURL: dwellings_ml.csv (ml ready)\nOptional URL: dwellings_neighborhoods_ml.csv (ml ready)\nInformational URL: dwellings_denver.csv (not cleansed)\nInformation: Data description\n\n\nReadings\n\nMachine Learning Introduction (Skim)\nA visual introduction to machine learning (Read)\nP4DS: CH22 Joins (Read)\nHow to choose a good evaluation metric for your Machine learning model (Skim)\n\n\nOptional References\n\nDecision Tree Classification in Python\n\nBoosted algorithms in scikit-learn\nscikit-plot package\n\n\n\n\nQuestions and Tasks (Core)\n\nCreate 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.\nBuild a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.\nJustify your classification model by discussing the most important features selected by your model. This discussion should include a feature importance chart and a description of the features.\nDescribe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.\n\n\n\nQuestions and Tasks (Stretch)\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis section lists the questions and tasks that need to be completed for the project. Your work on the project must be compiled into a report, rendered to HTML file in a Course Portfolio a link to that project page uploaded in Canvas.\nThere are two types of questions: Core and Stretch. Core questions are required for each project. The course syllabus competencies requires specic a number of projects having all the Stretch questions achived based on your goals for the grade level you are seeking.\n\n\n\nHere is an example Stretch question(s) for this project. Your instructor may assign different Stretch question(s). You must comment in Canvas when submitting your project if you completed any of the Stretch questions.\n\nRepeat the classification model using 3 different algorithms. Display their Feature Importance, and Decision Matrix. Explian the differences between the models and which one you would recommend to the Client.\nJoin the dwellings_neighborhoods_ml.csv data to the dwelling_ml.csv on the parcel column to create a new dataset. Duplicate the code for the stretch question above and update it to use this data. Explain the differences and if this changes the model you recomend to the Client.\nCan you build a model that predicts the year a house was built? Explain the model and the evaluation metrics you would use to determine if the model is good.\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the Course Work Portfolio open in VS Code and open Projects/Project4.qmd\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\nDeliverables:\nUse this P4_template to submit your Client Report. The template has two sections:\n\nA short elevator pitch that highlights key values or metrics from the results. Describing these key insights to interest or hook the reader to want to read more about your work. The writing style should be more technical with some creative elements. Do not summarize what you did.\n\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\nA short summary of work must be submitted in the comments in Canvas wwhen you submit the URL. Rate your own work on a scale of 1-5. 1 being poor and 5 being excellent. Include a short description of why you rated your work the way you did.\n\n\n\nFeedback:\n\n\n\n\n\n\nNote\n\n\n\n\n\nYou will recieve feedback and/or coaching notes in the form of a GitHub issue. You will need to address the feedback, re-render and resubmit the project, and mark the GitHub issue as closed.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 4: Can You Predict That?"
    ]
  },
  {
    "objectID": "Projects/project_2.html",
    "href": "Projects/project_2.html",
    "title": "Project 2: Finding Relationships in Baseball",
    "section": "",
    "text": "Walkthrough\n\n\n\nSQL Refresher\n\n\n\nSetup\nSQL setup and test\n\n\nBackground\n\n\n\n\n\n\nNote\n\n\n\n\n\nWe will complete six projects during the semester that each take about two weeks (four days of class). On average, a student will spend 2 hours outside of class per hour in class to complete the assigned readings, submit any Canvas items, and complete the project (for a total of 8 hours per project). The instruction for each project will be structured into sections as written on this page.\nThis first Background section provides context for the project. Make sure you read the background carefully to see the big picture needs and purpose of the project.\n\n\n\nWhen you hear the word “relationship” what is the first thing that comes to mind? Probably not baseball. But a relationship is simply a way to describe how two or more objects are connected. There are many relationships in baseball such as those between teams and managers, players and salaries, even stadiums and concession prices.\nThe graphs on Data Visualizations from Best Tickets show many other relationships that exist in baseball.\n\n\nClient Request\nFor this project, the Client wants SQL queries that they can use to retrieve data for use on their website without needing Python. They would also like to see the results in Lets-Plot charts.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Project 3 will use the Lahman Baseball Database. You will need to download the database and set it up on your computer to complete the project. Place it inside the DS250 Projects folder within your repository next to the project_3.qmd file. Note: Right click the ‘Download’ link and select “Save Link As” to download the data to your computer.\n\n\n\nDownload: lahmansbaseballdb\nInformation: Lahman Data Dictionary\nSetup Instructions: See SQL Setup\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe Readings section will contain links to reading assignments that are required for each project, as well as optional references. Remember that you are reading this material to build skills. Take the time to comprehend the readings and the skills contained within.\nWe recommend reading through the assigned material once for a general understanding before the first day of each project. You will reread and reference the material multiple times as you complete the project.\n\n\n\n\nSQL Setup and References (Read)\nSQL for Data Science (Read)\n\n\nOptional References\n\nWhy SQL is beating NoSQL, and what this means for the future of data\n\n\n\n\nQuestions and Tasks (Core)\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis section lists the questions and tasks that need to be completed for the project. Your work on the project must be compiled into a report, rendered to a HTML file and uploaded in Canvas.\nThere are two types of questions: Core and Stretch. Core questions are required for each project. The course syllabus competencies requires specic a number of projects having all the Stretch questions achived based on your goals for the grade level you are seeking.\n\n\n\n\nDownload this Project2 Template template.\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats)\n\nWrite an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\n\nUse the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\n\nNow calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\n\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Lets-Plot to visualize the comparison. What do you learn?\n\n\n\nQuestions and Tasks (Stretch)\nHere is an example Stretch question(s) for this project. Your instructor may assign different Stretch question(s). You must comment in Canvas when submitting your project if you completed any of the Stretch questions.\n\nAdvanced Salary Distribution by Position (with Case Statement):\n\nWrite an SQL query that provides a summary table showing the average salary for players in each position (e.g., pitcher, catcher, outfielder) across all years. Include the following columns:\n\nposition\naverage_salary\ntotal_players\nhighest_salary\n\nThe highest_salary column should display the highest salary ever earned by a player in that position. If no player in that position has a recorded salary, display “N/A” for the highest salary.\nAdditionally, create a new column called salary_category using a case statement:\n\nIf the average salary is above $1 million, categorize it as “High Salary.”\n\nIf the average salary is between $500,000 and $1 million, categorize it as “Medium Salary.”\n\nOtherwise, categorize it as “Low Salary.”\n\nOrder the table by average salary in descending order.\nPrint the top 10 rows of this summary table.\n\nAdvanced Career Longevity and Performance (with Subqueries):\n\nCalculate the average career length (in years) for players who have played at least one game. Then, identify the top 10 players with the longest careers (based on the number of years they played). Include their:\n\nplayerID\nfirst_name\nlast_name\ncareer_length\n\nThe career_length should be calculated as the difference between the maximum and minimum yearID for each player.\n\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the P2_template open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop P2_template.qmd into the terminal this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\nUse this P2_template to submit your Client Report.\n\nA short elevator pitch that highlights key values or metrics from the results. Describing these key insights to interest or hook the reader to want to read more about your work. The writing style should be more technical with some creative elements. Do not summarize what you did.\n\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\nA short summary of work must be submitted in the comments in Canvas wwhen you submit the URL. Rate your own work on a scale of 1-5. 1 being poor and 5 being excellent. Include a short description of why you rated your work the way you did.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\nResubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nIf you submit before the due date, you will have one opportunity to resubmit the project after you have received feedback. The window for the resubmission will be open through the Wednesday following the due date of the project.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 2: Finding Relationships in Baseball"
    ]
  },
  {
    "objectID": "Projects/project_0_dp.html",
    "href": "Projects/project_0_dp.html",
    "title": "Project 0: Introduction",
    "section": "",
    "text": "Background\nEach assignment will have a Background section that provides context for the project. Make sure you read the background carefully to see the big picture needs and purpose of the project.\nPython and VS Code are tools commonly used in the field of data science. During our first two days of class we will primarily be installing software, libraries, extensions, etc. Completing Project 0 will set you up for success the rest of the semester. Since this project is strictly about software installation, there is no contextual background for this project.\n\n\nData\nThis project will use the Palmer Penguins data set. This dataset is embedded in a library we will load, so there is no need to read it in from the link below. But in future assignments, data for the assignment can be found in this section.\nURL: penguins data\n\n\nReadings\nPlease do the assigned before coming to class!\nMany people have different levels of experience with Python, VS Code, and programming in general. That is why there are so many and why skimming may be a good strategy for some students, but not for others.\n\nCourse Setup (Do)\nLearn about our Book Python for Data Science (Skim)\nPY4DS: First Steps (Skim)\nPY4DS: CH1 Whole Game (Skim)\nPY4DS: CH2 Data Visualization (Read)\nP4DS: CH30 Markdown (Read)\nP4DS: CH31 Quarto (Skim)\nQuarto Instructional Template for DS (Read)\n\n\nOptional References\n\nLearn about VS Code\nVS Code user interface\nReading Technical Documentation\n\n\n\n\nQuestions and Tasks\n\nDownload this Project0 Template. The template has working code for the Penguine data set. You need to finish the project by adding code to recreate charts from the book. More specifically, copy and paste code from the book into this template quarto file to:\n\nInclude the tables created from PY4DS: CH2 Data Visualization\n\nRecreate the example charts from PY4DS: CH2 Data Visualization of the textbook.\n\nFollow the instructions in the submission section below to submit your work\n\n\nThe main purpose of this project is to ensure your set-up and installations are done correctly. You will know this is the case if you can create an html file with those graphs and table in it.\n\n\nSubmission:\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the P0_template open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displays as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack #tutoring_lab channel)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop P0_template.qmd into the terminal this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer menu on the left side bar of VS Code and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\nDeliverables:\nUse this P0_template to submit your Client Report.\n\nThe template should include answers to the tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Course Materials/vs_code.html",
    "href": "Course Materials/vs_code.html",
    "title": "VS Code for Data Science",
    "section": "",
    "text": "Learn How to Install VS Code\nVS Code\n\n\n\nWhat if my interactive Python window in VS Code is not using the same version of Python as my terminal?\nYou can set your Python version in VS Code by opening a .py script and then clicking on the Python text in the bottom left corner as shown below.\n\nOnce you click, VS Code will open the command pallete where you can select your installation of Python that you would like to use with this workspace.\n\nThis setting will not fix what version your interactive Python window is using. You can get there by opening settings by using the ⌘, shortcut.\nYou can then search your settings for jupyter and you should see a section that has Jupyter Command Line Arguments. Click on the Edit in settings.json.\n\nHere you can set the jupyter path to Python to match the one you picked for your Terminal. An example for a Mac computer is shown below.\n\"python.pythonPath\": \"/usr/local/opt/python/bin/python3\",\n\n\n\nWhat if I am not able to read in files from the GitHub links using read_csv()?\nMost likely your Python SSl certificates are not installed. Follow the answer in this post.\n\n\n\nHow do I use VS Code to collaborate?”\nMicrosft’s Live Share extension documentation says, ‘Live Share enables you to quickly collaborate with a friend, classmate, or professor on the same code without the need to sync code or to configure the same development tools, settings, or environment.’ You can follow their guide or use our course created video.\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "VS Code"
    ]
  },
  {
    "objectID": "Course Materials/sql.html",
    "href": "Course Materials/sql.html",
    "title": "SQL for Data Science",
    "section": "",
    "text": "Learn How to Setup SQLite\nReview the set-up instructions as well in preparation for class.\nSQLite\nThere are many flavors of SQL but most flavors have the same base commands. SQL queries are typed in the following pattern;\nSELECT -- &lt;columns&gt; and &lt;column calculations&gt;\nFROM -- &lt;table name&gt;\n  JOIN -- &lt;table name&gt;\n  ON -- &lt;columns to join&gt;\nWHERE -- &lt;filter condition on rows&gt;\nGROUP BY -- &lt;subsets for column calculations&gt;\nHAVING -- &lt;filter conditions on groups&gt;\nORDER BY -- &lt;how the output is returned in sequence&gt;\nLIMIT -- &lt;number of rows to return&gt;\nThe reading for this task are from this excellent SQL Guide. To prepare for class and this task you should read:\n\nAll the categories in the “Basic” group. (topics are grouped in the menu on the left side of the page).\nThe following sections in the Intermediate group:\n\nAggregations\nGROUP BY and FILTER\nHAVING\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "SQLite"
    ]
  },
  {
    "objectID": "Course Materials/ml.html",
    "href": "Course Materials/ml.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Everyone seems to have a slightly different take on the differences between Artificial Intelligence, Machine Learning, and Data Science. The following four articles cover some of the most common definitions.\nAs you read them, think about the differences and similarities of the definitions. Given the backgrounds of the various authors, whose opinions might you give more weight to?\n\nMichael Copeland writing for NVidia\nBernard Marr writing for Forbes\nVincent Granville writing for Data Science Central\nSimply Statistics Blog - The key word in “Data Science” is not Data, it is Science\n\nOf particular note is this quote from the Granville article:\n\nEarlier in my career (circa 1990) I worked on image remote sensing technology, among other things to identify patterns (or shapes or features, for instance lakes) in satellite images and to perform image segmentation: at that time my research was labeled as computational statistics, but the people doing the exact same thing in the computer science department next door in my home university, called their research artificial intelligence. Today, it would be called data science or artificial intelligence, the sub-domains being signal processing, computer vision or IoT.\n\nAs with most things in the realm of science, there tends to be a wide gap between how the media, government, and business sectors view a particular technology compared to how it’s viewed by the engineers and scientists using that technology.\nFor our purposes in this course, we’ll define these terms as follows:\n\nArtificial Intelligence: The study of man-made “agents” that perceive their environment and take actions that maximize their chances of success at some goal.1\nMachine Learning: A subfield within Artificial Intelligence that gives “computers the ability to learn without being explicitly programmed.”2\nData Science: The study and use of the techniques, statistics, algorithms, and tools needed to extract knowledge and insights from data.3",
    "crumbs": [
      "Machine Learning (ML)"
    ]
  },
  {
    "objectID": "Course Materials/ml.html#footnotes",
    "href": "Course Materials/ml.html#footnotes",
    "title": "Machine Learning",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nArtificial Intelligence: A Modern Approach by Russell and Norvig (Prentice Hall, 2009).↩︎↩︎\nSome Studies in Machine Learning Using the Game of Checkers, by Arthur L. Samuel (IBM Journal, Vol 3, No 3, 1959).↩︎↩︎\nWikipedia article on Data Science.↩︎↩︎\nMind Children, by Hans Moravec (Harvard University Press, 1988).↩︎↩︎\nXKCD 1425: Tasks.↩︎↩︎\nCambridge Alumni Magazine, Issue 79, pg 19.↩︎↩︎\nCambridge Alumni Magazine, Issue 79, pg 19.↩︎↩︎\nCross Validated: Prediction vs Inference.↩︎↩︎\nCross Validated: Prediction vs Inference.↩︎↩︎",
    "crumbs": [
      "Machine Learning (ML)"
    ]
  },
  {
    "objectID": "Course Materials/git_pull_merge.html",
    "href": "Course Materials/git_pull_merge.html",
    "title": "Pull and Merge Forks on GitHub",
    "section": "",
    "text": "Create Pull Request\n\n\nGo the the forked repository in byuids-resumes and click Pull request.\n\n\n\n\n\nThis will bring you to the the following page where you need to click switching the base.\n\n\n\n\n\nNow you can Create pull request.\n\n\n\n\n\nHere you can type a note and then actually Create pull request.\n\n\n\n\n\nNow you need to View pull request.\n\n\n\n\n\nMerge Request\nIf you have admin access of the forked repository where you are doing the pull request, you can finish the next two steps.\n\n\nClick the Merge pull request button.\n\n\n\n\n\nNow confirm the merge.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "GitHub - Pull and Merge Forks"
    ]
  },
  {
    "objectID": "Course Materials/lets_plot.html",
    "href": "Course Materials/lets_plot.html",
    "title": "Data Visualization with Lets Plot",
    "section": "",
    "text": "Introduction\n\n“The simple graph has brought more information to the data analyst’s mind than any other device.” — John Tukey\n\nThis chapter introudces data visualization with the Lets Plot library. We briefly discus the grammar of graphics which is a useful paradigm for understanding the fundamentals of building graphs. Then we introudce the basics of Lets Plot and provide resources for further development.\n\n\nPrerequisites\nLets Plot Install\nFor a slightly more interesting introduction, let’s look at the penguins dataset built into the lets_plot data library. This dataset contains measurements on species of penguins.\n::: {.callout-caution, collapse=“false”} #### Caution R has a package that uses ggplot and there is also another Python library plotnine that uses the same ggplot syntax. If you don’t specify lets_plot when using ChatGPT, you may be led down the wrong code path. It is recommended you only use the ChatGPT that was designed for this course. :::\nFirst, load the data by calling load_penguins from the palmerpenguins library as follows:\n\nimport pandas as pd\nimport numpy as np\nfrom lets_plot import *\nfrom palmerpenguins import load_penguins\n\nLetsPlot.setup_html()\n\ndata = load_penguins()\n\n\n            \n            \n            \n\n\nTo explore the relationship between bill length and bill depth, we can start with a basic scatterplot.\n\n# sometime you have to run this cell twice to get the plot to show\n(\n    ggplot(data) \n    + geom_point(aes(x='bill_length_mm', y='bill_depth_mm'), color='blue') \n    + ggtitle(\"The relationship between bill length and bill depth\")\n)\n\n   \n   \n\n\nWhen all species are lumped together in this scatterplot it doesn’t look like there is much of a relationship between the bill length and bill depth. We can improve our visualization by coloring the points based on species.\n\n(\n    ggplot(data) \n    + geom_point(aes(x='bill_length_mm', y='bill_depth_mm', color='species')) \n    + ggtitle(\"The relationship between bill length and bill depth by species\")\n)\n\n   \n   \n\n\nWe can also easily change the shape and size of the points in a scatterplot.\n\n(\n    ggplot(data) \n    + geom_point(aes(x='bill_length_mm', y='bill_depth_mm', color='species', shape='species', size='flipper_length_mm')) \n    + ggtitle(\"The relationship between bill length and bill depth by species with flipper length as size\")\n)\n\n   \n   \n\n\nNow that’s going overboard! But hopefully the basic syntax for using lets_plot makes sense.\n\n\nMaking Lets-Plot More Presentable\nIn this section, we look at how to customize charts to be more informative and presentable. For example, column names in a dataset are rarely a good idea to present to someone not as intimately familiar with the data as you. We may also wish to highlight certain points, or draw attention to areas on a graph.\nTo begin, let’s return to a reasonable visualization of the penguins data. We will start by naming our ggplot chart object “plot” and changing the X and Y axis labels.\nThe way is to include the labs function in the plot inputs. The arguments in this function are the axis names and their desired labels.\n\nplot = (\n    ggplot(data)\n    + geom_point(aes(x='bill_length_mm', y='bill_depth_mm', color='species', shape='species', size='flipper_length_mm'))\n    + ggtitle(\"The relationship between bill length and bill depth by species with flipper length as size\")\n    + labs(x='Bill Length (mm)', y='Bill Depth (mm)', color='Species', shape='Species', size='Flipper Length (mm)')\n)\n\nplot\n\n   \n   \n\n\nThe next method makes the same adjustments but modifies the chart “post hoc”. Start with a very basic chart, “plot” and use the + operator to add layers and modify titles.\n\nplot = (\n    ggplot(data)\n    + geom_point(aes(x='bill_length_mm', y='bill_depth_mm', color='species', shape='species', size='flipper_length_mm'))\n    + ggtitle(\"The relationship between bill length and bill depth by species with flipper length as size\")\n)\n\nplot = plot + labs(x='Bill Length (mm)', y='Bill Depth (mm)', color='Species', shape='Species', size='Flipper Length (mm)')\nplot\n\n   \n   \n\n\n The 2 approaches above have the same outcome, but the latter example introduces a flexible lets_plot paradigm that can be extended to other chart additions and modifications. For example, if we want to add a reference line to “plot”, we can use the geom_hline() function. \n\nplot = plot + geom_hline(yintercept=7, linetype='dotted', color='black')\nplot\n\n   \n   \n\n\nWe can add several different shapes, including circles, lines or rectanges using the .add_shape() method. This method specifies what type of shape to add to the graph given a set of coordinates (x0, x1, y0, y1). “.add_shape()” can be used to draw reference lines as well, but still requires a all 4 coordinates.\nHere is a simple example first:\n\n# Adds a horizontal line\nimport pandas as pd\nfrom lets_plot import *\nLetsPlot.setup_html()\n\n# Sample data with correct data types\ndata = {'x': [1.0, 2.0, 3.0, 4.0, 5.0], 'y': [5.0, 4.0, 3.0, 2.0, 1.0]}\ndf = pd.DataFrame(data)\n\n# Ensure data types are correct\ndf['x'] = df['x'].astype(float)\ndf['y'] = df['y'].astype(float)\n\n# Create scatter plot\nplot = ggplot(df, aes('x', 'y')) + geom_point()\n\n# Add a rectangle shape using direct numeric values\nplot += geom_rect(xmin=2.0, xmax=4.0, ymin=1.0, ymax=3.0, fill='red', alpha=0.3)\n\n# Display the plot\nplot.show()\n\n\n            \n            \n            \n\n\n   \n   \n\n\nNow here is it applied to our penguin data:\n\n# Load the penguins dataset\npenguins = load_penguins()\n\n# Create scatter plot\nplot = (\n    ggplot(penguins)\n    + geom_point(aes(x='bill_length_mm', y='bill_depth_mm', color='species', shape='species', size='flipper_length_mm'))\n    + ggtitle(\"The relationship between bill length and bill depth by species with flipper length as size\")\n)\n\n# Add labels\nplot = plot + labs(x='Bill Length (mm)', y='Bill Depth (mm)', color='Species', shape='Species', size='Flipper Length (mm)')\n\n# Add a rectangle shape using direct numeric values\nplot += geom_rect(xmin=33.0, xmax=45.0, ymin=16.0, ymax=22.0, fill='red', alpha=0.3)\n\n# Display the plot\nplot\n\n   \n   \n\n\nThe code above introduces the geom_rect features, it is not always necessary for every situation. But hopefully this gives a flavor of what can be done.\nNotice also, that the geom_ methods actually update plot. No need to overwrite the original object or create a new chart object for each modification.\n\n\nOther geom_*itions\nThere are several other useful “post hoc” graph modifications that we only mention in this chapter. For further exploration, see Lets-Plot Documentation.\nUse geom_text() to add text annotations at specific locations. Update axes by using scale_x_continuous() or scale_y_continuous() which allows you to modify gridlines and add units of measure like “%” or “$”. geom_vline() and geom_hline() allow you to add vertical or horizontal reference lines. The possibilities are almost endless!\n\n\nResources\nThis page has introduced the basics of lets_plot, but we have only looked at a scatterplot. For links to further documentation and a whole gallery of lets_plot possibilities, see Lets-Plot Documentation.\n\n\n\n\n Back to top",
    "crumbs": [
      "Lets Plot"
    ]
  },
  {
    "objectID": "Course Materials/python.html",
    "href": "Course Materials/python.html",
    "title": "Python for Data Science",
    "section": "",
    "text": "Python for Data Science python4DS is a port of R for Data Science (2e) into Python. The authors keep Garrett Grolemund and Hadley Wickham’s writing and examples as much as possible while demonstrating Python instead of R. The book focuses on pandas and LetsPlot in the Python code snippets.\nThis book will teach you how to do data science with Python: You’ll learn how to get your data into Python, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you’ll learn how to clean data and draw plots—and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with Python. You’ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You’ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.\n\nLearn How to Setup Python\nPython\n\n\n\n\n Back to top",
    "crumbs": [
      "Python for Data Science"
    ]
  },
  {
    "objectID": "Course Materials/sql_page.html",
    "href": "Course Materials/sql_page.html",
    "title": "Introduction",
    "section": "",
    "text": "Structured Query Language (SQL) is a powerful tool for managing and manipulating relational databases. It is essential for data scientists, analysts, and anyone working with large datasets. This chapter will explore the importance of SQL, its applications, and provide example code format to illustrate its utility."
  },
  {
    "objectID": "Course Materials/sql_page.html#why-sql-is-important",
    "href": "Course Materials/sql_page.html#why-sql-is-important",
    "title": "Introduction",
    "section": "Why SQL is Important",
    "text": "Why SQL is Important\n\nData Management: SQL allows for efficient management of large volumes of data. It provides the means to create, read, update, and delete data in a relational database.\nData Retrieval: With SQL, you can perform complex queries to retrieve specific data from one or more tables, making it easier to analyze and draw insights.\nData Manipulation: SQL enables the manipulation of data through operations such as sorting, filtering, and aggregating. This is crucial for data cleaning and preprocessing.\nData Integration: SQL supports the integration of data from different sources, allowing for comprehensive data analysis.\nStandardization: SQL is a standardized language used by most relational database management systems (RDBMS), making it a versatile and essential skill for professionals in the field."
  },
  {
    "objectID": "Course Materials/sql_page.html#basic-sql-concepts",
    "href": "Course Materials/sql_page.html#basic-sql-concepts",
    "title": "Introduction",
    "section": "Basic SQL Concepts",
    "text": "Basic SQL Concepts\n\nimport sqlite3\nimport pandas as pd"
  },
  {
    "objectID": "Course Materials/sql_page.html#basic-sql-concepts-1",
    "href": "Course Materials/sql_page.html#basic-sql-concepts-1",
    "title": "Introduction",
    "section": "Basic SQL Concepts",
    "text": "Basic SQL Concepts\nTo illustrate the following SQL concepts, we will use the employees table with the following data:\nTable: employees\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n1\nAlice\nSmith\nHR\n60000\n\n\n2\nBob\nJohnson\nIT\n80000\n\n\n3\nCharlie\nLee\nSales\n55000\n\n\n4\nDavid\nKim\nHR\n75000\n\n\n5\nEva\nBrown\nIT\n65000\n\n\n6\nFrank\nWilson\nSales\n70000\n\n\n7\nGrace\nTaylor\nHR\n62000\n\n\n8\nHenry\nAnderson\nIT\n77000\n\n\n9\nIrene\nThomas\nSales\n53000\n\n\n10\nJack\nWhite\nHR\n58000\n\n\n11\nKaren\nHarris\nIT\n69000\n\n\n12\nLeo\nMartin\nSales\n50000\n\n\n13\nMia\nJackson\nHR\n64000\n\n\n14\nNoah\nLee\nIT\n72000\n\n\n15\nOlivia\nPerez\nSales\n68000\n\n\n16\nPaul\nYoung\nHR\n61000\n\n\n17\nQuinn\nKing\nIT\n76000\n\n\n18\nRachel\nScott\nSales\n57000\n\n\n19\nSam\nGreen\nHR\n63000\n\n\n20\nTina\nAdams\nIT\n81000\n\n\n\n\nSELECT and FROM\nThe SELECT statement is used to fetch data from a database, and the FROM clause specifies the table.\n-- Selecting all columns from a table\np = \"\"\"\n\nSELECT * \nFROM \n  employees;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n1\nAlice\nSmith\nHR\n60000\n\n\n2\nBob\nJohnson\nIT\n80000\n\n\n3\nCharlie\nLee\nSales\n55000\n\n\n4\nDavid\nKim\nHR\n75000\n\n\n5\nEva\nBrown\nIT\n65000\n\n\n6\nFrank\nWilson\nSales\n70000\n\n\n7\nGrace\nTaylor\nHR\n62000\n\n\n8\nHenry\nAnderson\nIT\n77000\n\n\n9\nIrene\nThomas\nSales\n53000\n\n\n10\nJack\nWhite\nHR\n58000\n\n\n11\nKaren\nHarris\nIT\n69000\n\n\n12\nLeo\nMartin\nSales\n50000\n\n\n13\nMia\nJackson\nHR\n64000\n\n\n14\nNoah\nLee\nIT\n72000\n\n\n15\nOlivia\nPerez\nSales\n68000\n\n\n16\nPaul\nYoung\nHR\n61000\n\n\n17\nQuinn\nKing\nIT\n76000\n\n\n18\nRachel\nScott\nSales\n57000\n\n\n19\nSam\nGreen\nHR\n63000\n\n\n20\nTina\nAdams\nIT\n81000\n\n\n\n-- Selecting specific columns\np = \"\"\"\n\nSELECT \n  first_name, \n  last_name, \n  salary \nFROM \n  employees;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\nsalary\n\n\n\n\n1\nAlice\nSmith\n60000\n\n\n2\nBob\nJohnson\n80000\n\n\n3\nCharlie\nLee\n55000\n\n\n4\nDavid\nKim\n75000\n\n\n5\nEva\nBrown\n65000\n\n\n6\nFrank\nWilson\n70000\n\n\n7\nGrace\nTaylor\n62000\n\n\n8\nHenry\nAnderson\n77000\n\n\n9\nIrene\nThomas\n53000\n\n\n10\nJack\nWhite\n58000\n\n\n11\nKaren\nHarris\n69000\n\n\n12\nLeo\nMartin\n50000\n\n\n13\nMia\nJackson\n64000\n\n\n14\nNoah\nLee\n72000\n\n\n15\nOlivia\nPerez\n68000\n\n\n16\nPaul\nYoung\n61000\n\n\n17\nQuinn\nKing\n76000\n\n\n18\nRachel\nScott\n57000\n\n\n19\nSam\nGreen\n63000\n\n\n20\nTina\nAdams\n81000\n\n\n\n\n\nSELECT EXCLUDE and RENAME\nYou can exclude columns using SELECT and rename them for clarity.\n-- Selecting all but one column\np = \"\"\"\n\nSELECT * \nEXCLUDE \n  salary \nFROM \n  employees;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\n\n\n\n\n1\nAlice\nSmith\nHR\n\n\n2\nBob\nJohnson\nIT\n\n\n3\nCharlie\nLee\nSales\n\n\n4\nDavid\nKim\nHR\n\n\n5\nEva\nBrown\nIT\n\n\n6\nFrank\nWilson\nSales\n\n\n7\nGrace\nTaylor\nHR\n\n\n8\nHenry\nAnderson\nIT\n\n\n9\nIrene\nThomas\nSales\n\n\n10\nJack\nWhite\nHR\n\n\n11\nKaren\nHarris\nIT\n\n\n12\nLeo\nMartin\nSales\n\n\n13\nMia\nJackson\nHR\n\n\n14\nNoah\nLee\nIT\n\n\n15\nOlivia\nPerez\nSales\n\n\n16\nPaul\nYoung\nHR\n\n\n17\nQuinn\nKing\nIT\n\n\n18\nRachel\nScott\nSales\n\n\n19\nSam\nGreen\nHR\n\n\n20\nTina\nAdams\nIT\n\n\n\n-- Renaming columns\np = \"\"\"\n\nSELECT \n  first_name AS fname, \n  last_name AS lname \nFROM \n  employees;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nfname\nlname\n\n\n\n\nAlice\nSmith\n\n\nBob\nJohnson\n\n\nCharlie\nLee\n\n\nDavid\nKim\n\n\nEva\nBrown\n\n\nFrank\nWilson\n\n\nGrace\nTaylor\n\n\nHenry\nAnderson\n\n\nIrene\nThomas\n\n\nJack\nWhite\n\n\nKaren\nHarris\n\n\nLeo\nMartin\n\n\nMia\nJackson\n\n\nNoah\nLee\n\n\nOlivia\nPerez\n\n\nPaul\nYoung\n\n\nQuinn\nKing\n\n\nRachel\nScott\n\n\nSam\nGreen\n\n\nTina\nAdams\n\n\n\n\n\nLIMIT and OFFSET\nThe LIMIT clause restricts the number of rows returned, and OFFSET skips rows before beginning to return rows.\n-- Limiting the number of rows returned\n\np = \"\"\"\n\nSELECT * \nFROM \n  employees \nLIMIT \n  10;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n1\nAlice\nSmith\nHR\n60000\n\n\n2\nBob\nJohnson\nIT\n80000\n\n\n3\nCharlie\nLee\nSales\n55000\n\n\n4\nDavid\nKim\nHR\n75000\n\n\n5\nEva\nBrown\nIT\n65000\n\n\n6\nFrank\nWilson\nSales\n70000\n\n\n7\nGrace\nTaylor\nHR\n62000\n\n\n8\nHenry\nAnderson\nIT\n77000\n\n\n9\nIrene\nThomas\nSales\n53000\n\n\n10\nJack\nWhite\nHR\n58000\n\n\n\n-- Skipping rows\np = \"\"\"\n\nSELECT * \nFROM \n  employees \nLIMIT 10 \nOFFSET 5;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n6\nFrank\nWilson\nSales\n70000\n\n\n7\nGrace\nTaylor\nHR\n62000\n\n\n8\nHenry\nAnderson\nIT\n77000\n\n\n9\nIrene\nThomas\nSales\n53000\n\n\n10\nJack\nWhite\nHR\n58000\n\n\n11\nKaren\nHarris\nIT\n69000\n\n\n12\nLeo\nMartin\nSales\n50000\n\n\n13\nMia\nJackson\nHR\n64000\n\n\n14\nNoah\nLee\nIT\n72000\n\n\n15\nOlivia\nPerez\nSales\n68000\n\n\n\n\n\nORDER BY\nThe ORDER BY clause sorts the result set.\n-- Sorting the result set by salary in ascending order\np = \"\"\"\n\nSELECT * \nFROM  \n  employees \nORDER BY \n  salary;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n12\nLeo\nMartin\nSales\n50000\n\n\n9\nIrene\nThomas\nSales\n53000\n\n\n3\nCharlie\nLee\nSales\n55000\n\n\n10\nJack\nWhite\nHR\n58000\n\n\n1\nAlice\nSmith\nHR\n60000\n\n\n19\nSam\nGreen\nHR\n63000\n\n\n7\nGrace\nTaylor\nHR\n62000\n\n\n13\nMia\nJackson\nHR\n64000\n\n\n5\nEva\nBrown\nIT\n65000\n\n\n11\nKaren\nHarris\nIT\n69000\n\n\n18\nRachel\nScott\nSales\n57000\n\n\n15\nOlivia\nPerez\nSales\n68000\n\n\n6\nFrank\nWilson\nSales\n70000\n\n\n14\nNoah\nLee\nIT\n72000\n\n\n17\nQuinn\nKing\nIT\n76000\n\n\n8\nHenry\nAnderson\nIT\n77000\n\n\n4\nDavid\nKim\nHR\n75000\n\n\n2\nBob\nJohnson\nIT\n80000\n\n\n20\nTina\nAdams\nIT\n81000\n\n\n16\nPaul\nYoung\nHR\n61000\n\n\n\n-- Sorting in descending order\np = \"\"\"\n\nSELECT * \nFROM \n  employees \nORDER BY \n  salary DESC;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n20\nTina\nAdams\nIT\n81000\n\n\n2\nBob\nJohnson\nIT\n80000\n\n\n8\nHenry\nAnderson\nIT\n77000\n\n\n17\nQuinn\nKing\nIT\n76000\n\n\n4\nDavid\nKim\nHR\n75000\n\n\n14\nNoah\nLee\nIT\n72000\n\n\n6\nFrank\nWilson\nSales\n70000\n\n\n15\nOlivia\nPerez\nSales\n68000\n\n\n11\nKaren\nHarris\nIT\n69000\n\n\n5\nEva\nBrown\nIT\n65000\n\n\n13\nMia\nJackson\nHR\n64000\n\n\n19\nSam\nGreen\nHR\n63000\n\n\n7\nGrace\nTaylor\nHR\n62000\n\n\n16\nPaul\nYoung\nHR\n61000\n\n\n1\nAlice\nSmith\nHR\n60000\n\n\n10\nJack\nWhite\nHR\n58000\n\n\n3\nCharlie\nLee\nSales\n55000\n\n\n9\nIrene\nThomas\nSales\n53000\n\n\n18\nRachel\nScott\nSales\n57000\n\n\n12\nLeo\nMartin\nSales\n50000\n\n\n\n\n\nAND, OR, NOT\nLogical operators filter records based on multiple conditions.\n-- Using AND, OR, NOT operators\np = \"\"\"\n\nSELECT * \nFROM \n  employees \nWHERE \n  department = 'Sales' AND salary &gt; 50000;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n6\nFrank\nWilson\nSales\n70000\n\n\n15\nOlivia\nPerez\nSales\n68000\n\n\n18\nRachel\nScott\nSales\n57000\n\n\n\n\n\nNumeric Operations\nPerform arithmetic operations in SQL.\n-- Calculating a new column\np = \"\"\"\n\nSELECT \n  first_name, \n  last_name, \n  salary, \n  salary * 1.1 AS new_salary \nFROM \n  employees;\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nfirst_name\nlast_name\nsalary\nnew_salary\n\n\n\n\nAlice\nSmith\n60000\n66000.0\n\n\nBob\nJohnson\n80000\n88000.0\n\n\nCharlie\nLee\n55000\n60500.0\n\n\nDavid\nKim\n75000\n82500.0\n\n\nEva\nBrown\n65000\n71500.0\n\n\nFrank\nWilson\n70000\n77000.0\n\n\nGrace\nTaylor\n62000\n68200.0\n\n\nHenry\nAnderson\n77000\n84700.0\n\n\nIrene\nThomas\n53000\n58300.0\n\n\nJack\nWhite\n58000\n63800.0\n\n\nKaren\nHarris\n69000\n75900.0\n\n\nLeo\nMartin\n50000\n55000.0\n\n\nMia\nJackson\n64000\n70400.0\n\n\nNoah\nLee\n72000\n79200.0\n\n\nOlivia\nPerez\n68000\n74800.0\n\n\nPaul\nYoung\n61000\n67100.0\n\n\nQuinn\nKing\n76000\n83600.0\n\n\nRachel\nScott\n57000\n62700.0\n\n\nSam\nGreen\n63000\n69300.0\n\n\nTina\nAdams\n81000\n89100.0\n\n\n\n\n\nLIKE and NOT LIKE\nPattern matching using LIKE.\n-- Pattern matching\np = \"\"\"\n\nSELECT * \nFROM \n  employees \nWHERE \n  last_name \nLIKE 'S%';\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n1\nAlice\nSmith\nHR\n60000\n\n\n18\nRachel\nScott\nSales\n57000\n\n\n\n\n\nBETWEEN\nRange filtering using BETWEEN.\n-- Filtering within a range\np = \"\"\"\n\nSELECT * \nFROM \n  employees \nWHERE \n  salary BETWEEN 40000 AND 60000;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n12\nLeo\nMartin\nSales\n50000\n\n\n3\nCharlie\nLee\nSales\n55000\n\n\n9\nIrene\nThomas\nSales\n53000\n\n\n10\nJack\nWhite\nHR\n58000\n\n\n1\nAlice\nSmith\nHR\n60000\n\n\n\n\n\nOFFSET\nSkip a specific number of rows before starting to return rows.\n-- Skipping the first 5 rows\np = \"\"\"\n\nSELECT * \nFROM \n  employees \nOFFSET 5;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nid\nfirst_name\nlast_name\ndepartment\nsalary\n\n\n\n\n6\nFrank\nWilson\nSales\n70000\n\n\n7\nGrace\nTaylor\nHR\n62000\n\n\n8\nHenry\nAnderson\nIT\n77000\n\n\n9\nIrene\nThomas\nSales\n53000\n\n\n10\nJack\nWhite\nHR\n58000\n\n\n11\nKaren\nHarris\nIT\n69000\n\n\n12\nLeo\nMartin\nSales\n50000\n\n\n13\nMia\nJackson\nHR\n64000\n\n\n14\nNoah\nLee\nIT\n72000\n\n\n15\nOlivia\nPerez\nSales\n68000\n\n\n16\nPaul\nYoung\nHR\n61000\n\n\n17\nQuinn\nKing\nIT\n76000\n\n\n18\nRachel\nScott\nSales\n57000\n\n\n19\nSam\nGreen\nHR\n63000\n\n\n20\nTina\nAdams\nIT\n81000"
  },
  {
    "objectID": "Course Materials/sql_page.html#intermediate-sql-concepts",
    "href": "Course Materials/sql_page.html#intermediate-sql-concepts",
    "title": "Introduction",
    "section": "Intermediate SQL Concepts",
    "text": "Intermediate SQL Concepts\n\nJoins\nTable: employees\n\n\n\nid\nfirst_name\nlast_name\ndepartment_id\nsalary\n\n\n\n\n1\nAlice\nSmith\n1\n60000\n\n\n2\nBob\nJohnson\n2\n80000\n\n\n3\nCharlie\nLee\n3\n55000\n\n\n4\nDavid\nKim\n1\n75000\n\n\n5\nEva\nBrown\n2\n65000\n\n\n6\nFrank\nWilson\n3\n70000\n\n\n7\nGrace\nTaylor\n1\n62000\n\n\n8\nHenry\nAnderson\n2\n77000\n\n\n9\nIrene\nThomas\n3\n53000\n\n\n10\nJack\nWhite\n1\n58000\n\n\n11\nKaren\nHarris\n2\n69000\n\n\n12\nLeo\nMartin\n3\n50000\n\n\n13\nMia\nJackson\n1\n64000\n\n\n14\nNoah\nLee\n2\n72000\n\n\n15\nOlivia\nPerez\n3\n68000\n\n\n16\nPaul\nYoung\n1\n61000\n\n\n17\nQuinn\nKing\n2\n76000\n\n\n18\nRachel\nScott\n3\n57000\n\n\n19\nSam\nGreen\n1\n63000\n\n\n20\nTina\nAdams\n2\n81000\n\n\n\nTable: departments\n\n\n\ndepartment_id\ndepartment_name\n\n\n\n\n1\nHR\n\n\n2\nIT\n\n\n3\nSales\n\n\n\nCombine rows from two or more tables based on a related column.\n-- Inner join example\np = \"\"\"\n\nSELECT \n  employees.first_name, \n    employees.last_name, \n    departments.department_name\nFROM \n  employees\nINNER JOIN \n  departments ON employees.department_id = departments.department_id;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nfirst_name\nlast_name\ndepartment_name\n\n\n\n\nAlice\nSmith\nHR\n\n\nDavid\nKim\nHR\n\n\nGrace\nTaylor\nHR\n\n\nJack\nWhite\nHR\n\n\nMia\nJackson\nHR\n\n\nPaul\nYoung\nHR\n\n\nSam\nGreen\nHR\n\n\nBob\nJohnson\nIT\n\n\nEva\nBrown\nIT\n\n\nHenry\nAnderson\nIT\n\n\nKaren\nHarris\nIT\n\n\nNoah\nLee\nIT\n\n\nQuinn\nKing\nIT\n\n\nTina\nAdams\nIT\n\n\nCharlie\nLee\nSales\n\n\nFrank\nWilson\nSales\n\n\nIrene\nThomas\nSales\n\n\nLeo\nMartin\nSales\n\n\nOlivia\nPerez\nSales\n\n\nRachel\nScott\nSales\n\n\n\n\n\nCAST\nConvert data from one type to another.\n-- Casting a column\np = \"\"\"\n\nSELECT \n  CAST(salary AS DECIMAL(10, 2)) \nFROM \n  employees;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nsalary\n\n\n\n\n60000.00\n\n\n80000.00\n\n\n55000.00\n\n\n75000.00\n\n\n65000.00\n\n\n70000.00\n\n\n62000.00\n\n\n77000.00\n\n\n53000.00\n\n\n58000.00\n\n\n69000.00\n\n\n50000.00\n\n\n64000.00\n\n\n72000.00\n\n\n68000.00\n\n\n61000.00\n\n\n76000.00\n\n\n57000.00\n\n\n63000.00\n\n\n81000.00\n\n\n\n\n\nAggregations\nPerform calculations on a set of values.\n-- Using aggregation functions\np = \"\"\"\n\nSELECT \n  department_id, \n  COUNT(employee_id) AS num_employees\nFROM \n  employees\nGROUP BY \n  department_id;\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\ndepartment_id\nnum_employees\n\n\n\n\n1\n7\n\n\n2\n7\n\n\n3\n6\n\n\n\n\n\nGROUP BY and HAVING\nGroup rows that have the same values and filter groups.\n-- Grouping rows and filtering groups\np = \"\"\"\nSELECT \n  department_id,\n  COUNT(employee_id) AS num_employees\nFROM \n  employees\nGROUP BY \n  department_id\nHAVING COUNT(employee_id) &gt; 5;\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\ndepartment_id\nnum_employees\n\n\n\n\n1\n7\n\n\n2\n7\n\n\n3\n6\n\n\n\n\n\nUNION, INTERSECT, MINUS\nCombine result sets\nTable: managers\n\n\n\nmanager_id\nfirst_name\nlast_name\n\n\n\n\n1\nMichael\nBrown\n\n\n2\nSarah\nJohnson\n\n\n3\nJohn\nLee\n\n\n\n-- Union example\np = \"\"\"\nSELECT \n  first_name \nFROM \n  employees\nUNION\n\nSELECT \n  first_name\nFROM\n   managers;\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nfirst_name\n\n\n\n\nAlice\n\n\nBob\n\n\nCharlie\n\n\nDavid\n\n\nEva\n\n\nFrank\n\n\nGrace\n\n\nHenry\n\n\nIrene\n\n\nJack\n\n\nKaren\n\n\nLeo\n\n\nMia\n\n\nNoah\n\n\nOlivia\n\n\nPaul\n\n\nQuinn\n\n\nRachel\n\n\nSam\n\n\nTina\n\n\nMichael\n\n\nSarah\n\n\nJohn\n\n\n\n\n\nPOSITION\nFind the position of a substring.\n-- Finding substring position\np = \"\"\"\nSELECT \n  POSITION('e' IN first_name) \nFROM \n  employees;\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nposition\n\n\n\n\n0\n\n\n0\n\n\n4\n\n\n0\n\n\n0\n\n\n2\n\n\n0\n\n\n3\n\n\n2\n\n\n0\n\n\n0\n\n\n3\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n2\n\n\n0\n\n\n0\n\n\n\n\n\nCASE\nConditional logic in `SQL.\n-- Using CASE statements\np = \"\"\"\nSELECT \n  first_name, \n  last_name,\n       CASE \n         WHEN salary &gt; 60000 THEN 'High'\n         WHEN salary BETWEEN 40000 AND 60000 THEN 'Medium'\n         ELSE 'Low'\n       END AS salary_category\nFROM \n  employees;\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\nfirst_name\nlast_name\nsalary_category\n\n\n\n\nAlice\nSmith\nMedium\n\n\nBob\nJohnson\nHigh\n\n\nCharlie\nLee\nMedium\n\n\nDavid\nKim\nHigh\n\n\nEva\nBrown\nMedium\n\n\nFrank\nWilson\nHigh\n\n\nGrace\nTaylor\nMedium\n\n\nHenry\nAnderson\nHigh\n\n\nIrene\nThomas\nMedium\n\n\nJack\nWhite\nMedium\n\n\nKaren\nHarris\nHigh\n\n\nLeo\nMartin\nMedium\n\n\nMia\nJackson\nMedium\n\n\nNoah\nLee\nHigh\n\n\nOlivia\nPerez\nHigh\n\n\nPaul\nYoung\nMedium\n\n\nQuinn\nKing\nHigh\n\n\nRachel\nScott\nMedium\n\n\nSam\nGreen\nMedium\n\n\nTina\nAdams\nHigh"
  },
  {
    "objectID": "Course Materials/sql_page.html#introduction",
    "href": "Course Materials/sql_page.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\nIt’s rare that a data analysis involves only a single data frame. Typically you have many data frames, and you must join them together to answer the questions that you’re interested in.\npandas has a really rich set of options for combining one or more data frames, with the two most important being concatenate and merge. Some of the examples in this chapter show you how to join a pair of data frames. Fortunately this is enough, since you can combine three data frames by combining two pairs.\n\n# remove cell\nimport matplotlib_inline.backend_inline\nimport matplotlib.pyplot as plt\n\n# Plot settings\nplt.style.use(\"https://github.com/aeturrell/python4DS/raw/main/plot_style.txt\")\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\nPrerequisites\nThis chapter will use the pandas data analysis package."
  },
  {
    "objectID": "Course Materials/sql_page.html#concatenate",
    "href": "Course Materials/sql_page.html#concatenate",
    "title": "Introduction",
    "section": "Concatenate",
    "text": "Concatenate\nIf you have two or more data frames with the same index or the same columns, you can glue them together into a single data frame using pd.concat().\n\nFor the same columns, pass axis=0 to glue the index together; for the same index, pass axis=1 to glue the columns together. The concatenate function will typically be used on a list of data frames.\nIf you want to track where the original data came from in the final data frame, use the keys keyword.\nHere’s an example using data on two different states’ populations that also makes uses of the keys option:\n\nimport pandas as pd\nimport urllib.request\n\nbase_url = \"http://www.stata-press.com/data/r14/\"\nstate_codes = [\"ca\", \"il\"]\nend_url = \"pop.dta\"\nheaders = {'User-Agent': 'Mozilla/5.0'}\n\ndef fetch_data(url):\n    req = urllib.request.Request(url, headers=headers)\n    with urllib.request.urlopen(req) as response:\n        return pd.read_stata(response)\n\n# This grabs the two data frames, one for each state\nlist_of_state_dfs = [fetch_data(base_url + state + end_url) for state in state_codes]\n\n# Show example of first entry in list of data frames\nprint(list_of_state_dfs[0])\n\n        county      pop\n0  Los Angeles  9878554\n1       Orange  2997033\n2      Ventura   798364\n\n\n\n# Concatenate the list of data frames\ndf = pd.concat(list_of_state_dfs, keys=state_codes, axis=0)\n\nNote that the keys argument is optional, but is useful for keeping track of origin data frames within the merged data frame.\n\nExercise\nConcatenate the follow two data frames:\ndf1 = pd.DataFrame([['a', 1], ['b', 2]],\n                   columns=['letter', 'number'])\n\ndf2 = pd.DataFrame([['c', 3], ['d', 4]],\n                   columns=['letter', 'number'])\n\n\nMerge\nThere are so many options for merging data frames using pd.merge(left, right, on=..., how=... that we won’t be able to cover them all here. The most important features are: the two data frames to be merged, what variables (aka keys) to merge on (and these can be indexes) via on=, and how to do the merge (eg left, right, outer, inner) via how=. This diagram shows an example of a merge using keys from the left-hand data frame:\n\nThe how= keyword works in the following ways: - how='left' uses keys from the left data frame only to merge. - how='right' uses keys from the right data frame only to merge. - how='inner' uses keys that appear in both data frames to merge. - how='outer' uses the cartesian product of keys in both data frames to merge on.\nLet’s see examples of some of these:\n\nleft = pd.DataFrame(\n    {\n        \"key1\": [\"K0\", \"K0\", \"K1\", \"K2\"],\n        \"key2\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n    }\n)\nright = pd.DataFrame(\n    {\n        \"key1\": [\"K0\", \"K1\", \"K1\", \"K2\"],\n        \"key2\": [\"K0\", \"K0\", \"K0\", \"K0\"],\n        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n    }\n)\n# Right merge\npd.merge(left, right, on=[\"key1\", \"key2\"], how=\"right\")\n\n\n\n\n\n\n\n\nkey1\nkey2\nA\nB\nC\nD\n\n\n\n\n0\nK0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nK0\nA2\nB2\nC1\nD1\n\n\n2\nK1\nK0\nA2\nB2\nC2\nD2\n\n\n3\nK2\nK0\nNaN\nNaN\nC3\nD3\n\n\n\n\n\n\n\nNote that the key combination of K2 and K0 did not exist in the left-hand data frame, and so its entries in the final data frame are NaNs. But it does have entries because we chose the keys from the right-hand data frame.\nWhat about an inner merge?\n\npd.merge(left, right, on=[\"key1\", \"key2\"], how=\"inner\")\n\n\n\n\n\n\n\n\nkey1\nkey2\nA\nB\nC\nD\n\n\n\n\n0\nK0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nK0\nA2\nB2\nC1\nD1\n\n\n2\nK1\nK0\nA2\nB2\nC2\nD2\n\n\n\n\n\n\n\nNow we see that the combination K2 and K0 are excluded because they didn’t exist in the overlap of keys in both data frames.\nFinally, let’s take a look at an outer merge that comes with some extra info via the indicator keyword:\n\npd.merge(left, right, on=[\"key1\", \"key2\"], how=\"outer\", indicator=True)\n\n\n\n\n\n\n\n\nkey1\nkey2\nA\nB\nC\nD\n_merge\n\n\n\n\n0\nK0\nK0\nA0\nB0\nC0\nD0\nboth\n\n\n1\nK0\nK1\nA1\nB1\nNaN\nNaN\nleft_only\n\n\n2\nK1\nK0\nA2\nB2\nC1\nD1\nboth\n\n\n3\nK1\nK0\nA2\nB2\nC2\nD2\nboth\n\n\n4\nK2\nK0\nNaN\nNaN\nC3\nD3\nright_only\n\n\n5\nK2\nK1\nA3\nB3\nNaN\nNaN\nleft_only\n\n\n\n\n\n\n\nNow we can see that the products of all key combinations are here. The indicator=True option has caused an extra column to be added, called ’_merge’, that tells us which data frame the keys on that row came from.\n\n\nExercise\nMerge the following two data frames using the left_on and right_on keyword arguments to specify a join on lkey and rkey respectively:\ndf1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n                    'value': [1, 2, 3, 5]})\ndf2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n                    'value': [5, 6, 7, 8]})\n\n\nExercise\nMerge the following two data frames on \"a\" using how=\"left\" as a keyword argument:\ndf1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\ndf2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\nWhat do you notice about the position .loc[1, \"c\"] in the merged data frame?\nFor more on the options for merging, see pandas’ comprehensive merging documentation."
  },
  {
    "objectID": "Course Materials/sql_page.html#introduction-to-sql-joins",
    "href": "Course Materials/sql_page.html#introduction-to-sql-joins",
    "title": "Introduction",
    "section": "Introduction to SQL Joins",
    "text": "Introduction to SQL Joins\nSQL joins are used to combine rows from two or more tables based on a related column between them. Understanding joins is crucial for effective data retrieval and manipulation. This section will cover the four main types of joins: INNER JOIN, LEFT JOIN, RIGHT JOIN, and FULL JOIN, using visual aids and code snippets with a fake data frame."
  },
  {
    "objectID": "Course Materials/sql_page.html#types-of-joins",
    "href": "Course Materials/sql_page.html#types-of-joins",
    "title": "Introduction",
    "section": "Types of Joins",
    "text": "Types of Joins\n\nINNER JOIN\nAn INNER JOIN returns only the rows that have matching values in both tables.\n\n\n\nINNER JOIN\n\n\n-- Inner join example\np = \"\"\"\nSELECT \n  A.id, \n  A.name, \n  B.order_id\nFROM \n  Customers A\nINNER JOIN \n  Orders B ON A.id = B.customer_id;\n\"\"\"\npd.read_sql_query(p, con)\n\n\nLEFT JOIN\nA LEFT JOIN returns all the rows from the left table and the matched rows from the right table. If no match is found, NULL values are returned for columns from the right table.\n\n\n\nLEFT JOIN\n\n\n-- Left join example\np = \"\"\"\nSELECT \n  A.id, \n  A.name, \n  B.order_id\nFROM \n  Customers A\nLEFT JOIN \n  Orders B ON A.id = B.customer_id;\n\"\"\"\npd.read_sql_query(p, con)\n\n\nRIGHT JOIN\nA RIGHT JOIN returns all the rows from the right table and the matched rows from the left table. If no match is found, NULL values are returned for columns from the left table.\n\n\n\nRIGHT JOIN\n\n\np = \"\"\"\nSELECT \n  A.id, \n  A.name, \n  B.order_id\nFROM \n  Customers A\nRIGHT JOIN \n  Orders B ON A.id = B.customer_id;\n\"\"\"\npd.read_sql_query(p, con)\n\n\nFULL JOIN\nA FULL JOIN returns all the rows when there is a match in either left or right table. Rows without a match in one of the tables will contain NULL values for columns from that table.\n\n\n\nFULL JOIN\n\n\n-- Full join example\np = \"\"\"\nSELECT \n  A.id, \n  A.name, \n  B.order_id\nFROM \n  Customers A\nFULL JOIN \n  Orders B ON A.id = B.customer_id;\n\"\"\"\npd.read_sql_query(p, con)"
  },
  {
    "objectID": "Course Materials/sql_page.html#example-data-frames",
    "href": "Course Materials/sql_page.html#example-data-frames",
    "title": "Introduction",
    "section": "Example Data Frames",
    "text": "Example Data Frames\nTo illustrate these joins, let’s consider two fake data frames: Customers and Orders.\n\nimport pandas as pd\n\n# Creating a fake data frame for Customers\ncustomers = pd.DataFrame({\n    'id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David']\n})\n\n# Creating a fake data frame for Orders\norders = pd.DataFrame({\n    'order_id': [101, 102, 103, 104],\n    'customer_id': [1, 2, 2, 4]\n})\n\n# Display the data frames\nprint(\"Customers Data Frame\")\nprint(customers)\n\nCustomers Data Frame\n   id     name\n0   1    Alice\n1   2      Bob\n2   3  Charlie\n3   4    David\n\n\n\nprint(\"Orders Data Frame\")\nprint(orders)\n\nOrders Data Frame\n   order_id  customer_id\n0       101            1\n1       102            2\n2       103            2\n3       104            4"
  },
  {
    "objectID": "Course Materials/sql_page.html#conclusion",
    "href": "Course Materials/sql_page.html#conclusion",
    "title": "Introduction",
    "section": "Conclusion",
    "text": "Conclusion\nSQL is an indispensable tool for anyone working with data. Its ability to manage, manipulate, and integrate data makes it essential for data analysis and decision-making. The examples provided in this chapter illustrate some of the key operations and techniques used in SQL, highlighting its importance in the field of data science."
  },
  {
    "objectID": "Projects/project_0.html",
    "href": "Projects/project_0.html",
    "title": "Project 0: Introduction",
    "section": "",
    "text": "Walkthrough\n\n\n\nBackground\n\n\n\n\n\n\nNote\n\n\n\n\n\nWe will complete six projects during the semester that each take about two weeks (four days of class). On average, a student will spend 2 hours outside of class per hour in class to complete the assigned readings, submit any Canvas items, and complete the project (for a total of 8 hours per project). The instruction for each project will be structured into sections as written on this page.\nThis first Background section provides context for the project. Make sure you read the background carefully to see the big picture needs and purpose of the project.\n\n\n\nPython and VS Code are tools commonly used in the field of data science. During our first two days of class we will get VS Code prepped for data science programming. Completing Project 0 will set you up for success the rest of the semester.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘Download’ and ‘Information’ links like the ones below.\n\n\n\nURL: penguins data\npenguins = load_penguins()\npenguins\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe Readings section will contain links to reading assignments that are required for each project, as well as optional references. Remember that you are reading this material to build skills. Take the time to comprehend the readings and the skills contained within.\nWe recommend reading through the assigned material once for a general understanding before the first day of each project. You will reread and reference the material multiple times as you complete the project.\n\n\n\nThe readings listed below are required for the first two days of class.\n\nCourse Setup (Do)\nLearn about our Book Python for Data Science (Skim)\nPY4DS: First Steps (Skim)\nPY4DS: CH1 Whole Game (Skim)\nPY4DS: CH2 Data Visualization (Read)\nP4DS: CH30 Markdown (Read)\nP4DS: CH31 Quarto (Skim)\nQuarto Instructional Template for DS (Read)\n\n\nOptional References\n\nLearn about VS Code\nVS Code user interface\nReading Technical Documentation\n\n\n\n\nQuestions and Tasks\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis section lists the questions and tasks that need to be completed for the project. Your work on the project must be compiled into a report, rendered to a HTML file and uploaded in Canvas.\n\n\n\n\nDownload this Project0 Template template as has working code for the Penguine data set. You need to finish the project by updating its markdown so that it is a report by completing the following tasks:\n\nInclude the tables created from PY4DS: CH2 Data Visualization used to create the above chart\n\nRecreate the example charts from PY4DS: CH2 Data Visualization of the textbook.\n\nFollow the instructions in the submission section below to submit your work\n\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the P0_template open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop P0_template.qmd into the terminal this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\n\n\n\n\n\n\nNote\n\n\n\n\n\nDeliverables are “the quantifiable goods or services that must be provided upon the completion of a project”. In this class the deliverable for each project is a GitHub published report created using Quarto files. This final section will be the same for each project.\n\n\n\nUse this P0_template to submit your Client Report.\n\nThe template should include answers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\nWrite short summary of work must be submitted in the comments in Canvas wwhen you submit the URL. Rate your own work on a scale of 1-5 (See the Rubric for Details) Include a short description of why you rated your work the way you did.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\nFeedback:\n\n\n\n\n\n\nNote\n\n\n\n\n\nIf you submit before the due date, you will recieve feedback and/or coaching notes. You will need to address the feedback, re-render and resubmit the project.\n\n\n\n\n\nResubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nIf you submit before the due date, you will have one opportunity to resubmit the project after you have received feedback. The window for the resubmission will be open through the Wednesday following the due date of the project.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 0: Introduction"
    ]
  },
  {
    "objectID": "Projects/project_1.html",
    "href": "Projects/project_1.html",
    "title": "Project 1: What’s in a Name?",
    "section": "",
    "text": "Walkthrough\n\n\n\nBackground\nHello!!!\n\n\n\n\n\n\nNote\n\n\n\n\n\nWe will complete six projects during the semester that each take about two weeks (four days of class). On average, a student will spend 2 hours outside of class per hour in class to complete the assigned readings, submit any Canvas items, and complete the project (for a total of 8 hours per project). The instruction for each project will be structured into sections as written on this page.\nThis first Background section provides context for the project. Make sure you read the background carefully to see the big picture needs and purpose of the project.\n\n\n\nEarly in prehistory, some descriptive names began to be used again and again until they formed a name pool for a particular culture. Parents would choose names from the pool of existing names rather than invent new ones for their children.\nWith the rise of Christianity, certain trends in naming practices manifested. Christians were encouraged to name their children after saints and martyrs of the church. These early Christian names can be found in many cultures today, in various forms. These were spread by early missionaries throughout the Mediterranean basin and Europe.\nBy the Middle Ages, the Christian influence on naming practices was pervasive. Each culture had its pool of names, which were a combination of native names and early Christian names that had been in the language long enough to be considered native. [ref]\n\n\nClient Request\nThis csv file contains the number of times a name was given to a child in a specific year. The Client has a passion for names throughout history. They would like to know how the usage of names has changed over time. They are particularly interested in the names Mary, Martha, Peter, and Paul. They would also like to know how the usage of a name from a famous movie has changed over time.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link” to use it to import the data into your project. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your project#.qmd file for it to work correclty in GitHub.\n\n\n\nURL: names_year.csv\nInformation: data.md\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe Readings section will contain links to reading assignments that are required for each project, as well as optional references. Remember that you are reading this material to build skills. Take the time to comprehend the readings and the skills contained within.\nWe recommend reading through the assigned material once for a general understanding before the first day of each project. You will reread and reference the material multiple times as you complete the project.\n\n\n\n\nP4DS: CH7 Workflow: Writing Code (Skim)\nP4DS: CH8 Data Import (Read)\nP4DS: CH14 Graphics for Communication (Read)\n\n\nOptional References\n\nThe query method\nEasy Data Visualiztation for Tidy Data with Lets-Plot\nExplore Your Data with Lets-Plot\n\n\n\n\nQuestions and Tasks (Core)\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis section lists the questions and tasks that need to be completed for the project. Your work on the project must be compiled into a report, rendered to a HTML file and uploaded in Canvas.\nThere are two types of questions: Core and Stretch. Core questions are required for each project. The course syllabus competencies requires specic a number of projects having all the Stretch questions achived based on your goals for the grade level you are seeking.\n\n\n\nDownload this Project1 Template template. The answer to each question should include a chart and a written response. The years labels on your charts should not include a comma. At least two of your charts must include reference marks.\n\nHow does your name at your birth year compare to its use historically?\n\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\n\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names in a single chart. What trends do you notice?\n\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\n\n\n\nQuestions and Tasks (Stretch)\nHere is an example Stretch question(s) for this project. Your instructor may assign different Stretch question(s). You must comment in Canvas when submitting your project if you completed any of the Stretch questions.\n\nReproduce the chart Elliot using the data from the names_year.csv file.\n\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the P1_template open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop P1_template.qmd into the terminal this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\n\n\n\n\n\n\nNote\n\n\n\n\n\nDeliverables are “the quantifiable goods or services that must be provided upon the completion of a project”. In this class the deliverable for each project is a GitHub published report created using Quarto files. This final section will be the same for each project.\n\n\n\nUse this P1_template to submit your Client Report.\n\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\nA short summary of work must be submitted in the comments in Canvas wwhen you submit the URL. Rate your own work on a scale of 1-5. 1 being poor and 5 being excellent. Include a short description of why you rated your work the way you did.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\nFeedback:\n\n\n\n\n\n\nNote\n\n\n\n\n\nIf you submit before the due date, you will recieve feedback and/or coaching notes. You will need to address the feedback, re-render and resubmit the project.\n\n\n\n\n\nResubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nIf you submit before the due date, you will have one opportunity to resubmit the project after you have received feedback. The window for the resubmission will be open through the Wednesday following the due date of the project.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 1: What's in a Name?"
    ]
  },
  {
    "objectID": "Projects/project_3.html",
    "href": "Projects/project_3.html",
    "title": "Project 3: Late Flights & Missing Data (JSON)",
    "section": "",
    "text": "Walkthrough\n\n\n\nSetup\nInstall Git & GitHub\n\n\nBackground\nDelayed flights are not something most people look forward to. In the best case scenario you may only wait a few extra minutes for the plane to be cleaned. However, those few minutes can stretch into hours if a mechanical issue is discovered or a storm develops. Arriving hours late may result in you missing a connecting flight, job interview, or your best friend’s wedding.\nIn 2003 the Bureau of Transportation Statistics (BTS) began collecting data on the causes of delayed flights. The categories they use are Air Carrier, National Aviation System, Weather, Late-Arriving Aircraft, and Security. You can visit the BTS website to read definitions of these categories.\n\n\nClient Request\nThe JSON file for this project contains information on delays at 7 airports over 10 years. Your task is to clean the data, search for insights about flight delays, and communicate your results to the Client. The Client is a CEO of a flight booking app who is interested in the causes of flight delays and wants to know which airports have the worst delays. They also want to know the best month to fly if you want to avoid delays of any length.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link” to use it to import the data into your project. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your project#.qmd file for it to work correclty in GitHub.\n\n\n\nURL: JSON File\nInformation: Data Description\nSubject Matter: Types of Delay\n\n\nReadings\n\nP4DS: CH4 Data Transformation (Read)\nP4DS: CH6 Tidy Data (Read)\nP4DS: CH11 Visualization (Read)\nP4DS: CH12 Layers (Skim)\nP4DS: CH13 Exploratory Data Analysis (Skim)\nP4DS: CH21 Missing Values (Read)\nP4DS: Ch25.3 JSON (Read)\n\n\nOptional References\n\nPython Data Science Handbook: Missing Data\nHandling Missing Data\nWikipedia Missing Data\nisin method\nwhere method\nnp.where method\nreplace method\nAn introduction to JSON (May need to open in ingognito to read.)\nThe key word in ‘Data Science’ is not Data…\nHow to Handle Missing Data (May need to open in ingognito to read.)\nLambda Function\n\n\n\n\nQuestions and Tasks (Core)\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis section lists the questions and tasks that need to be completed for the project. Your work on the project must be compiled into a report, rendered to HTML file in a Course Portfolio a link to that project page uploaded in Canvas.\nThere are two types of questions: Core and Stretch. Core questions are required for each project. The course syllabus competencies requires specic a number of projects having all the Stretch questions achived based on your goals for the grade level you are seeking.\n\n\n\n\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.__\nWhich airport has the worst delays? Describe the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nWhat is the best month to fly if you want to avoid delays of any length? Describe the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations:\n\n100% of delayed flights in the Weather category are due to weather\n\n30% of all delayed flights in the Late-Arriving category are due to weather\n\nFrom April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%\n\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Describe what you learn from this graph.\n\n\n\nQuestions and Tasks (Stretch)\nHere is an example Stretch question(s) for this project. Your instructor may assign different Stretch question(s). You must comment in Canvas when submitting your project if you completed any of the Stretch questions.\n\nWhich delay is the worst delay? Create a similar analysis as above for Weahter Delay with: Carrier Delay and Security Delay. Compare the proportion of delay for each of the three categories in a Chart and a Table. Describe your results.\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the Course Work Portfolio open in VS Code and open Projects/Project3.qmd\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\nDeliverables:\n\n\n\n\n\n\nNote\n\n\n\n\n\nDeliverables are “the quantifiable goods or services that must be provided upon the completion of a project”. In this class the deliverable for each project is a GitHub published report created using Quarto files. This final section will be the same for each project.\n\n\n\nUse this P3_template to submit your Client Report. The template has two sections:\n\nA short elevator pitch that highlights key values or metrics from the results. Describing these key insights to interest or hook the reader to want to read more about your work. The writing style should be more technical with some creative elements. Do not summarize what you did.\n\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\nIn Canvas write short summary of work must be submitted in the comments when you submit the URL. Rate your own work on a scale of 1-5. 1 being poor and 5 being excellent. Include a short description of why you rated your work the way you did.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and pushed to GitHub. Submit a URL of the rendered project in Canvas. (Do not submit the URL to the GitHub .qmd file)\n\n\n\n\n\nFeedback:\n\n\n\n\n\n\nNote\n\n\n\n\n\nYou will recieve feedback and/or coaching notes in the form of a GitHub issue. You will need to address the feedback, re-render and resubmit the project, and mark the GitHub issue as closed.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 3: Late Flights and Missing Data (JSON)"
    ]
  },
  {
    "objectID": "Projects/project_5.html",
    "href": "Projects/project_5.html",
    "title": "Project 5: The War with Star Wars",
    "section": "",
    "text": "Walkthrough\n\n\n\nBackground\nSurvey data is notoriously difficult to munge. Even when the data is recorded cleanly the options for ‘write in questions’, ‘choose from multiple answers’, ‘pick all that are right’, and ‘multiple choice questions’ makes storing the data in a tidy format difficult.\nIn 2014, FiveThirtyEight surveyed over 1000 people to write the article titled, America’s Favorite ‘Star Wars’ Movies (And Least Favorite Characters). They have provided the data on GitHub.\nFor this project, your client would like to use the Star Wars survey data to figure out if they can predict an interviewing job candidate’s current income based on a few responses about Star Wars movies.\n\n\nClient Request\nThe Client is who performed the survey but outsourced the analitics to a 3rd party. They want you to clean up the data so you can: a. Validate the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article a. Determine if you predict if a person from the survey makes more than $50k\n\n\nData\nURL: StarWars.csv\nInformation: Article\n\n\nReadings\n\nP4DS: CH6 Tidy Data (Skim)\nP4DS: CH14 Graphics for Communication (Skim)\nP4DS: CH16 Numbers (Read)\nP4DS: CH17 Strings and Text (Read)\nP4DS: Ch18 Regular Expressions (Read)\nP4DS: CH19 Categorical Data (Read)\n\n\nOptional References\n\nWhy to not use get_dummies\n\n\n\n\nQuestions and Tasks (Core)\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis section lists the questions and tasks that need to be completed for the project. Your work on the project must be compiled into a report, rendered to HTML file in a Course Portfolio a link to that project page uploaded in Canvas.\nThere are two types of questions: Core and Stretch. Core questions are required for each project. The course syllabus competencies requires specic a number of projects having all the Stretch questions achived based on your goals for the grade level you are seeking.\n\n\n\n\nShorten the column names and clean them up for easier use with pandas. Provide a table or list that exemplifies how you fixed the names.\nClean and format the data so that it can be used in a machine learning model. As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.\n\nFilter the dataset to respondents that have seen at least one film\n\nCreate a new column that converts the age ranges to a single number. Drop the age range categorical column\n\nCreate a new column that converts the education groupings to a single number. Drop the school categorical column\n\nCreate a new column that converts the income ranges to a single number. Drop the income range categorical column\n\nCreate your target (also known as “y” or “label”) column based on the new income range column\n\nOne-hot encode all remaining categorical columns\n\nValidate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.\nBuild a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.\n\n\n\nQuestions and Tasks (Stretch)\nHere is an example Stretch question(s) for this project. Your instructor may assign different Stretch question(s). You must comment in Canvas when submitting your project if you completed any of the Stretch questions.\n\nBuild a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.\nValidate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.\nCreate a new column that converts the location groupings to a single number. Drop the location categorical column.\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the Course Work Portfolio open in VS Code and open Projects/Project5.qmd\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\nDeliverables:\nUse this P5_template to submit your Client Report. The template has two sections:\n\nA short elevator pitch that highlights key values or metrics from the results. Describing these key insights to interest or hook the reader to want to read more about your work. The writing style should be more technical with some creative elements. Do not summarize what you did.\n\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\nA short summary of work must be submitted in the comments in Canvas wwhen you submit the URL. Rate your own work on a scale of 1-5. 1 being poor and 5 being excellent. Include a short description of why you rated your work the way you did.\n\n\n\nFeedback:\n\n\n\n\n\n\nNote\n\n\n\n\n\nYou will recieve feedback and/or coaching notes in the form of a GitHub issue. You will need to address the feedback, re-render and resubmit the project, and mark the GitHub issue as closed.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 5: The War with Star Wars"
    ]
  },
  {
    "objectID": "Projects/unit1_task1.html",
    "href": "Projects/unit1_task1.html",
    "title": "Unit 1 Task 1: Exploring Names",
    "section": "",
    "text": "Background\nEarly in prehistory, some descriptive names began to be used again and again until they formed a name pool for a particular culture. Parents would choose names from the pool of existing names rather than invent new ones for their children.\nWith the rise of Christianity, certain trends in naming practices manifested. Christians were encouraged to name their children after saints and martyrs of the church. These early Christian names can be found in many cultures today, in various forms. These were spread by early missionaries throughout the Mediterranean basin and Europe.\nBy the Middle Ages, the Christian influence on naming practices was pervasive. Each culture had its pool of names, which were a combination of native names and early Christian names that had been in the language long enough to be considered native. [ref]\n\n\nClient Request\nThis csv file contains the number of times a name was given to a child in a specific year. The Client has a passion for names throughout history. They would like to know how the usage of names has changed over time. They are particularly interested in the names Mary, Martha, Peter, and Paul. They would also like to know how the usage of a name from a famous movie has changed over time.\n\n\nData\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link”. You can use that copied URL in your code to read in the data. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your quarto file for the assignment in order for it to work correclty in GitHub.\nURL: names_year.csv\nInformation: data.md\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nComplete these readings before we cover the material in class. This will help you retain the material and make the class period more engaging - not less.\nIn other words, if an assignment is due on Wednesday, we will cover the material needed to complete the assignment on Tuesday. Therefore, you should complete the readings on Monday (or anytime before class on Tuesday).\n\n\n\n\nPandas Tutorial 1: What kind of data does pandas handle?\nPandas Tutorial 2: How do I read and write tabular data?\nPandas Tutorial 3: How do I select a subset of a DataFrame?\nP4DS: Chapter 4.3 Manipulating rows in data frames\n\n\n\nQuestions and Tasks (Core)\nDownload this Unit 1 Task 1 template. The answer to each question should include code and an answer written in a full sentence.\n\nWhat was the earliest year that the name ‘Felisha’ was used?\n\nWhat year had the most babies named ‘David’? How many babies were named ‘David’ that year?\n\nWhat year did your name hit its peak? How many babies were named your name in that year?\nHow many babies are named ‘Oliver’ in the state of Utah for all years?\nIn the most recent year of data, what was the most common female name in Utah?\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the Unit1_Task1 template open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the file but also the entire course work portfolio into HTML files for review\nConfirm everything displays as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop unit1_task1.qmd into the terminal, this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\n\n\n\n\n\n\nNote\n\n\n\n\n\nDeliverables are “the quantifiable goods or services that must be provided upon the completion of a project”. In this class the deliverable for each project is a .html file report created using Quarto files. This final section will be the same for each project.\n\n\n\nUse this Unit1_Task1 template to submit your Client Report.\n\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, and any charts and/or tables.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit1_task3.html",
    "href": "Projects/unit1_task3.html",
    "title": "Unit 1 Task 3: Famous Names",
    "section": "",
    "text": "Background\nEarly in prehistory, some descriptive names began to be used again and again until they formed a name pool for a particular culture. Parents would choose names from the pool of existing names rather than invent new ones for their children.\nWith the rise of Christianity, certain trends in naming practices manifested. Christians were encouraged to name their children after saints and martyrs of the church. These early Christian names can be found in many cultures today, in various forms. These were spread by early missionaries throughout the Mediterranean basin and Europe.\nBy the Middle Ages, the Christian influence on naming practices was pervasive. Each culture had its pool of names, which were a combination of native names and early Christian names that had been in the language long enough to be considered native. [ref]\n\n\nClient Request\nThis csv file contains the number of times a name was given to a child in a specific year. The Client has a passion for names throughout history. They would like to know how the usage of names has changed over time. They are particularly interested in the names Mary, Martha, Peter, and Paul. They would also like to know how the usage of a name from a famous movie has changed over time.\n\n\nData\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link”. You can use that copied URL in your code to read in the data. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your quarto file for the assignment in order for it to work correclty in GitHub.\nURL: names_year.csv\nInformation: data.md\n\n\nReadings\nNo new readings. Review the previous readings as needed\n\nPandas Tutorial 1: What kind of data does pandas handle?\nPandas Tutorial 2: How do I read and write tabular data?\nPandas Tutorial 3: How do I select a subset of a DataFrame?\nP4DS: Chapter 4.3 Manipulating rows in data frames\nP4DS: Chapter 11 Visualisation\nP4DS: Chapter 12.1 - 12.3 Layers: Aesthetic mappings and geometries\nP4DS: Chapter 14.2 - 14.3 Labels, titles, contextual info, annotations\n\nOptional Readings:\n\nP4DS: Rest of Chapter 12\nP4DS: Rest of Chapter 14\n\n\n\nQuestions and Tasks\nDownload this Unit 1 Task 3 Template template. The answer to each question should include a chart and a written response. The years labels on your charts should not include a comma. At least one of your charts must include reference marks.\n\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names in a single chart. What trends do you notice?\n\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the Unit1_Task3 template open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the file but also the entire course work portfolio into HTML files for review\nConfirm everything displays as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop unit1_task3.qmd into the terminal, this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\n\n\n\n\n\n\nNote\n\n\n\n\n\nDeliverables are “the quantifiable goods or services that must be provided upon the completion of a project”. In this class the deliverable for each project is a .html file report created using Quarto files. This final section will be the same for each project.\n\n\n\nUse this Unit1_Task3 template to submit your Client Report.\n\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, and any charts and/or tables.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit2_task1.html",
    "href": "Projects/unit2_task1.html",
    "title": "Unit 2 Task 1: Batting Averages",
    "section": "",
    "text": "Setup\nSQL setup and test\n\n\nBackground\nWhen you hear the word “relationship” what is the first thing that comes to mind? Probably not baseball. But a relationship is simply a way to describe how two or more objects are connected. There are many relationships in baseball such as those between teams and managers, players and salaries, even stadiums and concession prices.\nThe graphs on Data Visualizations from Best Tickets show many other relationships that exist in baseball.\n\n\nClient Request\nFor this project, the Client wants you to use SQL queries called from within Python.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis project will use the Lahman Baseball Database. In order to complete this project, you will need to download the database and save it inside the DS250 folder (hopefully you have a folder dedicated to this class) next to the .qmd file you will be using for this assignment. Note: Right click the ‘Download’ link and select “Save Link As” to download the data to your computer.\n\n\n\nDownload: lahmansbaseballdb\nInformation: Lahman Data Dictionary\nSetup Instructions: See SQL Setup\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nComplete these readings before we cover the material in class. This will help you retain the material and make the class period more engaging - not less.\nIn other words, if an assignment is due on Wednesday, we will cover the material needed to complete the assignment on Tuesday. Therefore, you should complete the readings on Monday (or anytime before class on Tuesday).\n\n\n\nReview the set-up instructions in preparation for class.\nSQLite\nHere is some introduction to working with databases in Python\n\nP4DS: CH24.1-24.3, and 24.7 Databases\n\nThere are many flavors of SQL but most flavors have the same base commands. SQL queries are typed in the following pattern;\nSELECT -- &lt;columns&gt; and &lt;column calculations&gt;\nFROM -- &lt;table name&gt;\n  JOIN -- &lt;table name&gt;\n  ON -- &lt;columns to join&gt;\nWHERE -- &lt;filter condition on rows&gt;\nGROUP BY -- &lt;subsets for column calculations&gt;\nHAVING -- &lt;filter conditions on groups&gt;\nORDER BY -- &lt;how the output is returned in sequence&gt;\nLIMIT -- &lt;number of rows to return&gt;\nThe reading for this task are from this excellent SQL Guide. Read the following for this task:\n\nAll the categories in the “Basic” group (topics are grouped in the menu on the left side of the page).\nAnd, the following sections in the Intermediate group:\n\nAggregations\nGROUP BY and FILTER\nHAVING\n\n\n\nOptional References\n\nWhy SQL is beating NoSQL, and what this means for the future of data\n\n\n\n\nQuestions and Tasks\nDownload the Unit 2 Task 1 Template. Note: batting average is number of hits divided by the number of at-bats. It is a number between 0 and 1 that represents what % of the time a player gets a hit (as opposed to getting out, for example).\n\nWrite an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\nUse the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\nNow calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats over their entire career, and print the top 5 results.\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave the unit2_task1_template open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop unit2_task1_template.qmd into the terminal this will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\nUse this unit2_task1_template to submit your Client Report.\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit2_task3.html",
    "href": "Projects/unit2_task3.html",
    "title": "Unit 2 Task 4: Longevity of Players",
    "section": "",
    "text": "Background\nWhen you hear the word “relationship” what is the first thing that comes to mind? Probably not baseball. But a relationship is simply a way to describe how two or more objects are connected. There are many relationships in baseball such as those between teams and managers, players and salaries, even stadiums and concession prices.\nThe graphs on Data Visualizations from Best Tickets show many other relationships that exist in baseball.\n\n\nClient Request\nFor this project, the Client wants SQL queries that they can use to retrieve data, then work with the data in pandas. They would also like to see the results in Lets-Plot charts.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis project will use the Lahman Baseball Database. In order to complete this project, you will need to download the database and save it inside the DS250 folder (hopefully you have a folder dedicated to this class) next to the .qmd file you will be using for this assignment. Note: Right click the ‘Download’ link and select “Save Link As” to download the data to your computer.\n\n\n\nDownload: lahmansbaseballdb\nInformation: Lahman Data Dictionary\nSetup Instructions: See SQL Setup\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nComplete these readings before we cover the material in class. This will help you retain the material and make the class period more engaging - not less.\nIn other words, if an assignment is due on Wednesday, we will cover the material needed to complete the assignment on Tuesday. Therefore, you should complete the readings on Monday (or anytime before class on Tuesday).\n\n\n\nOptional - P4DS: CH20.7 Working with Date Times in Dataframes\n\n\nQuestions and Tasks\nDownload the the template for this task.\n\nIdentify the top 10 players with the longest Major League Baseball careers. Include their:\n\nplayerID\nfirst_name\nlast_name\ncareer_length\n\n\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop this assignment into the terminal. This will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\nUse the template for this task to submit your Client Report.\nAnswers to the questions | tasks. Each should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit2_task4.html",
    "href": "Projects/unit2_task4.html",
    "title": "Unit 2 Task 4: Highest Paid Positions",
    "section": "",
    "text": "Background\nWhen you hear the word “relationship” what is the first thing that comes to mind? Probably not baseball. But a relationship is simply a way to describe how two or more objects are connected. There are many relationships in baseball such as those between teams and managers, players and salaries, even stadiums and concession prices.\nThe graphs on Data Visualizations from Best Tickets show many other relationships that exist in baseball.\n\n\nClient Request\nFor this project, the Client wants SQL queries that they can use to retrieve data, then work with the data in pandas. They would also like to see the results in Lets-Plot charts.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis project will use the Lahman Baseball Database. In order to complete this project, you will need to download the database and save it inside the DS250 folder (hopefully you have a folder dedicated to this class) next to the .qmd file you will be using for this assignment. Note: Right click the ‘Download’ link and select “Save Link As” to download the data to your computer.\n\n\n\nDownload: lahmansbaseballdb\nInformation: Lahman Data Dictionary\nSetup Instructions: See SQL Setup\n\n\nReadings\n\n\n\n\n\n\nNote\n\n\n\n\n\nComplete these readings before we cover the material in class. This will help you retain the material and make the class period more engaging - not less.\nIn other words, if an assignment is due on Wednesday, we will cover the material needed to complete the assignment on Tuesday. Therefore, you should complete the readings on Monday (or anytime before class on Tuesday).\n\n\n\nThere are many flavors of SQL but most flavors have the same base commands. SQL queries are typed in the following pattern;\nSELECT -- &lt;columns&gt; and &lt;column calculations&gt;\nFROM -- &lt;table name&gt;\n  JOIN -- &lt;table name&gt;\n  ON -- &lt;columns to join&gt;\nWHERE -- &lt;filter condition on rows&gt;\nGROUP BY -- &lt;subsets for column calculations&gt;\nHAVING -- &lt;filter conditions on groups&gt;\nORDER BY -- &lt;how the output is returned in sequence&gt;\nLIMIT -- &lt;number of rows to return&gt;\nReading you may find useful (depending on how you approach the assignment):\n\nInline subqueries\nCASE\nWITH\n\n\n\nQuestion 1\n\nWrite an SQL query that provides a summary table showing the average salary for each position (e.g., pitcher, catcher, outfielder). Position information can be found in the fielding table in the POS column.\n\nInclude the following columns:\n- position\n- average_salary\n- total_players\n- highest_salary\nThe highest_salary column should display the highest salary ever earned by a player in that position.\n\nAdditionally, create a new column called salary_category using a case statement:\n\nIf the average salary is above $3 million, categorize it as “High Salary.”\nIf the average salary is between $2 million and $3 million, categorize it as “Medium Salary.”\nOtherwise, categorize it as “Low Salary.”\n\nOrder the table by average salary in descending order.\n\nHint: Beware, it is common for a player to play multiple positions in a single year. For this analysis, each player’s salary should only be counted toward one position in a given year: the position at which they played the most games that year. This will likely require a (sub-query)\n\n\nSubmission:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report, you will need to follow this process to submit your work:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open a VS Code Terminal\n\nclick Terminal in the top menu bar and then New Terminal\n\nType the following in the terminal quarto render\n\nThen drag and drop this assignment into the terminal. This will add the file path to the terminal command\nPress Enter\n\nThis will render the project into a HTML file in the same location as the .qmd file\nTo locate the file in VS Code\n\nRight click on the file in the file explorer and select Reveal in File Explorer(Win) or Reveal in Finder(Mac)\n\nUpload HTML file into Canvas\n\n\n\n\n\n\nDeliverables:\nNo template is provided. Create a new quarto file for this assignment. It is part of stretching yourself. But don’t forget to include a 1 paragraph write-up / summary description of your results!\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour report should be written in quarto markdown files and rendered to an HTML File. Upload the HTML file in Canvas. (Do not submit the .qmd file)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit3_task2.html",
    "href": "Projects/unit3_task2.html",
    "title": "Project 3: Weather Delays",
    "section": "",
    "text": "Background\nDelayed flights are not something most people look forward to. In the best case scenario you may only wait a few extra minutes for the plane to be cleaned. However, those few minutes can stretch into hours if a mechanical issue is discovered or a storm develops. Arriving hours late may result in you missing a connecting flight, job interview, or your best friend’s wedding.\nIn 2003 the Bureau of Transportation Statistics (BTS) began collecting data on the causes of delayed flights. The categories they use are Air Carrier, National Aviation System, Weather, Late-Arriving Aircraft, and Security. You can visit the BTS website to read definitions of these categories.\n\n\nClient Request\nThe JSON file for this project contains information on delays at 7 airports over 10 years. Your task is to clean the data, search for insights about flight delays, and communicate your results to the Client. The Client is a CEO of a flight booking app who is interested in the causes of flight delays and wants to know which airports have the worst delays. They also want to know the best month to fly if you want to avoid delays of any length.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link” to use it to import the data into your project. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your .qmd file for it to work correclty in GitHub.\n\n\n\nURL: JSON File\nInformation: Data Description\nSubject Matter: Types of Delay\n\n\nReadings\n\nP4DS: CH4 Data Transformation\nP4DS: CH13 Exploratory Data Analysis\n\n\nOptional References\nRecommended! - BYUI DS Programming CH5.5 - Lambda Function\n\n\n\nQuestions\n\nWhich airport has the worst delays? Describe the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations:\n\n100% of delayed flights in the Weather category are due to weather\n\n30% of all delayed flights in the Late-Arriving category are due to weather\n\nFrom April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%\n\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Describe what you learn from this graph.\n\n\n\nSubmission / Deliverables:\nUse this unit3_task2_template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit3_task4.html",
    "href": "Projects/unit3_task4.html",
    "title": "Project 3: Comparing Delay Types",
    "section": "",
    "text": "Background\nDelayed flights are not something most people look forward to. In the best case scenario you may only wait a few extra minutes for the plane to be cleaned. However, those few minutes can stretch into hours if a mechanical issue is discovered or a storm develops. Arriving hours late may result in you missing a connecting flight, job interview, or your best friend’s wedding.\nIn 2003 the Bureau of Transportation Statistics (BTS) began collecting data on the causes of delayed flights. The categories they use are Air Carrier, National Aviation System, Weather, Late-Arriving Aircraft, and Security. You can visit the BTS website to read definitions of these categories.\n\n\nClient Request\nThe JSON file for this project contains information on delays at 7 airports over 10 years. Your task is to clean the data, search for insights about flight delays, and communicate your results to the Client. The Client is a CEO of a flight booking app who is interested in the causes of flight delays and wants to know which airports have the worst delays. They also want to know the best month to fly if you want to avoid delays of any length.\n\n\nData\n\n\n\n\n\n\nNote\n\n\n\n\n\nEvery data science project should start with data, and our class projects are no different. Each project will have ‘URL’ and ‘Information’ links like the ones below. Right click the ‘URL’ link and select “Copy Link” to use it to import the data into your project. This is the preferred method to get data into your report as you will be publishing your report to GitHub. If you choose to download the data file to your computer you will need to save it in the same folder as your .qmd file for it to work correclty in GitHub.\n\n\n\nURL: JSON File\nInformation: Data Description\nSubject Matter: Types of Delay\n\n\nReadings\n\nBYUI DS Programming CH12.1-12.3 Tidy Data, Pivoting, the rest of chapter 12 is good too\n\n\n\nQuestions\n\nWhich delay is the worst delay? Build on the analysis you already did regarding Weahter Delay. This time though, instead of comparing one type of delay across multiple airports, we want to compare Weather Delay (an involved calculation that you already did in a previous task) with Carrier Delay and Security Delay (both of which are in the dataset and don’t need fancy calculations like Weather did). Compare the proportion of delay for each of the three categories in a Chart and a Table. Describe your results.\nCreate another chart that shows the proportion of delays for each reason (Weather, Carrier, and Security) across all 7 airports. Describe your results.\n\n\n\nSubmission / Deliverables:\nNo template is provided. You must create your own file. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables._\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit4_task2.html",
    "href": "Projects/unit4_task2.html",
    "title": "Unit 4, Task 2: How good is it, really?",
    "section": "",
    "text": "Background\nThe clean air act of 1970 was the beginning of the end for the use of asbestos in home building. By 1976, the U.S. Environmental Protection Agency (EPA) was given authority to restrict the use of asbestos in paint. Homes built during and before this period are known to have materials with asbestos You can read more about this ban.\nThe state of Colorado has a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\nColorado gave you home sales data for the city of Denver from 2013 on which to train your model. They said all the column names should be descriptive enough for your modeling and that they would like you to use the latest machine learning methods.\n\n\nClient Request\nThe Client is a state agency in Colorado that is responsible for the health and safety of its residents. They have a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\n\n\nData\nURL: dwellings_ml.csv (ml ready)\nOptional URL: dwellings_neighborhoods_ml.csv (ml ready)\nInformational URL: dwellings_denver.csv (not cleansed)\nInformation: Data description\n\n\nReadings\n\nHow to choose a good evaluation metric for your Machine learning model\nIdentify and graph feature importance (especially method 1)\nExhaustive list of classifiers in scikit-Learn (skim)\n\n\nOptional References\n\nPros and cons of popular classifiers\nAnother overview and description of pros and cons for popular classifiers and regression models\n\n\n\n\nQuestions\n\nDescribe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.\nJustify your classification model by discussing the most important features selected by your model. This discussion should include a feature importance chart and a description of the features.\n\n\n\nSubmission / Deliverables:\nUse this unit4_task2_template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit4_task4.html",
    "href": "Projects/unit4_task4.html",
    "title": "Unit 4 Stretch: Regression ML",
    "section": "",
    "text": "Background\nThe clean air act of 1970 was the beginning of the end for the use of asbestos in home building. By 1976, the U.S. Environmental Protection Agency (EPA) was given authority to restrict the use of asbestos in paint. Homes built during and before this period are known to have materials with asbestos You can read more about this ban.\nThe state of Colorado has a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\nColorado gave you home sales data for the city of Denver from 2013 on which to train your model. They said all the column names should be descriptive enough for your modeling and that they would like you to use the latest machine learning methods.\n\n\nClient Request\nThe Client is a state agency in Colorado that is responsible for the health and safety of its residents. They have a large portion of their residential dwelling data that is missing the year built and they would like you to build a predictive model that can classify if a house is built pre 1980.\n\n\nData\nURL: dwellings_ml.csv (ml ready)\nOptional URL: dwellings_neighborhoods_ml.csv (ml ready)\nInformational URL: dwellings_denver.csv (not cleansed)\nInformation: Data description\n\n\nReadings\n\nP4DS: CH22 Joins\nAll regressor algorithms in scikit-learn (skim)\nHow to choose a good evaluation metric for your Machine learning model (you can start in section 11 - Evaluating for regression problems)\n\n\nOptional References\n\nAnother overview and description of pros and cons for popular classifiers and regression models\nBoosted algorithms in scikit-learn\n\n\n\n\nQuestions\n\nRepeat the classification model using 3 different algorithms. Display their Feature Importance, and Classification Report. Explian the differences between the models and which one you would recommend to the Client.\nJoin the dwellings_neighborhoods_ml.csv data to the dwelling_ml.csv on the parcel column to create a new dataset. Duplicate the code for the model you recommended in the stretch question above and update it to use this data. Explain the differences and if this changes the model you recomend to the Client.\nCan you build a model that predicts the year a house was built? Note this is a regression ML model, not a classifier. Report appropriate evaluation metrics for the model. Explain the model and the evaluation metrics you used to determine if the model is good.\n\n\n\nSubmission / Deliverables:\nNo template is provided for this assignment. You must create your own file as part of the task. Answer the questions in this assignment. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit5_task1_bits.html",
    "href": "Projects/unit5_task1_bits.html",
    "title": "Project 5: The war with Star Wars",
    "section": "",
    "text": "Background\nSurvey data is notoriously difficult to munge. Even when the data is recorded cleanly the options for ‘write in questions’, ‘choose from multiple answers’, ‘pick all that are right’, and ‘multiple choice questions’ makes storing the data in a tidy format difficult.\nIn 2014, FiveThirtyEight surveyed over 1000 people to write the article titled, America’s Favorite ‘Star Wars’ Movies (And Least Favorite Characters). They have provided the data on GitHub.\nFor this project, your client would like to use the Star Wars survey data to figure out if they can predict an interviewing job candidate’s current income based on a few responses about Star Wars movies.\n\n\nClient Request\nThe Client is who performed the survey but outsourced the analitics to a 3rd party. They want you to clean up the data so you can: a. Validate the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article a. Predict if a person from the survey makes at least $50k\n\n\nData\nURL: StarWars.csv\nInformation: Article\n\n\nReadings\n\nBYUI DS Programming: CH12 Tidy Data\nP4DS: CH16 Numbers\nVideo on regular expression\nP4DS: CH17 Strings and Text\nP4DS: Ch18 Regular Expressions\n\n\n\nQuestions\n\nShorten the column names and clean them up for easier use with pandas. Provide a table or list that exemplifies how you fixed the names.\nFilter the dataset to 835 respondents that have seen at least one film (Hint: Don’t use the column Have you seen any of the 6 films in the Star Wars franchise?)\nValidate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article. These visuals should be similar, including titles, subtitles, gridlines, order of categories, colors, etc. But, they don’t have to be exact. They need to be close enough that we can validate that the values in the dataset match the graphs in the chart. Though their charts were built using a different plotting software, the more you push yourself for an exact replica, the more you will learn. Spend at least a couple of hours on this.\n\n\n\nSubmission / Deliverables:\nUse this unit5_task1_template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit5_task3.html",
    "href": "Projects/unit5_task3.html",
    "title": "Project 5: Star Wars for Dummies",
    "section": "",
    "text": "Background\nSurvey data is notoriously difficult to munge. Even when the data is recorded cleanly the options for ‘write in questions’, ‘choose from multiple answers’, ‘pick all that are right’, and ‘multiple choice questions’ makes storing the data in a tidy format difficult.\nIn 2014, FiveThirtyEight surveyed over 1000 people to write the article titled, America’s Favorite ‘Star Wars’ Movies (And Least Favorite Characters). They have provided the data on GitHub.\nFor this project, your client would like to use the Star Wars survey data to figure out if they can predict an interviewing job candidate’s current income based on a few responses about Star Wars movies.\n\n\nClient Request\nThe Client is who performed the survey but outsourced the analitics to a 3rd party. They want you to clean up the data so you can: a. Validate the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article a. Predict if a person from the survey makes at least $50k\n\n\nData\nURL: StarWars.csv\nInformation: Article\n\n\nReadings\n\nP4DS: CH14.4-14.8 Graphics for Communication\nP4DS: CH17 Strings and Text (especially 17.4)\n\nReview previous readings as needed:\n\nBYUI DS Programming: CH12 Tidy Data\nP4DS: CH16 Numbers\nVideo on regular expression\nP4DS: CH17 Strings and Text\nP4DS: Ch18 Regular Expressions\n\n\n\nQuestions\n\nPrep the data for machine learning:\n\nCreate your target (also known as “y” or “label”) column based on the new income range column\n\nOne-hot encode all remaining categorical columns\n\nBuild a machine learning model that predicts whether a person makes at least $50k. Describe your model and report the accuracy.\n\n\n\nSubmission / Deliverables:\nRather than submitting something for each task of this unit, you will submit one client report at the end of the unit that is the culmination of all the tasks. Use this template to create your Client Report. Answer the questions. Each answer should include a written description of your results, code cells with comments, charts and/or tables.\n\n\n\n\n\n\nNote\n\n\n\n\n\nYour instructor will advise you, or it will be evident in Canvas, whether to submit an rendered .html file, or a link to the rendered file on GitHub on gh-pages. (Do not submit the URL to the GitHub .qmd file)\n\n\n\nHere are some reminder instructions if you are using GitHub:\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhen you have completed the report and are ready to submit it, you will need to render the project into HTML files and publish it to GitHub pages. Follow these steps:\n\nHave this assignment’s template/quarto file open in VS Code and nothing else\nClick Preview Button in VS Code in the top right of the screen\n\nThis will render the project but also entire course work portfolio into HTML files for review\nConfirm everything displas as you would like it to\nHow you see it will be how it is viewed for grading\nIf there is an error in any cell of the quarto files, the rendering will stop and you will need to fix the error before rendering again (if you get stuck post your error in Slack)\n\nOnce the report is confirmed close the preview and open the GitHub Desktop application\nConfirm you are in the correct repository in the top left corner of the screen\nConfirm you are on the correct branch Main in the top left corner of the screen (Never change off the Main branch)\nType a summary of the changes in the Summary box\nClick Commit to main blue button in the bottom left corner\nClick Push origin blue button in the middle right of the screen\n\nThis will push all your changes in the project .qmd file to GitHub\nThe publish.yml file will kick off an automated process to render the project into HTML files\nThe HTML files will be published to GitHub pages in the gh-pages branch\nThe URL to the published project will be in the deployment section in GitHub\n\nIn GitHub Desktop click Open in GitHub to navigete to the repository\nClick on the Actions tab and make sure there were no errors in the rendering process\nClick on the deployment section of the main page of the repository to find the URL\nNavigate to the URL and confirm it displays as you intended\nCopy the URL and submit it in Canvas\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/unit6.html",
    "href": "Projects/unit6.html",
    "title": "Project 6: Git Your DS Portfolio Online",
    "section": "",
    "text": "Background\nGitHub is an online platform where data scientists and developers can communicate and share work. It has also morphed into a tool to house all your work in a portfolio. Think about an Art student and how they have to develop their portfolio of various skills they have across the art classes. Similarly you will want to showcase you skillset across the Data Science skillsets.\nAs students, you will want to curate your creative work on GitHub using a program called Git. GitHub is the place to share your original work, not your homework assignments. The reading assignments will dive deaper into what to include in your portfolio and what not to include.\nMany people store their personal websites, blogs, and project websites on GitHub. Our textbook and course are hosted on GitHub, and you can see J. Hathaway’s or Ryan Hafen’s personal Data Science websites that are hosted on GitHub as well.\nFor this project, you will be making a public website that is a data science portfolio that will be hosted on GitHub. Your Resume will be one section of your portfolio/website. You should also post Data Science Society projects, personal projects, and any other data science related work you have done outside of class. Do not post any of the DS250 course work in this portfolio.\n\n\nData\nNone/missing/null/NA \n\n\nReadings\n\nNew to Git and GitHub? This Essential Beginners Guide is for you\nGit vs. GitHub: What is the difference between them?\nGit in Visual Studio Code video\nSetting up a website using Quarto documents\n\n\nOptional\n\nGit and GitHub for DS\nPull and Merge Forks on GitHub\nUsing Version Control in VS Code\n\n\nPortfolio Resources\n\nHow to Modify a Quarto Website\nHow to Create a Compelling GitHub Portfolio\nHow to Create a Professional Portfolio on GitHub\nData Science Portfolios That Will Get You the Job\n4 Data Science Portfolio Projects You Need to Create\nExample 1 - Data Science Portfolio\nExample 2 - Data Science Portfolio\n\n\n\n\n\nQuestions and Tasks\nThere are multiple ways to set-up a website using quarto documents. A succinct synopsis of the 3 ways is found here. We will walk through the first and 3rd ways.\nThe first option is to “Render sites on your local machine to the docs directory, check the rendered site into GitHub, and then configure your GitHub repo to publish from the docs directory. This is referred to as Method 1 below. We will show how to do this using a starting template, or from scratch. The 3rd option (also called Method 3) is to “Use a GitHub Action to automatically render your files and publish the resulting content whenever you push a source code (e.g. quarto file) change to your repository”. This will be illustrated using a template file as a starting point.\nChoose 1 of the 3 tabs below and follow those instructions for publishing a portfolio website hosted through your own personal GitHub repository.\n\nMethod 1: Use a template, publish from docsMethod 1: From scratch, publish from docsMethod 3: GitHub actions, gh-pages branch\n\n\n\nNavigate to the Data Science Portfolio2 repo in GitHub\nClick the green button ‘Use this template’ and select ‘Create a new repository’\na. Select yourself as owner\nb. Pick a professional name (potential employers will be seeing this)\nc. Choose ‘public’\nd. Click ‘create repository’\nCopy the url of the GitHub repo. You’ll need this when we return to VS Code\nModify ‘Pages’ Setting for build and deployment from \\docs folder\na. Click the Settings tab\nb. Scroll down to the Pages section on the left hand menu\nc. Change the branch option from “none” to “main”, and change the folder next to it from “/(root)” to “/docs”.  Don’t forget to click ‘Save’!\nd. Wait a couple of minutes and refresh your page. There should now be a url address to the website and a link that says “Visit Site”. This is the url address to your home page! You will want to come click on that later to access the website at the end of this process.\nNow go to VS Code\nClone the GitHub repository to your local machine\na. On the main page there is an option to ‘Clone Git Repository’\n\nb. You are prompted to paste the url to the GitHub repository at the top of your VS Code screen\n\nYou will then be asked where to store it. Create a new folder that does not reside within any other projects or GitHub repo folders. Select that newly created folder\n\nYou can now make changes to any of the pages, delete pages, or add pages. Be sure to render or preview the pages you made changes to. This will create the .html file the website needs and store it in the docs folder.\nNote: If you make changes to the menu options along the top or side of the website by editing the _quarto.yml file you will need to render the entire website (since those options are on every page). To do that, type `quarto render` in the terminal.\nWe will no implement the “pull, add, commit push” workflow in RStudio to send our local files to GitHub. To do this, go to the terminal and type the following commands:\n\ngit pull\ngit add .\ngit commit -m”a message of your choice”\ngit push\n\nNow let’s return to GitHub to see the “finished” product!\nIt may take a minute, but when you return to the website (see step 4d), any changes you made should be visible.\n\n\n\n\nGo to File -&gt; Open Folder\n\nCreate a new folder that does not reside within any other projects or folders associated with GitHub repos. Then select that folder as the one to open\n\nNow that we are inside that new folder in VS Code, in VS Code go to New File -&gt; Quarto Project. Choose Quarto Website. When prompted, select the folder that you just created.\n\nThis will populate the folder with a few new files. These are the beginnings of your website.\n\nYou will now have a _quarto.yml file show up in the folder. This file is like a yaml header for the entire website. It controls many website level  attributes, like top and side menus, file output type, etc.\n\nOpen the _quarto.yml file. Add output-dir: docs on line 3, so that it looks like the image below. The Save the file.\n\nNow we will create a GitHub repository to connect to this folder/project. We will use GitHub to host the website.\nGo to your GitHub home page. Click on the “Repositories” tab, and then click the big, green “new” button.\n\nChoose these settings on the next screen:\n\nChoose your own username as the “owner”. This is for your own personal use - even after the class, so don’t choose a school/class organization.\nGive the repo a name that is professional sounding, since this is what you will ultimately be sharing with future employers.\nA good description is nice, but optional\nChoose public (it won’t matter too much at this point, you can always change it later)\nLeave the other options at their defaults and click “Create repository”\n\nOn the next page, copy all the code it provides under the heading “…or create a new repository on the command line” so you can paste it into your terminal\n\nReturn to VS Code\nPaste the lines of code (right click paste) into the terminal and run them all. This will essentially connect your local folder in VSCode to the GitHub repository.\nThen run quarto render in the terminal. This will run all your files and build the website. You’ll notice that a docs folder has been created. That is where all the html files are stored, and it serves as the top level folder for your website.\nWe will now implement the “pull, add, commit, push” workflow in VSCode to sync our local files with the files on GitHub.\n\nSelect the source control (aka Git) icon on the left side menu.\n\n\n\nClick the ‘pull’ button. (Though this is technically not necessary at this step, it is important to get into the habit of always pulling before pushing.)\n\n\n\nType a message in the commit box. This is just for your own benefit\n\n\n\nClick the blue “Commit” button.\nThe click the “Sync” button to push the commited changes to GitHub\n\nNow return to your GitHub repo. You should see on the code page that some files are there, with your message showing. We will now configure GitHub to host the website.\nGo to the “Settings” menu/tab along the top\nAfter clicking Settings, there are various options along the left. Select “Pages”\nChange the branch from “None” to “Main”, then change the folder from “(root)” to “/docs”.\nDon’t forget to click “Save”.\n\n\n\nYou will have to wait a minute or two. Then you can refresh your page and you should see a url and a link to “Visit Site”. That’s where your website is located. Anyone can access that webpage!\n\n\n\n\n\n\nNote\n\n\n\nWith the correct folder open in VS Code, you can make changes to existing files and add files. Then follow the pull, add, commit, push process (Steps 10) and your website will update. To see other files (besides index) add the file name or path to the url. (Remember, it starts in the docs folder)\nNOTE: If you make changes to the _quarto.yml file, you will need to rebuild the website by running `quarto render` in the terminal before pushing to GitHub. Quarto render will rebuild every webpage on your site.\n\n\n\n\n\n** Video walk through of the instructions below**\n\nGit a Data Science Portfolio in GitHub (main page)\n\nUse the Portfolio Template on your Githhub root directory\n\nNavigate to the Data Science Portfolio repo in GitHub.\nClick the Green Button Use this template and select Create a new repository\n\nClick include all branches checkbox, this will include the gh-pages branch\n\nSelect yourself as the Owner\n\nName the repository as username.github.io where the username is your username on GitHub (Note: If the username part of the repository doesn’t exactly match your username, it won’t work, so make sure to get it right.)\nClick the Green Button Create repository\n\n\nCreate a new branch gh-pages if you forgot to check the include all branches box (skip otherwise)\n\nClick the Branch: main button then view all branches\n\nClick the New Branch button\n\nName the branch gh-pages and click the Green Button Create new branch\n\n\nModify Pages Settings for Build and deployment from main to gh-pages:\n\nClick the Settings tab\n\nScroll down to the Pages section in the left hand menu\n\nLocate the Build and deployment section and change Branch from main to gh-pages and leave the right side as /root\n\n\nClone the repository to your computer\n\nClick the &lt;&gt; Code menu\nClick the Green Button &lt;&gt; Code and select Open with GitHub Desktop\n\nClick the Button Open in Visual Studio Code \n\nUpdate the _quarto.yml file\n\nChange the title to your name\nChange the repo-url to your code repository url\nChange the page-footer left: to your name\nChange the page footer href: to your LinkedIn profile link\nScroll to the bottom and change the theme light: and/or dark: to another theme (optional)\n\nPush the changes to GitHub via GitHub Desktop\n\nMake sure your current repo in the top left is username.github.io\n\nType a commit message and click the Blue Button Commit to main\n\nClick the Blue Button Push origin\n\n\nConfirm the GitHub Actions are working\n\nNavigate to the repo in GitHub and click on the Actions tab\n\nConfirm the Update _quarto.yml is working by the yellow circle turning to a green check circle (Note: this can take 3-5min)\n\n\nFix the main page loading the ReadMe.md file\n\nRun quarto publish gh-pages in the terminal of VS Code\n\n\n\n\n\n\nPut your Resume online\n\nUpdate the resume.qmd file located at the top level folder with information about you. See P4DS: CH30 Markdown\nPush your results to GitHub. Then go online to verify it was successful.\n\n\n\n\nDeliverables\nSubmit a URL link to your resume as a webpage hosted on GitHub.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Setup/copilot_setup.html",
    "href": "Setup/copilot_setup.html",
    "title": "Getting started with GitHub Copilot",
    "section": "",
    "text": "GitHub Copilot is free to use for verified students, teachers, and maintainers of popular open source projects.",
    "crumbs": [
      "Setup",
      "Copilot"
    ]
  },
  {
    "objectID": "Setup/copilot_setup.html#footnotes",
    "href": "Setup/copilot_setup.html#footnotes",
    "title": "Getting started with GitHub Copilot",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n1↩︎\n2↩︎\nhttps://docs.github.com/en/copilot/using-github-copilot/getting-started-with-github-copilot#next-steps↩︎",
    "crumbs": [
      "Setup",
      "Copilot"
    ]
  },
  {
    "objectID": "Setup/python_lib.html",
    "href": "Setup/python_lib.html",
    "title": "Python for Data Science",
    "section": "",
    "text": "Install Python Libraries\n\n\n\nInstalling and Importing Packages\nThe Apple Silicon is still more difficult to get installed. You can use the following links to get it installed - Link 1, Link 2, Link 3.\nWe can get packages installed for this course using one of the two methods below.\n\nUsing your interactive Python (Jupyter server)\nThis is the preferred install method for both PC and Mac:\n#%%\n# copy paste this into a python file in vs code and run this cell\nimport sys\n!{sys.executable} -m pip install numpy pandas scikit-learn lets-plot palmerpenguins nbformat nbclient pyyaml setuptools\n\n\nUsing your terminal (alternative method)\n# default way\npip install numpy pandas scikit-learn lets-plot palmerpenguins nbformat nbclient pyyaml setuptools\n\n\n\n\nLearn More about the Packages you Installed\nWe want to install the following three packages;\n\npandas\nnumpy\nlets-plot\nscikit-learn\n\n\nLearn More About Python\nPython\n\n\nContinue to Install VS Code\nInstall VS Code\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup",
      "Python Libraries"
    ]
  },
  {
    "objectID": "Setup/quarto_setup.html",
    "href": "Setup/quarto_setup.html",
    "title": "Quarto for Data Science",
    "section": "",
    "text": "Quarto\n\nQuarto is an open-source scientific and technical publishing system built on Pandoc. You can create dynamic content with Python, R, Julia, and Observable.\nWe use this perfect union of Jupyter Notebooks and RMarkdown for reporting on our projects. It leverages Markdown and Python code chunks to create dynamic HTML content.\n\n\nMarkdown\nMarkdown is a plain text formatting syntax aimed at making writing more accessible. The philosophy behind Markdown is that plain text documents should be readable without tags making a mess, but there should still be ways to add text modifiers like lists, bold, italics, etc. It is an alternative to WYSIWYG (what you see is what you get) editors, which use rich text that later gets converted to proper HTML.\n\n\nQuarto Basics\nYou will need to install the Quarto CLI and then go through the VS Code directions on using Quarto with Python.\n\nInstall Quarto CLI \nDownload the class instructional template. Open it in VS Code and press the Preview button. It should produce a HTML file with a Lets-Plot Chart and a data table. (If it errors, it may be missing some libraries. Go back to the python library setup.)\n\n\n\nIf you still can not Preview your .qmd template file. Run quarto check in your Terminal section of VS Code and copy paste the ouput in a DM to your teacher or TA.\n\n\n\n\nQuarto Preview Tip\nWhen clicking on the Preview Icon  in the top right of your .qmd file, some students experience the preview rendering their entire course website. If this is the case, you can fix it by only opening the project.qmd file you are working on in VS-Code instead of opening the entire course folder.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup",
      "Quarto"
    ]
  },
  {
    "objectID": "Setup/sql_setup.html",
    "href": "Setup/sql_setup.html",
    "title": "SQL for Data Science",
    "section": "",
    "text": "SQLITE Setup\nThere is nothing to download to setup SQLITE This SQLite Viewer VS Code extension will be helpful to explore the database\n\n\nDownloads\nDownload this sqlite db file Save it in the same place as the .py or .qmd file created in the next step\n\n\nTest Your Setup\nCopy the code below and test it in a .py file. If everything works you are all set\nimport pandas as pd \nimport numpy as np\nimport sqlite3\n\n# %%\n# careful to list your path to the file or save it in the same place as your .qmd or .py file\nsqlite_file = 'lahmansbaseballdb.sqlite'\ncon = sqlite3.connect(sqlite_file)\n\nq = 'SELECT * FROM allstarfull LIMIT 5'\nresults = pd.read_sql_query(q,con)\n\nresults\nYou can see the list of tables available in the database\nq = '''\n    SELECT * \n    FROM sqlite_master \n    WHERE type='table'\n    '''\ntable = pd.read_sql_query(q,con)\ntable.filter(['name'])\n\n\n\n\n Back to top",
    "crumbs": [
      "Setup",
      "SQL"
    ]
  },
  {
    "objectID": "Skill Builders/git_github.html#before-you-start",
    "href": "Skill Builders/git_github.html#before-you-start",
    "title": "GitHub and Git",
    "section": "Before you start",
    "text": "Before you start\nMake sure you have gone through the tutorial on under course materials called Git: we assume that you have a connection to your data.\n\nComplete the Hello World GitHub Guide",
    "crumbs": [
      "Project 6: GitHub and Git"
    ]
  },
  {
    "objectID": "Skill Builders/json_missing.html",
    "href": "Skill Builders/json_missing.html",
    "title": "JSONs & Missing",
    "section": "",
    "text": "Link to json file\n\n\n\n\nRead in the json file as a pandas dataframe. After reading in the data, you’ll want to explore it and gain some intuition. Exploring data is a very important step — the more you know about your data the better! Answer the following questions to gain some insight into this dataset.\n\nHow many rows are there?\nHow many columns?\nWhat does a row represent in this dataset?\nWhat are the different ways missing values are encoded?\nHow many np.nan in each column?\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\n# Object/Categorical Columns\ndf.column_name.value_counts(dropna=False)\ndf.column_name.unique()\n\n# Numeric Columns\ndf.column_name.describe()\n\n# Counting missing values\ndf.isna().sum()  # Creates boolean dataframe and sums each column\n\n\n\n\n\n\n\nAfter learning different ways our data encodes missing values, now we will neatly manage them. There are many techniques we can use to handle missing values; for example, we can drop all rows that contain a missing value, impute with mean or median, or replace missing values with a new missing category. We will use some of these techniques in this exercise.\n\nshape_reported - replace missing values with missing string.\ndistance_reported - change -999 values to np.nan. (-999 is a typical way of encoding missing values.)\ndistance_reported - fill in missing values with the mean (imputation)\nwere_you_abducted - replace - string with missing string.\n\nThe first 10 rows of your data should look like this after completion of the above steps.\n\n\n\n\n\n\n\n\n\n\n\n\ncity\nshape_reported\ndistance_reported\nwere_you_abducted\nestimated_size\n\n\n\n\n0\nIthaca\nTRIANGLE\n8521.9\nyes\n5033.9\n\n\n1\nWillingboro\nOTHER\n7438.64\nno\n5781.03\n\n\n2\nHolyoke\nOVAL\n7438.64\nno\n697203\n\n\n3\nAbilene\nDISK\n7438.64\nno\n5384.61\n\n\n4\nNew York Worlds Fair\nLIGHT\n6615.78\nmissing\n3417.58\n\n\n5\nValley City\nDISK\n7438.64\nno\n4280.1\n\n\n6\nCrater Lake\nCIRCLE\n7377.89\nno\n528289\n\n\n7\nAlma\nDISK\n7438.64\nmissing\n4772.75\n\n\n8\nEklutna\nCIGAR\n5214.95\nno\n4534.03\n\n\n9\nHubbard\nCYLINDER\n8220.34\nmissing\n4653.72\n\n\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\ndf.column_name.replace(..., ..., inplace=True)\ndf.column_name.fillna(..., inplace=True)\n\n\n\n\n\n\n\nCreate a table that contains the following summary statistics. - median estimated size by shape - mean distance reported by shape - count of reports belonging to each shape\nYour table should look like this:\n\n\n\n\n\n\n\n\n\nshape_reported\nmedian_est_size\nmean_distance_reported\ngroup_count\n\n\n\n\nCIGAR\n5899.68\n6520.21\n3\n\n\nCIRCLE\n266002\n7408.26\n2\n\n\nCYLINDER\n4550.58\n8039.49\n2\n\n\nDISK\n4581.8\n7516.39\n16\n\n\nFIREBALL\n5407.22\n7097.78\n3\n\n\nFLASH\n6108.34\n7438.64\n1\n\n\nFORMATION\n5104.4\n8708.32\n2\n\n\nLIGHT\n3850.25\n7636.09\n2\n\n\nOTHER\n4699.4\n7473.98\n4\n\n\nOVAL\n4943.63\n7787.24\n4\n\n\nRECTANGLE\n3668.1\n6054.62\n2\n\n\nSPHERE\n5076.78\n7206.55\n6\n\n\nTRIANGLE\n5033.9\n8521.9\n1\n\n\nmissing\n250153\n7438.64\n2\n\n\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\n(df.groupby(...)\n     .agg(...,\n          ...,\n          ...))\n\n\n\n\n\n\n\nThe cities listed below reported their estimated size in square inches, not square feet. Create a new column named estimated_size_sqft in the dataframe, that has all the estimated sizes reported as sqft. (Hint: divide by 144 to go from sqin -&gt; sqft)\n\nHolyoke\nCrater Lake\nLos Angeles\nSan Diego\nDallas\n\nThe head of your data should look like this.\n\n\n\n\n\n\n\n\n\n\n\n\n\ncity\nshape_reported\ndistance_reported\nwere_you_abducted\nestimated_size\nestimated_size_sqft\n\n\n\n\n0\nIthaca\nTRIANGLE\n8521.9\nyes\n5033.9\n5033.9\n\n\n1\nWillingboro\nOTHER\n7438.64\nno\n5781.03\n5781.03\n\n\n2\nHolyoke\nOVAL\n7438.64\nno\n697203\n4841.69\n\n\n3\nAbilene\nDISK\n7438.64\nno\n5384.61\n5384.61\n\n\n4\nNew York Worlds Fair\nLIGHT\n6615.78\nmissing\n3417.58\n3417.58\n\n\n5\nValley City\nDISK\n7438.64\nno\n4280.1\n4280.1\n\n\n6\nCrater Lake\nCIRCLE\n7377.89\nno\n528289\n3668.68\n\n\n7\nAlma\nDISK\n7438.64\nmissing\n4772.75\n4772.75\n\n\n8\nEklutna\nCIGAR\n5214.95\nno\n4534.03\n4534.03\n\n\n9\nHubbard\nCYLINDER\n8220.34\nmissing\n4653.72\n4653.72\n\n\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nnp.where(...,  # Condition\n         ...,  # If condition is true\n         ...)  # If condition is false\n\n\n\n\n\n\n\n\n\n\nNoteAfter you have completed this skill builder with your team (or on your own) then compare your work to our script\n\n\n\n\n\nSee the script.",
    "crumbs": [
      "Project 2: JSON & Missing"
    ]
  },
  {
    "objectID": "Skill Builders/json_missing.html#skill-builder",
    "href": "Skill Builders/json_missing.html#skill-builder",
    "title": "JSONs & Missing",
    "section": "",
    "text": "Link to json file\n\n\n\n\nRead in the json file as a pandas dataframe. After reading in the data, you’ll want to explore it and gain some intuition. Exploring data is a very important step — the more you know about your data the better! Answer the following questions to gain some insight into this dataset.\n\nHow many rows are there?\nHow many columns?\nWhat does a row represent in this dataset?\nWhat are the different ways missing values are encoded?\nHow many np.nan in each column?\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\n# Object/Categorical Columns\ndf.column_name.value_counts(dropna=False)\ndf.column_name.unique()\n\n# Numeric Columns\ndf.column_name.describe()\n\n# Counting missing values\ndf.isna().sum()  # Creates boolean dataframe and sums each column\n\n\n\n\n\n\n\nAfter learning different ways our data encodes missing values, now we will neatly manage them. There are many techniques we can use to handle missing values; for example, we can drop all rows that contain a missing value, impute with mean or median, or replace missing values with a new missing category. We will use some of these techniques in this exercise.\n\nshape_reported - replace missing values with missing string.\ndistance_reported - change -999 values to np.nan. (-999 is a typical way of encoding missing values.)\ndistance_reported - fill in missing values with the mean (imputation)\nwere_you_abducted - replace - string with missing string.\n\nThe first 10 rows of your data should look like this after completion of the above steps.\n\n\n\n\n\n\n\n\n\n\n\n\ncity\nshape_reported\ndistance_reported\nwere_you_abducted\nestimated_size\n\n\n\n\n0\nIthaca\nTRIANGLE\n8521.9\nyes\n5033.9\n\n\n1\nWillingboro\nOTHER\n7438.64\nno\n5781.03\n\n\n2\nHolyoke\nOVAL\n7438.64\nno\n697203\n\n\n3\nAbilene\nDISK\n7438.64\nno\n5384.61\n\n\n4\nNew York Worlds Fair\nLIGHT\n6615.78\nmissing\n3417.58\n\n\n5\nValley City\nDISK\n7438.64\nno\n4280.1\n\n\n6\nCrater Lake\nCIRCLE\n7377.89\nno\n528289\n\n\n7\nAlma\nDISK\n7438.64\nmissing\n4772.75\n\n\n8\nEklutna\nCIGAR\n5214.95\nno\n4534.03\n\n\n9\nHubbard\nCYLINDER\n8220.34\nmissing\n4653.72\n\n\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\ndf.column_name.replace(..., ..., inplace=True)\ndf.column_name.fillna(..., inplace=True)\n\n\n\n\n\n\n\nCreate a table that contains the following summary statistics. - median estimated size by shape - mean distance reported by shape - count of reports belonging to each shape\nYour table should look like this:\n\n\n\n\n\n\n\n\n\nshape_reported\nmedian_est_size\nmean_distance_reported\ngroup_count\n\n\n\n\nCIGAR\n5899.68\n6520.21\n3\n\n\nCIRCLE\n266002\n7408.26\n2\n\n\nCYLINDER\n4550.58\n8039.49\n2\n\n\nDISK\n4581.8\n7516.39\n16\n\n\nFIREBALL\n5407.22\n7097.78\n3\n\n\nFLASH\n6108.34\n7438.64\n1\n\n\nFORMATION\n5104.4\n8708.32\n2\n\n\nLIGHT\n3850.25\n7636.09\n2\n\n\nOTHER\n4699.4\n7473.98\n4\n\n\nOVAL\n4943.63\n7787.24\n4\n\n\nRECTANGLE\n3668.1\n6054.62\n2\n\n\nSPHERE\n5076.78\n7206.55\n6\n\n\nTRIANGLE\n5033.9\n8521.9\n1\n\n\nmissing\n250153\n7438.64\n2\n\n\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\n(df.groupby(...)\n     .agg(...,\n          ...,\n          ...))\n\n\n\n\n\n\n\nThe cities listed below reported their estimated size in square inches, not square feet. Create a new column named estimated_size_sqft in the dataframe, that has all the estimated sizes reported as sqft. (Hint: divide by 144 to go from sqin -&gt; sqft)\n\nHolyoke\nCrater Lake\nLos Angeles\nSan Diego\nDallas\n\nThe head of your data should look like this.\n\n\n\n\n\n\n\n\n\n\n\n\n\ncity\nshape_reported\ndistance_reported\nwere_you_abducted\nestimated_size\nestimated_size_sqft\n\n\n\n\n0\nIthaca\nTRIANGLE\n8521.9\nyes\n5033.9\n5033.9\n\n\n1\nWillingboro\nOTHER\n7438.64\nno\n5781.03\n5781.03\n\n\n2\nHolyoke\nOVAL\n7438.64\nno\n697203\n4841.69\n\n\n3\nAbilene\nDISK\n7438.64\nno\n5384.61\n5384.61\n\n\n4\nNew York Worlds Fair\nLIGHT\n6615.78\nmissing\n3417.58\n3417.58\n\n\n5\nValley City\nDISK\n7438.64\nno\n4280.1\n4280.1\n\n\n6\nCrater Lake\nCIRCLE\n7377.89\nno\n528289\n3668.68\n\n\n7\nAlma\nDISK\n7438.64\nmissing\n4772.75\n4772.75\n\n\n8\nEklutna\nCIGAR\n5214.95\nno\n4534.03\n4534.03\n\n\n9\nHubbard\nCYLINDER\n8220.34\nmissing\n4653.72\n4653.72\n\n\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nnp.where(...,  # Condition\n         ...,  # If condition is true\n         ...)  # If condition is false\n\n\n\n\n\n\n\n\n\n\nNoteAfter you have completed this skill builder with your team (or on your own) then compare your work to our script\n\n\n\n\n\nSee the script.",
    "crumbs": [
      "Project 2: JSON & Missing"
    ]
  },
  {
    "objectID": "Skill Builders/munging.html#data",
    "href": "Skill Builders/munging.html#data",
    "title": "Munging Data",
    "section": "Data",
    "text": "Data\nLink to the data",
    "crumbs": [
      "Project 5: Munging Data"
    ]
  },
  {
    "objectID": "Skill Builders/munging.html#intro-to-cleaning-movies-data",
    "href": "Skill Builders/munging.html#intro-to-cleaning-movies-data",
    "title": "Munging Data",
    "section": "Intro to cleaning movies data",
    "text": "Intro to cleaning movies data\nThis skill builder focuses on munging (formatting) data into a machine learning ready dataset. We will be using an IMDB Ratings dataset. It contains columns that are categorical. Sklearn cannot handle columns that are strings, so we need to convert these into a numerical representation. We accomplish this by either one hot encoding, label encoding, or taking just one value of the range provided. There are many other ways to represent these columns as numbers, but they are beyond the scope of this course.\nOnce you’ve converted all columns to numeric, in an intelligent way, you will be asked to recreate a graph using Lets-Plot. Here is the head of the data you will be working with. Enjoy!\n\n\n\n\n\n\n\n\n\n\n\nstar_rating\ncontent_rating\ngenre\nduration\nbox_office_rev\nmajor_hit\n\n\n\n\n9.3\nR\nCrime\n142\n€1924521976 - €1925521976\nno\n\n\n9.2\nR\nCrime\n175\n€177034987 - €178034987\nno\n\n\n9.1\nR\nCrime\n200\n€2617541398 - €2618541398\nno\n\n\n9\nPG-13\nAction\n152\n€996115723 - €997115723\nno\n\n\n8.9\nR\nCrime\n154\n€1172054364 - €1173054364\nno\n\n\n\n\n\nExercise 1\n\nGrab the high range value for each movie and put it into a new column called high_range_rev.\n\nMake sure the data type of this new column is numeric!!\n\nRemove the box_office_rev column from the dataset.\n\nThe .str.split() and .astype() methods might be of use! Also, to get the euro sign just copy it from here, €, and put it in your code.\nThe first 5 rows of the resulting dataframe should look like this\n\n\n\n\n\n\n\n\n\n\n\nstar_rating\ncontent_rating\ngenre\nduration\nmajor_hit\nhigh_range_rev\n\n\n\n\n9.3\nR\nCrime\n142\nno\n2345444803\n\n\n9.2\nR\nCrime\n175\nno\n2182412593\n\n\n9.1\nR\nCrime\n200\nno\n1604872807\n\n\n9\nPG-13\nAction\n152\nno\n284317976\n\n\n8.9\nR\nCrime\n154\nyes\n1791932201\n\n\n\n\n\n\nExercise 2\nConvert the major_hit column to 1/0’s. yes -&gt; 1 and no -&gt; 0. Again, there are several ways to accomplish this. Using our old friend np.where is probably the easiest though.\nThe first 5 rows of the resulting dataframe should like this\n\n\n\n\n\n\n\n\n\n\n\nstar_rating\ncontent_rating\ngenre\nduration\nmajor_hit\nhigh_range_rev\n\n\n\n\n9.3\nR\nCrime\n142\n0\n1925521976\n\n\n9.2\nR\nCrime\n175\n0\n178034987\n\n\n9.1\nR\nCrime\n200\n0\n2618541398\n\n\n9\nPG-13\nAction\n152\n0\n997115723\n\n\n8.9\nR\nCrime\n154\n0\n1173054364\n\n\n\n\n\n\nExercise 3\nConvert the content_rating column using label encoding. We’re using label encoding in this case because the movie ratings already have a natural ordering to them. We will replace each rating with a number in it’s natural ascending order.\nTo be more specific, here is how we will do it.\n\nG: 0\nPG: 1\nPG-13: 2\nR: 3\n\nA dictionary and the .map() method could be useful for this exercise. There are other ways of tackling this problem though. Be creative!\nThe first 5 rows of the resulting dataframe should look like\n\n\n\n\n\n\n\n\n\n\n\nstar_rating\ncontent_rating\ngenre\nduration\nmajor_hit\nhigh_range_rev\n\n\n\n\n9.3\n3\nCrime\n142\n0\n1925521976\n\n\n9.2\n3\nCrime\n175\n0\n178034987\n\n\n9.1\n3\nCrime\n200\n0\n2618541398\n\n\n9\n2\nAction\n152\n0\n997115723\n\n\n8.9\n3\nCrime\n154\n0\n1173054364\n\n\n\n\n\n\nExercise 4\nThe last column that we need to take care of is genre. We will use one hot encoding for this. Make sure to ONLY one hot encode the genre column!\nA useful function for one hot encoding is pd.get_dummies(). I recommend checking out the documentation.\nThe resulting dataframe should look like the following example; don’t worry if your high_range_rev column turned into scientific notation—Pandas does this sometimes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstar_rating\ncontent_rating\nduration\nmajor_hit\nhigh_range_rev\ngenre_Action\ngenre_Adventure\ngenre_Animation\ngenre_Biography\ngenre_Comedy\ngenre_Crime\ngenre_Drama\ngenre_Family\ngenre_Fantasy\ngenre_Horror\ngenre_Mystery\ngenre_Sci-Fi\ngenre_Thriller\ngenre_Western\n\n\n\n\n0\n9.3\n3\n142\n0\n1.92552e+09\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n9.2\n3\n175\n0\n1.78035e+08\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n9.1\n3\n200\n0\n2.61854e+09\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n9\n2\n152\n0\n9.97116e+08\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n8.9\n3\n154\n0\n1.17305e+09\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\nExercise 5\nRecreate this graph as best you can. You’ll need to use the original data that specifies the actual rating.\n\n\n\n\n\n\n\n\nNoteAfter you have completed this skill builder with your team (or on your own) then compare your work to our script\n\n\n\n\n\nSee the script.",
    "crumbs": [
      "Project 5: Munging Data"
    ]
  },
  {
    "objectID": "Skill Builders/relational_data.html",
    "href": "Skill Builders/relational_data.html",
    "title": "SQL & Databases",
    "section": "",
    "text": "For this skill builder, we are exploring some important topics in relational databases. This exercise will require you to create SQL queries through python. You may want to at least scan the readings before beginning this task since this serves as an assessment of your understanding of the assigned readings.\nThis should be able to be finished within 75 minutes. Work through it on your own or in a group based in your professors instruction.",
    "crumbs": [
      "Project 3: SQL & Databases"
    ]
  },
  {
    "objectID": "Skill Builders/relational_data.html#skill-builder",
    "href": "Skill Builders/relational_data.html#skill-builder",
    "title": "SQL & Databases",
    "section": "",
    "text": "For this skill builder, we are exploring some important topics in relational databases. This exercise will require you to create SQL queries through python. You may want to at least scan the readings before beginning this task since this serves as an assessment of your understanding of the assigned readings.\nThis should be able to be finished within 75 minutes. Work through it on your own or in a group based in your professors instruction.",
    "crumbs": [
      "Project 3: SQL & Databases"
    ]
  },
  {
    "objectID": "Skill Builders/relational_data.html#before-you-start",
    "href": "Skill Builders/relational_data.html#before-you-start",
    "title": "SQL & Databases",
    "section": "Before you start",
    "text": "Before you start\nMake sure you have installed VS-code, pandas, and Plotly Express on your computer.\nAlso make sure you have gone through the tutorial on under course materials called SQL for Data Science: we assume that you have a connection to your data.\n\n\nExercise 1\n\nReadme file\nA database can consist of more than one table/data set. A relational database consists of tables/data sets that share columns. These shared columns then establish the relationship between the tables, thus the name relational database. The relations are sometimes not easily found and they require careful investigations.\nTo understand what is in a relational database, we can start with understanding the tables and the columns within.\nHere is a link to the readme file of the baseball database.\n\nWhat is the name of the table that records data about pitchers in the regular seasons?\n\n\nWhat do the HR and HBP columns mean in that table respectively?\n\n\n\n\n\nExcercise 2\n\nSELECT and FROM\nThe simplest SQL query is a query with SELECT and FROM. These are the keywords you will see again and again in SQL. Usually, when constructing a more complex query, it is easier to identify what goes into these two clauses first.\n\nCreate a query that shows all columns from the table you found in Exercise 1, save the dataframe in a variable “pitch”\n\n\n\n\n\n\n\nTipHint\n\n\n\n\n\nresult = pd.read_sql_query(\n    'SELECT _______ FROM _______',\n    con)\n\nresults\n\n\n\n\n\n\n\nExcercise 3\n\nWHERE\nThe WHERE keyword allows us to filter down the table horizontally (fewer rows).\nIt goes after SELECT and FROM.\n\nUsing a SQL query, select all rows in the same table where HR is lesser than 10 and gs is greater than 25.\n\n\nFind out what the columns mean and explain your query in words\n\n\n\n\n\nExcercise 4\n\nORDER BY\nORDER BY sort the table you select by one or more columns and goes after WHERE\n\nUsing the same query in exercise 2, edit it so that the table is ordered by the year of the season (nearest to furthermost) and the player ID (alphabetically).\n\n\n\n\n\nExcercise 5\n\nJoins\nJoins are used when you wish to create a new table through two different tables. Keep in mind that you have to identify the relationship between two tables before you can correctly join them.\nJOIN goes between FROM and WHERE.\n\nIdentify the shared columns (keys) and join the table in exercise 2 with the salaries table, then filter the data so that it shows only pitchers in the year 1986.\n\nYou should get a dataframe with 306 rows.\n\n\n\n\nExercise 6\n\nGroup by\nGroup by is a keyword we use to lower the level of granularity of a table. Meaning we are combining rows into one by the given column(s).\nCreate a query that captures the number of pitchers the Washington Nationals used in each year, then sort the table by year\nYou should get a dataframe with 23 rows.",
    "crumbs": [
      "Project 3: SQL & Databases"
    ]
  },
  {
    "objectID": "Skill Builders/relational_data.html#because-youre-extra",
    "href": "Skill Builders/relational_data.html#because-youre-extra",
    "title": "SQL & Databases",
    "section": "Because You’re Extra",
    "text": "Because You’re Extra\n\nExercise 7\nResearch the order of operations for SQL and put the following keywords in that order.\n\nSELECT\nFROM\nJOIN\nWHERE\nHAVING\nORDER BY\nGROUP BY\nLIMIT\n\n\n\n\n\n\n\n\nNoteAfter you have completed this skill builder with your team (or on your own) then compare your work to our script\n\n\n\n\n\nSee the script.",
    "crumbs": [
      "Project 3: SQL & Databases"
    ]
  },
  {
    "objectID": "Syllabus/syllabus.html",
    "href": "Syllabus/syllabus.html",
    "title": "DS 250 Syllabus",
    "section": "",
    "text": "Most people would sooner die than think, and most of them do.\n-Bertrand Russell-",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "Syllabus/syllabus.html#footnotes",
    "href": "Syllabus/syllabus.html#footnotes",
    "title": "DS 250 Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://medium.com/@nikhilbd/what-makes-a-good-data-scientist-engineer-a8b4d7948a86#.jr80wl98y. I suppose some of you are just taking this class because your degree says you can, and it fits in your schedule. If so, we should chat to make sure this is the right class for you.↩︎\nhttps://arxiv.org/ftp/arxiv/papers/1612/1612.07140.pdf. You will see this pattern in DS 350, DS 460, and Math 488. It will progressively get more realistic.↩︎\nWe do expect that this is not your first experience with Python and VS Code. If you have done other programming courses, you should be able to succeed in this course. If you have any questions, please ask.↩︎\nMaking the right checklists can be difficult. Bad checklists could fall in the following categories – vague and imprecise; too long; hard to use; impractical; too pedantic. Useful checklists are precise, efficient, easy to use and understand. This is the first time this course has been offered, so we will have to work together to ensure the requirements are reasonable.↩︎",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "Workbooks/wb1.html",
    "href": "Workbooks/wb1.html",
    "title": "Project 1 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 1"
    ]
  },
  {
    "objectID": "Workbooks/wb1.html#tutoring-lab-info",
    "href": "Workbooks/wb1.html#tutoring-lab-info",
    "title": "Project 1 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 1"
    ]
  },
  {
    "objectID": "Workbooks/wb1.html#text-basics",
    "href": "Workbooks/wb1.html#text-basics",
    "title": "Project 1 Workbook",
    "section": "Text Basics",
    "text": "Text Basics\n\nHorizontal Lines\nAdd horizontal lines with either three ---, ***, or ___ But you also need blank lines above and below them\n\n\n\n\n\n\nTipExpand To See The Results\n\n\n\n\n\n\n\n\n\n\n\nHeaders\n# Level 1 Header\n## Level 2 Header\n### Level 3 Header\n#### Level 4 Header\n##### Level 5 Header\n###### Level 6 Header\nNote: only top 3 Levels of Headers will automatically generate a table of contents. Also Level 2 will automatically add a line underneath it.\n\n\n\n\n\n\nTipExpand To See The Results\n\n\n\n\n\nLevel 1 Header\n\nLevel 2 Header\n\nLevel 3 Header\n\nLevel 4 Header\n\nLevel 5 Header\n\nLevel 6 Header\n\n\n\n\n\n\n\n\n\n\nItalics and Bold\n_italics_ use one `_`\nyou can also use _mid_ sentence\n\n__bold__ use two `__`\nyou can also use __mid__ sentence\n\n\n\n\n\n\nTipExpand To See The Results\n\n\n\n\n\nitalics use one _ you can also use mid sentence\nbold use two __ you can also use mid sentence\n\n\n\n\n\nBullet Items\n- Bulleted items\n  - Indented bulleted items\n  - You can have as many as you want\n    - Really as many as you want\n      - I knew you wanted one more\n\n\n\n\n\n\nTipExpand To See The Results\n\n\n\n\n\n\nBulleted items\n\nIndented bulleted items\nYou can have as many as you want\n\nReally as many as you want\n\nI knew you wanted one more bullet\n\n\n\n\n\n\n\n\n\nNumbered Items\n1. Numbered items\n1. Numbered items continued\n1. Dont worry these will iterate\n1. Keep using 1. each time\n\n\n\n\n\n\nTipExpand To See The Results\n\n\n\n\n\n\nNumbered items\nNumbered items continued\nDont worry these will iterate\nKeep using 1. each time",
    "crumbs": [
      "Project 1"
    ]
  },
  {
    "objectID": "Workbooks/wb1.html#level-2-header",
    "href": "Workbooks/wb1.html#level-2-header",
    "title": "Project 1 Workbook",
    "section": "Level 2 Header",
    "text": "Level 2 Header\n\nLevel 3 Header\n\nLevel 4 Header\n\nLevel 5 Header\n\nLevel 6 Header",
    "crumbs": [
      "Project 1"
    ]
  },
  {
    "objectID": "Workbooks/wb1.html#pandas-dataframe-df",
    "href": "Workbooks/wb1.html#pandas-dataframe-df",
    "title": "Project 1 Workbook",
    "section": "Pandas DataFrame (df)",
    "text": "Pandas DataFrame (df)\n\n\n\n\n\n\nNoteExpand To See Links to Chapter in the book Python4DS\n\n\n\n\n\n\nChapter on Pandas: DataFrames\n\n\n\n\nWhat is a pandas dataFrame? We can read the official documentation. I also like the video in this tutorial.\nUse the Import Packages and Load df for the Code that follows.",
    "crumbs": [
      "Project 1"
    ]
  },
  {
    "objectID": "Workbooks/wb1.html#import-packages",
    "href": "Workbooks/wb1.html#import-packages",
    "title": "Project 1 Workbook",
    "section": "Import Packages",
    "text": "Import Packages\nimport `library` as `alias`\n\n\nImport Libraries\n\n#| label: libraries\n#| include: false\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\n\nfrom IPython.display import Markdown\nfrom IPython.display import display",
    "crumbs": [
      "Project 1"
    ]
  },
  {
    "objectID": "Workbooks/wb1.html#load-data",
    "href": "Workbooks/wb1.html#load-data",
    "title": "Project 1 Workbook",
    "section": "Load Data",
    "text": "Load Data\ndf = pd.read_csv(`url` or `file_path`)\n\n\nLoad Data\n\n#| label: project data\n#| code-summary: Read and format project data\n# Include and execute your code here\nurl = \"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\"\ndf = pd.read_csv(url)\n\nData Frames come with attributes and built-in functions that can help us get a feel for our df.\nRun the code below one at a time (or use other functions of your choice) to explore the names df. What do you learn?\n\n\n.columns\n\ndf.columns\n\n\n\n.shape\n\ndf.shape\n\n\n\n.size\n\ndf.size\n\n\n\n.head()\n\ndf.head()\n\n\n\n.describe()\n\ndf.describe()",
    "crumbs": [
      "Project 1"
    ]
  },
  {
    "objectID": "Workbooks/wb1.html#pandas-data-transformation",
    "href": "Workbooks/wb1.html#pandas-data-transformation",
    "title": "Project 1 Workbook",
    "section": "Pandas Data Transformation",
    "text": "Pandas Data Transformation\n\n\n\n\n\n\nNoteExpand To See Links to Chapter in the book Python4DS\n\n\n\n\n\n\nChapters Transformation: 15-22",
    "crumbs": [
      "Project 1"
    ]
  },
  {
    "objectID": "Workbooks/wb3.html",
    "href": "Workbooks/wb3.html",
    "title": "Project 3 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 3"
    ]
  },
  {
    "objectID": "Workbooks/wb3.html#tutoring-lab-info",
    "href": "Workbooks/wb3.html#tutoring-lab-info",
    "title": "Project 3 Workbook",
    "section": "",
    "text": "The data science lab is a resource you can use in person, online, and in Slack.",
    "crumbs": [
      "Project 3"
    ]
  },
  {
    "objectID": "Workbooks/wb5.html",
    "href": "Workbooks/wb5.html",
    "title": "Project 5 Workbook",
    "section": "",
    "text": "Project 5 WorkBook\nUnder Construction\n\n\n\n\n Back to top",
    "crumbs": [
      "Project 5"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Book Time with Us",
    "section": "",
    "text": "Book an office hour slot with your teacher.  Find office hours for all the Data Science Faculty Faculty.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DS 250: Data Science Programming",
    "section": "",
    "text": "Use the top menue to navigate to specific assignments, or use the Setup menu to get your computer ready for the course"
  },
  {
    "objectID": "index.html#how-to-navigate-this-course",
    "href": "index.html#how-to-navigate-this-course",
    "title": "DS 250: Data Science Programming",
    "section": "",
    "text": "Use the top menue to navigate to specific assignments, or use the Setup menu to get your computer ready for the course"
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "DS 250: Data Science Programming",
    "section": "Setup",
    "text": "Setup\nThis section contains all the needed info to get your computer setup for the course"
  },
  {
    "objectID": "index.html#faq",
    "href": "index.html#faq",
    "title": "DS 250: Data Science Programming",
    "section": "FAQ",
    "text": "FAQ\nLook here for common questions on the course"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "We will be relying on a few resources for this course. You will find the pertinant readings attached to each of the projects. Those readings will be culled from:\n\nPython for Data Science python4DS is a port of R for Data Science (2e) into Python.\npandas User Guide\nLets-Plot User Guide\nscikit-learn learn User Guide\nscikit-learn Tutorials\nPython Data Science Handbook\nA Whirlwind Tour of Python\nSQL\n\nWes McKinney’s pandas code for his book Python for Data Analysis is a useful reference as well: https://github.com/wesm/pydata-book\n\n\n\n Back to top",
    "crumbs": [
      "Projects"
    ]
  },
  {
    "objectID": "skill_builders.html",
    "href": "skill_builders.html",
    "title": "Skill Builders",
    "section": "",
    "text": "These short activites are provided for you to gain some additional skills to help with the class projects.\n\n\n\n Back to top",
    "crumbs": [
      "Skill Builders"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "About this site\n\n\n\n Back to top"
  }
]